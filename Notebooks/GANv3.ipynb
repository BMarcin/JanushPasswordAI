{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "plik = open(\"test.txt\")\n",
    "\n",
    "slowka = [slowo.lower().replace(\"\\n\", \"\") for index,slowo in enumerate(plik)]\n",
    "slowa = []\n",
    "\n",
    "print(len(slowka))\n",
    "\n",
    "# while len(slowa) < 1000:\n",
    "#     los = random.randint(0, len(slowka) - 1)\n",
    "#     if slowka[los] not in slowa:\n",
    "#         slowa.append(slowka[los])\n",
    "\n",
    "# print(len(slowa))\n",
    "# print(slowa[0:200])\n",
    "\n",
    "# slowa = slowa[0:2000]\n",
    "slowa = slowka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = open(\"test.txt\", \"a\")\n",
    "for slowo in slowa:\n",
    "    p1.write(slowo+\"\\n\")\n",
    "p1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plikembd = open(\"../character_embeddings.txt\")\n",
    "\n",
    "embeddings = {}\n",
    "\n",
    "for line in plikembd.readlines():\n",
    "    exp1 = line.replace(\"\\n\", \"\").split(\":\")\n",
    "    \n",
    "    znak = exp1[0]\n",
    "    embedding = [float(liczba) for liczba in exp1[1].replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\",\\t\")[:-1]]\n",
    "\n",
    "    \n",
    "    embeddings[znak] = embedding\n",
    "    \n",
    "embeddings['ðŸˆ³'] = [0 for __ in range(1600)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def podobienstwo_cosinusowe(wektor1, wektor2, podobienstwo_min=0.01):\n",
    "    if np.sum(wektor1) == 0 or np.sum(wektor2) == 0:\n",
    "        return 0\n",
    "    \n",
    "    sumaup = np.sum([(wektor1[x] * wektor2[x]) for x in range(len(wektor1))])\n",
    "    s1 = np.sum([skladowa**2 for skladowa in wektor1])\n",
    "    s2 = np.sum([skladowa**2 for skladowa in wektor2])\n",
    "    \n",
    "    down = math.sqrt(s1)*math.sqrt(s2)\n",
    "    \n",
    "    outt = sumaup/down\n",
    "    \n",
    "    if outt>=podobienstwo_min:\n",
    "        return outt\n",
    "    else:\n",
    "        return 0 \n",
    "    \n",
    "podobienstwo_cosinusowe(embeddings['a'], embeddings['ðŸˆ³'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('@', 0.0750612887457633)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def znajdz_najblizszy(wektor, embeddings):\n",
    "    najblizszy = 'ðŸˆ³'\n",
    "    podobienstwo = 0\n",
    "    \n",
    "    for key in embeddings:\n",
    "        pdb = podobienstwo_cosinusowe(wektor, embeddings[key])\n",
    "        \n",
    "        if pdb > podobienstwo:\n",
    "            podobienstwo = pdb\n",
    "            najblizszy = key\n",
    "    return najblizszy, podobienstwo\n",
    "    \n",
    "znajdz_najblizszy(np.random.rand(1600), embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11200,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_slowo(slowo, embeddings, dlugosc):\n",
    "    zwrot = np.array([])\n",
    "    for literka in slowo:\n",
    "        zwrot = np.append(zwrot, embeddings[literka])\n",
    "    \n",
    "    roznica = int(dlugosc - len(zwrot)/len(embeddings[list(embeddings.keys())[0]]))\n",
    "    \n",
    "    for __ in range(roznica):\n",
    "        zwrot = np.append(zwrot, [0 for __ in range(len(embeddings[literka]))])\n",
    "    \n",
    "    return zwrot.reshape(-1)\n",
    "\n",
    "build_slowo(\"a\", embeddings, 7).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "def najdluzsze_slowo(slowa):\n",
    "    najdl = 0\n",
    "    \n",
    "    for slowo in slowa:\n",
    "        if len(slowo) > najdl:\n",
    "            najdl = len(slowo)\n",
    "            \n",
    "    return najdl\n",
    "\n",
    "longest = 16\n",
    "print(longest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def przetlumacz_wyjscia(wyjscia_flat, embeddings):\n",
    "    dlugosc = len(embeddings[list(embeddings.keys())[0]])\n",
    "    \n",
    "    wyjscia = wyjscia_flat.reshape(-1, dlugosc)\n",
    "    \n",
    "    zwrot = \"\"\n",
    "    \n",
    "    for wyjscie in wyjscia:\n",
    "        zwrot = zwrot + znajdz_najblizszy(wyjscie, embeddings)[0]\n",
    "        \n",
    "    return zwrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.ConvTranspose1d(1, 4, 3, 1, 1)\n",
    "        self.mp1 =  nn.MaxPool1d(4)\n",
    "        \n",
    "        self.conv2 = nn.ConvTranspose1d(4, 8, 5, 1, 2)\n",
    "        self.mp2 = nn.MaxPool1d(8)\n",
    "        \n",
    "        \n",
    "        self.fc_in = nn.Linear(6400, 3000)\n",
    "        self.fc_h1 = nn.Linear(3000, 2000)\n",
    "        self.fc_h2 = nn.Linear(2000, 1000)\n",
    "        self.fc_out = nn.Linear(1000, 200)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.mp1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.mp2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = x.reshape(len(x), -1)\n",
    "        \n",
    "        x = self.fc_in(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_h1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_h2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc_1 = nn.Linear(500, 1500)\n",
    "        self.fc_out = nn.Linear(1500, 1800)\n",
    "        \n",
    "        self.conv1 = nn.ConvTranspose1d(100, 32, 8, 8, 0)\n",
    "        self.norm1 =  nn.BatchNorm1d(32)\n",
    "        \n",
    "        self.conv2 = nn.ConvTranspose1d(32, 16, 6, 6, 4)\n",
    "        self.norm2 =  nn.BatchNorm1d(16)\n",
    "      \n",
    "        self.conv3 = nn.ConvTranspose1d(16, 4, 6, 6, 6)\n",
    "        self.norm3 =  nn.BatchNorm1d(4)\n",
    "        \n",
    "        self.conv4 = nn.ConvTranspose1d(4, 1, 5, 5, 10)\n",
    "        self.norm4 =  nn.BatchNorm1d(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc_1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = x.reshape(len(x), 100, -1)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.norm3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        #x = self.norm4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        #nn.init.xavier_normal(m.weight.data, 1.0, 0.002)\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Discriminator().to(\"cuda:0\")\n",
    "generator = Generator().to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (conv1): ConvTranspose1d(1, 4, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (mp1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): ConvTranspose1d(4, 8, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (mp2): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc_in): Linear(in_features=6400, out_features=3000, bias=True)\n",
       "  (fc_h1): Linear(in_features=3000, out_features=2000, bias=True)\n",
       "  (fc_h2): Linear(in_features=2000, out_features=1000, bias=True)\n",
       "  (fc_out): Linear(in_features=1000, out_features=200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.apply(weights_init)\n",
    "classifier.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TensorRealIns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-0c232d58d341>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTensorFakeSeeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorRealIns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mTensorFakeIns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorFakeSeeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorFakeIns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TensorRealIns' is not defined"
     ]
    }
   ],
   "source": [
    "TensorFakeSeeds = torch.rand(len(TensorRealIns), 500).to(\"cuda:0\")\n",
    "TensorFakeIns = generator(TensorFakeSeeds).to(\"cuda:0\")\n",
    "\n",
    "print(TensorFakeIns.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ae0032fc70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manualSeed = 1001\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 200])\n",
      "torch.Size([400, 200])\n"
     ]
    }
   ],
   "source": [
    "TensorRealOuts = torch.ones((len(slowa), 200)).float().to(\"cuda:0\")\n",
    "TensorFakeOuts = torch.zeros((len(slowa), 200)).float().to(\"cuda:0\")\n",
    "\n",
    "TensorOuts = torch.cat((TensorRealOuts, TensorFakeOuts), 0)\n",
    "\n",
    "print(TensorRealOuts.shape)\n",
    "print(TensorFakeOuts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "optimizerGenerator = optim.Adam(generator.parameters(), lr=1e-3)\n",
    "optimizerClassifier = optim.Adam(classifier.parameters(), lr=1e-6)\n",
    "\n",
    "print(optimizerGenerator)\n",
    "print(optimizerClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 1, 25600])\n"
     ]
    }
   ],
   "source": [
    "probki = np.array([])\n",
    "\n",
    "for slowo in slowa:\n",
    "    probki = np.append(probki, build_slowo(slowo, embeddings, longest))\n",
    "    \n",
    "probki = probki.reshape(len(slowa), 1, -1)\n",
    "\n",
    "TensorRealIns = torch.tensor(probki).float().to(\"cuda:0\")\n",
    "\n",
    "print(TensorRealIns.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeneratorLosses = []\n",
    "ClassifierLosses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.4583, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>) tensor(12.9305, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "RhPon`@y.@#i,g`@\n",
      "torch.Size([400, 1, 25600])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    TensorFakeSeeds = torch.rand(len(TensorRealIns), 500).to(\"cuda:0\")\n",
    "    TensorFakeIns = generator(TensorFakeSeeds).to(\"cuda:0\")\n",
    "    \n",
    "    if epoch == 1:\n",
    "        print(TensorFakeIns.shape)\n",
    "    \n",
    "    TensorIns = torch.cat((TensorRealIns, TensorFakeIns.detach()), 0)\n",
    "    \n",
    "    classifier.train()\n",
    "    optimizerClassifier.zero_grad()\n",
    "    \n",
    "    y_ = classifier(TensorIns)\n",
    "    lossClassifier = criterion(y_, TensorOuts)\n",
    "    \n",
    "    lossClassifier.backward()\n",
    "    optimizerClassifier.step()\n",
    "    \n",
    "    generator.train()\n",
    "    optimizerGenerator.zero_grad()\n",
    "    \n",
    "    y_ = classifier(TensorFakeIns)\n",
    "    lossGenerator = criterion(y_, TensorRealOuts)\n",
    "    \n",
    "    lossGenerator.backward()\n",
    "    optimizerGenerator.step()\n",
    "    \n",
    "    GeneratorLosses.append(lossGenerator)\n",
    "    ClassifierLosses.append(lossClassifier)\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        print(lossClassifier, lossGenerator)\n",
    "        print(przetlumacz_wyjscia(TensorFakeIns[0].cpu().detach().numpy(), embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8b344f9260452e95a98151eea426ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ae065e6588>,\n",
       " <matplotlib.lines.Line2D at 0x1ae07a2e6d8>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix, ax = plt.subplots()\n",
    "ax.plot([x for x in range(len(GeneratorLosses))], GeneratorLosses, \".\", [x for x in range(len(GeneratorLosses))], ClassifierLosses, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L5K@@@@ww@oi^5`@\n",
      "L5K@@@@ww@oi^5`@\n",
      "L5K^@@@ww@oi^5`@\n",
      "L5K@@@@ww@oi^5`@\n",
      "L5K^@@@ww@oi^5`@\n"
     ]
    }
   ],
   "source": [
    "TensorFakeSeeds = torch.rand(5, 500).to(\"cuda:0\")\n",
    "TensorFakeIns = generator(TensorFakeSeeds).to(\"cuda:0\")\n",
    "\n",
    "\n",
    "outs = TensorFakeIns.cpu().detach().numpy()\n",
    "for out in outs:\n",
    "    print(przetlumacz_wyjscia(out, embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
