{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400])\n",
      "torch.Size([82, 400])\n",
      "tensor([-0.1842972338,  0.1992288828, -0.1093217134,  0.0635560006,\n",
      "        -0.0170881711, -0.0069951965,  0.1790032834, -0.1581476331,\n",
      "         0.0322009474, -0.1496459693, -0.1595581025, -0.2537648678,\n",
      "         0.2232226729, -0.1215698719,  0.0059251408, -0.1644940972,\n",
      "         0.0264174044,  0.0696226805, -0.0749481246,  0.2048900872,\n",
      "        -0.0481871516, -0.1348041445,  0.1884992272, -0.0314494744,\n",
      "         0.1081886366,  0.0045932876, -0.1269595921,  0.1936095357,\n",
      "        -0.0679676980,  0.1462467760, -0.2293221653, -0.2348391116,\n",
      "        -0.1658135504, -0.0536651835,  0.0345649682, -0.0555758253,\n",
      "         0.1800168753, -0.1355556846,  0.0986127034, -0.0864410177,\n",
      "        -0.1333196312, -0.0306926053,  0.2023293376,  0.1658294201,\n",
      "         0.1575038880,  0.1013869643, -0.0837135166, -0.0609861165,\n",
      "        -0.1243505403, -0.0618062057, -0.0087015610, -0.1109482422,\n",
      "        -0.1424127370,  0.1705076247, -0.0412648059, -0.1866530329,\n",
      "         0.1705746651, -0.0454960205,  0.0511074215, -0.1814958006,\n",
      "         0.0312571451,  0.0023679240,  0.1567359865,  0.1214345321,\n",
      "         0.1875774860, -0.1155519187, -0.1487986147,  0.0846847817,\n",
      "        -0.1553875506,  0.1239548177,  0.1238240525,  0.1030294448,\n",
      "        -0.1249729469,  0.0957288370,  0.1068888679,  0.1004554108,\n",
      "         0.1896177530,  0.0751672834, -0.0123409629, -0.0072713750,\n",
      "        -0.1125810742,  0.1464326680, -0.0432669930,  0.1002970040,\n",
      "         0.1720880121, -0.1439751685,  0.1484931260, -0.0750802234,\n",
      "         0.1245075390,  0.1575208008,  0.0472818762,  0.1708101332,\n",
      "         0.1424195766, -0.2113518566,  0.1518024951,  0.1012588069,\n",
      "        -0.0948293880,  0.0880734175,  0.0028987343,  0.2490037680,\n",
      "        -0.1517948061,  0.2179073542,  0.1115292311, -0.0907436609,\n",
      "         0.0373055227,  0.1338036805,  0.0446807742,  0.0494914353,\n",
      "        -0.2003040314, -0.0165758971,  0.1906725913, -0.1125686616,\n",
      "         0.0837075040,  0.0787189752,  0.1161330193, -0.0904760137,\n",
      "        -0.2200971097,  0.1388819069,  0.2000113577,  0.0662657768,\n",
      "        -0.0767664090, -0.0759414434, -0.1551424116,  0.0764692724,\n",
      "         0.1699705720, -0.1184115931, -0.1102459058, -0.1875358224,\n",
      "        -0.0696347654,  0.0091158981, -0.0635609850, -0.1298705339,\n",
      "        -0.1130863652,  0.1928980798,  0.0196687635, -0.1482946724,\n",
      "         0.1796324104, -0.0572765842, -0.0930459797,  0.1370632946,\n",
      "        -0.0885020420, -0.0541497134, -0.0244223736,  0.1394562423,\n",
      "        -0.1150914058,  0.1048353016, -0.2776700556, -0.0062887603,\n",
      "         0.0435514413, -0.1757234782,  0.1874617785,  0.0973147750,\n",
      "         0.0489514396, -0.0719382167, -0.1697351038,  0.1430554092,\n",
      "         0.0192177109,  0.1406140029,  0.1027340665, -0.0372597240,\n",
      "         0.1868329346,  0.0916185975,  0.1726666093,  0.0728651732,\n",
      "         0.1129153222, -0.1677419543,  0.1660490781,  0.1553547531,\n",
      "        -0.1485620588, -0.0291875415,  0.0967422724, -0.1426796019,\n",
      "        -0.1801590472,  0.1073170677, -0.0307026878, -0.0640823022,\n",
      "        -0.0255387817,  0.1424802244,  0.0004050134,  0.0920248032,\n",
      "         0.0143009005,  0.1399734169,  0.1375159621,  0.0583447553,\n",
      "        -0.1298392266,  0.1625779867,  0.2700724602, -0.0049731066,\n",
      "         0.0533687323,  0.1339427382, -0.1611949503,  0.1461808085,\n",
      "         0.0875659809,  0.1031135619,  0.1906691343,  0.1570144594,\n",
      "         0.1205297783,  0.1688521951, -0.1290624142,  0.1077630520,\n",
      "         0.0646254569, -0.0102814827,  0.1897805631,  0.0730651394,\n",
      "        -0.0361849256, -0.2131652385, -0.1004962847, -0.0281383228,\n",
      "         0.1142958701,  0.3582850695, -0.0521302670,  0.0565140471,\n",
      "         0.1427058876,  0.0326559618, -0.1475312263,  0.2360350192,\n",
      "         0.0762174577,  0.1049004719, -0.0177720413,  0.0165965576,\n",
      "        -0.1699303985, -0.1306957453,  0.0217954274, -0.1758347750,\n",
      "        -0.0145670343, -0.0427457616, -0.1830043495, -0.1423098147,\n",
      "        -0.0442552604, -0.1996498257, -0.1549610943, -0.1192394048,\n",
      "        -0.0189614743,  0.1687261015, -0.1377387643,  0.1158430278,\n",
      "        -0.1168809235, -0.0595252439,  0.1422863752, -0.0726736933,\n",
      "        -0.0970197693, -0.1513723582, -0.0153689021,  0.1075288206,\n",
      "         0.0062753111, -0.0657496303,  0.1142629385, -0.1874541789,\n",
      "         0.1355450153, -0.1197057068,  0.0969110653,  0.1124221683,\n",
      "        -0.1598580629, -0.1999936551,  0.1559768468, -0.0135932276,\n",
      "         0.0698354617, -0.0378662422, -0.0273320470,  0.1686098427,\n",
      "         0.0638542548,  0.0868597031, -0.2574052811, -0.1108667031,\n",
      "         0.1787936836, -0.0970125794,  0.1467291713, -0.1019845307,\n",
      "        -0.1779254824,  0.1495919228,  0.2319046408, -0.0068741417,\n",
      "         0.1250005960,  0.1217587665,  0.0579981767, -0.1207496375,\n",
      "         0.1159732714,  0.1765701473,  0.0880894139,  0.0891111791,\n",
      "        -0.0511370264, -0.1724291742, -0.0651685894, -0.1133691743,\n",
      "         0.0261005946,  0.1822266430, -0.1386639923,  0.1091069654,\n",
      "         0.0469622687,  0.0981997624,  0.1842999160,  0.0152545795,\n",
      "         0.2312818617, -0.2560451925,  0.2024395615, -0.1238090470,\n",
      "         0.0606538616,  0.1952640712,  0.1311136633,  0.0081821000,\n",
      "        -0.1812462211, -0.1416241527,  0.1679642946,  0.1101941615,\n",
      "         0.1321880817, -0.1651239395,  0.1416729391, -0.0768660903,\n",
      "        -0.0916962326, -0.0775291026, -0.2172259390, -0.1380983442,\n",
      "         0.0925596729, -0.0876334459, -0.2041635662, -0.0396521129,\n",
      "        -0.0101271058,  0.0576047227,  0.1529120356,  0.0813933760,\n",
      "        -0.1099956483,  0.0344682857, -0.0813828111, -0.0637205914,\n",
      "        -0.1817055047, -0.0274054278,  0.2254342586,  0.2037117928,\n",
      "        -0.0709478110,  0.0082736313, -0.0607478879,  0.1292374283,\n",
      "        -0.0619269907, -0.1211330220, -0.0717913657, -0.1346032619,\n",
      "         0.0283130053,  0.0519250222,  0.1985547543, -0.1104769856,\n",
      "         0.0229423828,  0.0502811708, -0.1786527038, -0.1101744026,\n",
      "        -0.1502699554,  0.0042145052,  0.1003464609, -0.1421854645,\n",
      "         0.2305352092, -0.1077509522, -0.0847016275, -0.0700057745,\n",
      "         0.0919583738,  0.0947080180, -0.0742726102,  0.0602409802,\n",
      "         0.0123806819, -0.0902131498, -0.1669095159, -0.0799129456,\n",
      "         0.0454242714, -0.0129831648,  0.0325469524, -0.1643709987,\n",
      "        -0.0702609643,  0.0084340880,  0.1076420695,  0.2151346654,\n",
      "         0.2070665509, -0.1017798707,  0.0752904639, -0.1276532561,\n",
      "         0.2041089237, -0.1919434816,  0.0478103012, -0.0078700772,\n",
      "        -0.0243321322, -0.1665397882, -0.0519231334,  0.0806803480,\n",
      "         0.1152695641, -0.1654838473, -0.1136450171, -0.0383588187,\n",
      "        -0.1330948323, -0.1974440515, -0.1925254464,  0.0895201564,\n",
      "        -0.1270922720,  0.0431650355,  0.1176075265, -0.1642593443,\n",
      "        -0.1327029169,  0.0386101417,  0.0340109691,  0.1809563041,\n",
      "         0.0674237758,  0.0658109337,  0.2508264184,  0.1139955670],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "plikembd = open(\"../embeddings_small.txt\")\n",
    "\n",
    "embeddings = {}\n",
    "\n",
    "embeddings['ðŸˆ³'] = np.zeros(400)\n",
    "\n",
    "embeddingscuda_chars = {}\n",
    "embeddingscuda_chars['ðŸˆ³'] = 0\n",
    "\n",
    "embeddingscuda = torch.tensor([]).to(\"cuda:0\")\n",
    "embeddingscuda =  torch.cat((embeddingscuda, torch.zeros((400)).to(\"cuda:0\")), 0)\n",
    "#mbeddingscuda = torch.cat((embeddingscuda, torch.zeros((1, 400), dtype=torch.float64).to(\"cuda:0\")), 0)\n",
    "\n",
    "print(embeddingscuda.shape)\n",
    "\n",
    "for cnt, line in enumerate(plikembd.readlines()):\n",
    "    exp1 = line.replace(\"\\n\", \"\").split(\":\")\n",
    "    \n",
    "    znak = exp1[0]\n",
    "    embedding = torch.tensor([float(liczba) for liczba in exp1[1].replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\",\\t\")[:-1]]).to(\"cuda:0\")\n",
    "    \n",
    "    embeddingscuda_chars[znak] = cnt+1\n",
    "    embeddingscuda = torch.cat((embeddingscuda, embedding), 0)\n",
    "    #embeddingscuda[cnt+1] = embedding\n",
    "\n",
    "    \n",
    "    embeddings[znak] = embedding\n",
    "\n",
    "#embeddingscuda = embeddingscuda/10\n",
    "    \n",
    "\n",
    "\n",
    "embeddingscuda = embeddingscuda.reshape(len(embeddings), -1)\n",
    "\n",
    "\n",
    "#print(embeddings['a'])\n",
    "#print(embeddingscuda_chars['a'])\n",
    "print(embeddingscuda.shape)\n",
    "print(embeddingscuda[embeddingscuda_chars['a']])\n",
    "#-0.18429723"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abmicro', '527579', 'agro2011', 'nakamichi', 'dugant', '29082009', 'hannah1', 'ma12po', '580813', 'lukasz4', 'kriket', 'werohaze', 'dron14121987', 'pinot1', 'maria59', 'moltrex', 'kilim', 'Zabeczka', '7937', '7maluszek', 'gacek16', 'ruleta1', '17Cyprian', 'maj2006', 'o2skarek', 'anno01', 'gusciol', 'gumis1', 'malaz11', 'watomzon', 'rumianek', 'neoisp', 'zsofie', 'zipera', '141084', 'ultraboy', '110567', 'anbog', 'troyd34', 'roxboro', 'werunia', 'misiokrzysio', 'hydra6', 'grzes10', 'kakigewy', 'filip98', '20021970', 'natka777', 'patricia', 'polisnova', 'miko20', 'prj2501', 'grobian1', '1972ml', 'robo21101967', 'jw17061958', 'gregordj', 'insko2000', 'maclear', 'zl060374', 'asia7', 'misiu777', 'varius2', 'lgflatron', 'rele1', '130178', 'centrala', 'filoman', '41karat2', '84jaysinner', 'agatina', 'ambasada', 'maly17', 'goszkam', '1branka', 'dasti', 'petro111', '070165', '20111965', 'triforce', 'bogumil1', 'anna3005', 'dron10011001', 'santaclara', 'pas2526', '11011975', 'rest12', 'j87neo', 'limak44', 'dark72', '258447', 'sk8000', '110871', 'wolf1111', 'arek1967', '24011959', 'kataga1', 'arek456', 'tokaj', 'platanowa']\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "polskie = open(\"../100k.txt\", encoding='utf8')\n",
    "slowa = [slowo.replace(\"\\n\", \"\") for slowo in polskie.readlines()]\n",
    "polskie.close()\n",
    "print(slowa[:100])\n",
    "print(len(slowa))\n",
    "slowa = slowa[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2830401361, device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def podobienstwo_cosinusowe(wektor1, wektor2, podobienstwo_min=0.01):\n",
    "    if torch.sum(wektor1) == 0 or torch.sum(wektor2) == 0:\n",
    "        return 0\n",
    "    \n",
    "    sumaup = torch.sum(wektor1 * wektor2)\n",
    "    s1 = torch.sum(wektor1**2)\n",
    "    s2 = torch.sum(wektor2**2)\n",
    "\n",
    "    outt = sumaup/(torch.sqrt(s1)*torch.sqrt(s2))\n",
    "    \n",
    "    if outt>=podobienstwo_min:\n",
    "        return outt\n",
    "    else:\n",
    "        return 0 \n",
    "podobienstwo_cosinusowe(embeddings['a'], embeddings['e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-14 19:34:53.074755\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sum(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a5318063b7b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mznajdz_najblizszy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-a5318063b7b2>\u001b[0m in \u001b[0;36mznajdz_najblizszy\u001b[1;34m(wektor, embeddings)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mpdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpodobienstwo_cosinusowe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwektor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;31m#przemnozyc macierze na raz, bez for'a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpdb\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mpodobienstwo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-b37a7bef01b9>\u001b[0m in \u001b[0;36mpodobienstwo_cosinusowe\u001b[1;34m(wektor1, wektor2, podobienstwo_min)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpodobienstwo_cosinusowe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwektor1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwektor2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpodobienstwo_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwektor1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwektor2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msumaup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwektor1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mwektor2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: sum(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "def znajdz_najblizszy(wektor, embeddings):\n",
    "    najblizszy = 'ðŸˆ³'\n",
    "    podobienstwo = 0\n",
    "    \n",
    "    if torch.sum(wektor) == 0:\n",
    "        return najblizszy, 1\n",
    "    \n",
    "    for key in embeddings:\n",
    "        pdb = podobienstwo_cosinusowe(wektor, embeddings[key])\n",
    "        #przemnozyc macierze na raz, bez for'a\n",
    "        if pdb > podobienstwo:\n",
    "            podobienstwo = pdb\n",
    "            najblizszy = key\n",
    "    return najblizszy, podobienstwo\n",
    "\n",
    "print(str(datetime.now()))\n",
    "znajdz_najblizszy(torch.randn((400)).to(\"cuda:0\"), embeddings)\n",
    "print(str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(str(datetime.now()))\n",
    "# sumaup = torch.sum(embeddingscuda[embeddingscuda_chars['a']] * embeddingscuda, dim=1, dtype=torch.float64).to(\"cuda:0\")\n",
    "\n",
    "\n",
    "\n",
    "# s1 = torch.sum(embeddingscuda[embeddingscuda_chars['a']]**2, dtype=torch.float64).to(\"cuda:0\")\n",
    "\n",
    "# s2 = torch.sum(embeddingscuda**2, dim=1, dtype=torch.float64).to(\"cuda:0\")\n",
    "\n",
    "# wynik = sumaup/(torch.sqrt(s1)*torch.sqrt(s2))\n",
    "\n",
    "# wynik[0] = 0\n",
    "\n",
    "# print(str(datetime.now()))\n",
    "# print(wynik)\n",
    "# print(torch.max(wynik))\n",
    "# print(list(embeddingscuda_chars.keys())[torch.argmax(wynik).item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddingscuda[embeddingscuda_chars['a']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2830401361, device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "podobienstwo_cosinusowe(embeddings['a'], embeddings['e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'm', 'i', 'c', 'r', 'o', '5', '2', '7', '9', 'g', '0', '1', 'n', 'k', 'h', 'd', 'u', 't', '8', 'p', '3', 'l', 's', 'z', '4', 'e', 'w', 'x', 'Z', '6', 'C', 'y', 'j', 'f', 'v', 'F', 'P', 'R', 'O', 'T', 'A', 'X', 'L', 'E', 'S', 'I', 'K', 'N', 'D', 'M', 'q', 'H', 'U', 'J', 'Q', 'G', 'W', 'B', 'V', 'Y', '@', '.', '#', '!', ';', '*']\n",
      "15\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "longestword = 0\n",
    "\n",
    "unikalneznaki = []\n",
    "for slowo in slowa:\n",
    "    for literka in slowo:\n",
    "        if literka not in unikalneznaki:\n",
    "            unikalneznaki.append(literka)\n",
    "    if len(slowo) > longestword:\n",
    "        longestword = len(slowo)\n",
    "            \n",
    "print(unikalneznaki)\n",
    "print(longestword)\n",
    "print(len(unikalneznaki))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ðŸˆ³', ' ', '!', '#', '$', '%', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ';', '=', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "print(list(embeddings.keys()))\n",
    "print(len(list(embeddings.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings[list(embeddings.keys())[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "82\n",
      "82\n",
      "{'ðŸˆ³': 0, ' ': 1, '!': 2, '#': 3, '$': 4, '%': 5, '*': 6, '+': 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ';': 22, '=': 23, '@': 24, 'A': 25, 'B': 26, 'C': 27, 'D': 28, 'E': 29, 'F': 30, 'G': 31, 'H': 32, 'I': 33, 'J': 34, 'K': 35, 'L': 36, 'M': 37, 'N': 38, 'O': 39, 'P': 40, 'Q': 41, 'R': 42, 'S': 43, 'T': 44, 'U': 45, 'V': 46, 'W': 47, 'X': 48, 'Y': 49, 'Z': 50, '[': 51, ']': 52, '^': 53, '_': 54, '`': 55, 'a': 56, 'b': 57, 'c': 58, 'd': 59, 'e': 60, 'f': 61, 'g': 62, 'h': 63, 'i': 64, 'j': 65, 'k': 66, 'l': 67, 'm': 68, 'n': 69, 'o': 70, 'p': 71, 'q': 72, 'r': 73, 's': 74, 't': 75, 'u': 76, 'v': 77, 'w': 78, 'x': 79, 'y': 80, 'z': 81}\n"
     ]
    }
   ],
   "source": [
    "onehotvectors = {}\n",
    "klasyid = {}\n",
    "\n",
    "for cnt, litera in enumerate(list(embeddings.keys())):\n",
    "    vector = [0 for __ in range(len(embeddings.keys()))]\n",
    "    vector[cnt] = 1\n",
    "    onehotvectors[litera] = torch.Tensor(vector).to(\"cuda:0\")\n",
    "    \n",
    "    klasyid[litera] = cnt\n",
    "    \n",
    "print(len(onehotvectors))\n",
    "print(len(onehotvectors['ðŸˆ³']))\n",
    "print(len(klasyid))\n",
    "print(klasyid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "print(onehotvectors['ðŸˆ³'])\n",
    "print(len(onehotvectors['ðŸˆ³']))\n",
    "\n",
    "dlugoschotvectora = len(onehotvectors['ðŸˆ³'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilosc wejsc dyskryminatora: 1230\n",
      "ilosc wyjsc generatora: 6000\n"
     ]
    }
   ],
   "source": [
    "print(\"ilosc wejsc dyskryminatora: \" + str(dlugoschotvectora * longestword))\n",
    "print(\"ilosc wyjsc generatora: \" + str(len(embeddings['ðŸˆ³']) * longestword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000\n"
     ]
    }
   ],
   "source": [
    "dataset_real = []\n",
    "iloscslow = 0\n",
    "\n",
    "pusty = torch.zeros(dlugoschotvectora).to(\"cuda:0\")\n",
    "\n",
    "for cnt, slowo in enumerate(slowa):\n",
    "    slowoencoded = []\n",
    "    \n",
    "    for index in range(longestword):\n",
    "        if index < len(slowo):\n",
    "            slowoencoded.append(onehotvectors[slowo[index]])\n",
    "        else:\n",
    "            slowoencoded.append(pusty)\n",
    "        iloscslow = iloscslow + 1\n",
    "    dataset_real = dataset_real + slowoencoded\n",
    "\n",
    "print(len(dataset_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [01:04, 153.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 1230])\n"
     ]
    }
   ],
   "source": [
    "dataset_real = torch.Tensor([]).to(\"cuda:0\")\n",
    "iloscslow = 0\n",
    "\n",
    "#pusty = [0 for __ in range(len(embeddings.keys()))]\n",
    "pusty = torch.zeros(len(embeddings.keys())).to(\"cuda:0\")\n",
    "\n",
    "for cnt, slowo in tqdm(enumerate(slowa)):\n",
    "    for index in range(longestword):\n",
    "        if index<len(slowo):\n",
    "            #slowoencoded = slowoencoded + onehotvectors[slowo[index]]\n",
    "            dataset_real = torch.cat((dataset_real, onehotvectors[slowo[index]]), 0)\n",
    "            # slowoencoded.append(slowo[index])\n",
    "        else:\n",
    "            #slowoencoded = slowoencoded + [0 for __ in range(len(unikalneznaki))]\n",
    "            dataset_real = torch.cat((dataset_real, pusty), 0)\n",
    "    #torch.cat((slowoencoded, pusty), 0)\n",
    "    #dataset_real = np.append(dataset_real, slowoencoded)\n",
    "    iloscslow = iloscslow + 1\n",
    "    #if len(slowo) < longestword:\n",
    "    #    for __ in range(longestword - len(slowo)):\n",
    "    #        #dataset_real.append(\"XD\")\n",
    "    #        slowoencoded = [slowoencoded[-1]] + slowoencoded[:-1]\n",
    "    #        dataset_real = dataset_real + slowoencoded\n",
    "    #        iloscslow = iloscslow + 1\n",
    "    \n",
    "#dataset_real = np.array(dataset_real)\n",
    "\n",
    "dataset_real = dataset_real.reshape(iloscslow, -1)\n",
    "\n",
    "print(dataset_real.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOs\n",
    "ZrobiÄ‡ FeatureLoss'a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-9331869679b5>, line 51)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-20-9331869679b5>\"\u001b[1;36m, line \u001b[1;32m51\u001b[0m\n\u001b[1;33m    def cuda(vectors):\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "vectors = [\n",
    "           [embeddingscuda[embeddingscuda_chars['a']], \n",
    "           embeddingscuda[embeddingscuda_chars['b']], \n",
    "           embeddingscuda[embeddingscuda_chars['c']], \n",
    "           embeddingscuda[embeddingscuda_chars['d']], \n",
    "           embeddingscuda[embeddingscuda_chars['e']],\n",
    "           embeddingscuda[embeddingscuda_chars['f']],\n",
    "           embeddingscuda[embeddingscuda_chars['g']],\n",
    "           embeddingscuda[embeddingscuda_chars['h']],\n",
    "           [embeddingscuda[embeddingscuda_chars['a']], \n",
    "           embeddingscuda[embeddingscuda_chars['b']], \n",
    "           embeddingscuda[embeddingscuda_chars['c']], \n",
    "           embeddingscuda[embeddingscuda_chars['d']], \n",
    "           embeddingscuda[embeddingscuda_chars['e']],\n",
    "           embeddingscuda[embeddingscuda_chars['f']],\n",
    "           embeddingscuda[embeddingscuda_chars['g']],\n",
    "           embeddingscuda[embeddingscuda_chars['h']],\n",
    "           [embeddingscuda[embeddingscuda_chars['a']], \n",
    "           embeddingscuda[embeddingscuda_chars['b']], \n",
    "           embeddingscuda[embeddingscuda_chars['c']], \n",
    "           embeddingscuda[embeddingscuda_chars['d']], \n",
    "           embeddingscuda[embeddingscuda_chars['e']],\n",
    "           embeddingscuda[embeddingscuda_chars['f']],\n",
    "           embeddingscuda[embeddingscuda_chars['g']],\n",
    "           embeddingscuda[embeddingscuda_chars['h']],\n",
    "           [embeddingscuda[embeddingscuda_chars['a']], \n",
    "           embeddingscuda[embeddingscuda_chars['b']], \n",
    "           embeddingscuda[embeddingscuda_chars['c']], \n",
    "           embeddingscuda[embeddingscuda_chars['d']], \n",
    "           embeddingscuda[embeddingscuda_chars['e']],\n",
    "           embeddingscuda[embeddingscuda_chars['f']],\n",
    "           embeddingscuda[embeddingscuda_chars['g']],\n",
    "           embeddingscuda[embeddingscuda_chars['h']],\n",
    "           [embeddingscuda[embeddingscuda_chars['a']], \n",
    "           embeddingscuda[embeddingscuda_chars['b']], \n",
    "           embeddingscuda[embeddingscuda_chars['c']], \n",
    "           embeddingscuda[embeddingscuda_chars['d']], \n",
    "           embeddingscuda[embeddingscuda_chars['e']],\n",
    "           embeddingscuda[embeddingscuda_chars['f']],\n",
    "           embeddingscuda[embeddingscuda_chars['g']],\n",
    "           embeddingscuda[embeddingscuda_chars['h']],\n",
    "           [embeddingscuda[embeddingscuda_chars['a']], \n",
    "           embeddingscuda[embeddingscuda_chars['b']], \n",
    "           embeddingscuda[embeddingscuda_chars['c']], \n",
    "           embeddingscuda[embeddingscuda_chars['d']], \n",
    "           embeddingscuda[embeddingscuda_chars['e']],\n",
    "           embeddingscuda[embeddingscuda_chars['f']],\n",
    "           embeddingscuda[embeddingscuda_chars['g']],\n",
    "           embeddingscuda[embeddingscuda_chars['h']]]\n",
    "]\n",
    "def cuda(vectors):\n",
    "    #strings = []\n",
    "    wyniki_loss = []\n",
    "    onehots = torch.tensor([]).to(\"cuda:0\")\n",
    "    \n",
    "    s2 = torch.sum(embeddingscuda**2, dim=1, dtype=torch.float64).to(\"cuda:0\")\n",
    "    \n",
    "    for cnt in tqdm(range(len(vectors))):\n",
    "\n",
    "        #string = \"\"\n",
    "\n",
    "        for single in vectors[cnt]:\n",
    "            \n",
    "            sumaup = torch.sum(single * embeddingscuda, dim=1, dtype=torch.float64).to(\"cuda:0\")\n",
    "            s1 = torch.sum(single**2, dtype=torch.float64).to(\"cuda:0\") \n",
    "\n",
    "            wynik = sumaup/(torch.sqrt(s1)*torch.sqrt(s2))\n",
    "            wynik[0] = 0\n",
    "            #string=string+list(embeddingscuda_chars.keys())[torch.argmax(wynik).item()]\n",
    "            wyniki_loss.append(torch.max(wynik).item())\n",
    "            onehots = torch.cat((onehots, onehotvectors[list(embeddingscuda_chars.keys())[torch.argmax(wynik).item()]]), 0)\n",
    "            \n",
    "    #strings.append(string)\n",
    "        \n",
    "    return \"\", onehots.reshape(len(vectors), -1), np.mean(np.array(wyniki_loss))\n",
    "%time cuda(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()     \n",
    "        \n",
    "        self.fc_in = nn.Linear(1230, 800)\n",
    "        self.fc_h1 = nn.Linear(800, 400)\n",
    "#         self.fc_h2 = nn.Linear(400, 200)\n",
    "#         self.fc_h3 = nn.Linear(200, 100)\n",
    "#         self.fc_h4 = nn.Linear(100, 50)\n",
    "        self.fc_h5 = nn.Linear(400, 20)\n",
    "        self.fc_out = nn.Linear(20, 1)\n",
    "        \n",
    "    def forward(self, x):      \n",
    "        x = self.fc_in(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_h1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "#         x = self.fc_h2(x)\n",
    "#         x = F.relu(x)\n",
    "        \n",
    "#         x = self.fc_h3(x)\n",
    "#         x = F.relu(x)\n",
    "        \n",
    "#         x = self.fc_h4(x)\n",
    "#         x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_h5(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.fc_in = nn.Linear(500, 800)\n",
    "        self.fc_h1 = nn.Linear(800, 3500)\n",
    "#         self.fc_h2 = nn.Linear(1200, 2000)\n",
    "#         self.fc_h3 = nn.Linear(2000, 2800)\n",
    "#         self.fc_h4 = nn.Linear(2800, 3500)\n",
    "        self.fc_out = nn.Linear(3500, 6000)\n",
    "        \n",
    "        self.activation1 = nn.PReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc_in (x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_h1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "#         x = self.fc_h2(x)\n",
    "#         x = F.relu(x)\n",
    "        \n",
    "#         x = self.fc_h3(x)\n",
    "#         x = F.relu(x)\n",
    "        \n",
    "#         x = self.fc_h4(x)\n",
    "#         x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        x = self.activation1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_real = np.array(dataset_real).reshape(iloscslow, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dataset_real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(dataset_real[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator().to(\"cuda:0\")\n",
    "generator = Generator().to(\"cuda:0\")\n",
    "\n",
    "TensorReal = dataset_real\n",
    "\n",
    "TensorFakeOuts = torch.zeros(len(dataset_real)).to(\"cuda:0\")\n",
    "TensorRealOuts = torch.ones(len(dataset_real)).to(\"cuda:0\")\n",
    "\n",
    "TensorOuts = torch.cat((TensorFakeOuts, TensorRealOuts), 0).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1230])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorReal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "criterion_segment = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_outputs_to_onehots(npoutputs, dlugoscunikalne, embeddings, longestword, onehots):\n",
    "    zwrot = []\n",
    "    \n",
    "    skok = int(len(npoutputs) / multiprocessing.cpu_count())\n",
    "    ilezostalo = len(npoutputs) % multiprocessing.cpu_count()\n",
    "    \n",
    "    padding = 0\n",
    "    if skok == 1:\n",
    "        padding = 1\n",
    "    \n",
    "    podzial = [(x*skok,x*skok+skok) if (x*skok+skok-1-x*skok) > 0 else (x*skok,x*skok+padding) for x in range(multiprocessing.cpu_count())]\n",
    "    \n",
    "    if ilezostalo != 0:\n",
    "        podzial[-1] = (podzial[-1][0], podzial[-1][1]+ilezostalo)\n",
    "\n",
    "    #print([(i[0],i[1]) for i in podzial])\n",
    "    \n",
    "    results = []\n",
    "    results = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(translate_outputs_to_onehots_parallel)(npoutputs[i[0]:i[1]], dlugoscunikalne, embeddings, onehots) for i in podzial)\n",
    "    \n",
    "    results2 = []\n",
    "    results_onehots = []\n",
    "    results_loss = []\n",
    "    \n",
    "    for cnt in tqdm(range(len(results))):\n",
    "        results2 = results2 + results[cnt][0]\n",
    "        results_onehots = results_onehots + results[cnt][1]\n",
    "        results_loss = results_loss + results[cnt][2]\n",
    "        \n",
    "    loss = torch.mean(torch.Tensor(np.array(results_loss)).to(\"cuda:0\").reshape(-1))\n",
    "    \n",
    "    return np.array(results2).reshape(-1, longestword), np.array(results_onehots).reshape(len(npoutputs), -1), loss.cpu().detach().numpy()\n",
    "\n",
    "def translate_outputs_to_onehots_parallel(npoutputs, jump, embeddings, onehots):\n",
    "    zwrot = []\n",
    "    zwrotonehots = []\n",
    "    zwrotloss = []\n",
    "    \n",
    "    for x in npoutputs:\n",
    "        slowo = []\n",
    "        onehot = []\n",
    "        loss = []\n",
    "        for i in range(int(len(x)/jump)):\n",
    "            najblizszy = znajdz_najblizszy(x[i*jump:i*jump+jump-1], embeddings)\n",
    "            slowo.append(najblizszy[0])\n",
    "            onehot = onehot + onehots[najblizszy[0]]\n",
    "            loss.append(najblizszy[1])\n",
    "        \n",
    "        zwrotonehots.append(onehot)\n",
    "        zwrot.append(slowo)\n",
    "        zwrotloss.append(loss)\n",
    "        \n",
    "    return zwrot, zwrotonehots, zwrotloss\n",
    "\n",
    "\n",
    "def translate_outputs_to_onehots_on_cuda(npoutputs, dlugoscunikalne, embeddings, longestword, onehots):\n",
    "    zwrot = []\n",
    "    zwrotonehots = torch.Tensor([]).to(\"cuda:0\")\n",
    "    zwrotloss = []\n",
    "    \n",
    "    for cnt in tqdm(range(len(npoutputs))):\n",
    "        x = npoutputs[cnt]\n",
    "        slowo = []\n",
    "        onehot = torch.Tensor([]).to(\"cuda:0\")\n",
    "        loss = []\n",
    "        for i in range(int(len(x)/dlugoscunikalne)):\n",
    "            print(str(datetime.now()))\n",
    "            najblizszy = znajdz_najblizszy(x[i*dlugoscunikalne:i*dlugoscunikalne+dlugoscunikalne], embeddings)\n",
    "            print(str(datetime.now()))\n",
    "            slowo.append(najblizszy[0])\n",
    "            onehot = torch.cat((onehot, onehots[najblizszy[0]]), 0)\n",
    "            loss.append(najblizszy[1])\n",
    "        zwrotonehots = torch.cat((zwrotonehots, onehot), 0)\n",
    "        zwrot.append(slowo)\n",
    "        zwrotloss.append(loss)\n",
    "    zwrotonehots = zwrotonehots.reshape(len(npoutputs), -1)\n",
    "    \n",
    "    return zwrot, zwrotonehots, zwrotloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorFakeSeeds = torch.rand(iloscslow, 500).to(\"cuda:0\")\n",
    "TensorFakeIns = generator(TensorFakeSeeds).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = TensorFakeIns.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(xx[0])\n",
    "#xx = xx[:1]\n",
    "#with np.printoptions(threshold=np.inf):\n",
    "#    print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                        | 0/10000 [00:00<?, ?it/s]\n",
      "  0%|                                                                             | 1/10000 [00:07<20:11:00,  7.27s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-7d34dd30de40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtranslated1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranslated2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranslated_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorFakeIns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslated_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-55-d5407e9c8a11>\u001b[0m in \u001b[0;36mcuda\u001b[1;34m(vectors)\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mwynik\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;31m#string=string+list(embeddingscuda_chars.keys())[torch.argmax(wynik).item()]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mwyniki_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwynik\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[0monehots\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0monehots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monehotvectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddingscuda_chars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwynik\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "translated1, translated2, translated_loss = cuda(TensorFakeIns.reshape(10000, -1))\n",
    "print(translated_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorFakeTranslated = torch.Tensor(translated2).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 984])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorFakeTranslated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4755],\n",
       "        [0.4748],\n",
       "        [0.4748],\n",
       "        [0.4751],\n",
       "        [0.4755],\n",
       "        [0.4747],\n",
       "        [0.4744],\n",
       "        [0.4764],\n",
       "        [0.4747],\n",
       "        [0.4743],\n",
       "        [0.4761],\n",
       "        [0.4752],\n",
       "        [0.4752],\n",
       "        [0.4737],\n",
       "        [0.4742],\n",
       "        [0.4744],\n",
       "        [0.4770],\n",
       "        [0.4752],\n",
       "        [0.4747],\n",
       "        [0.4742],\n",
       "        [0.4760],\n",
       "        [0.4761],\n",
       "        [0.4748],\n",
       "        [0.4753],\n",
       "        [0.4756],\n",
       "        [0.4761],\n",
       "        [0.4755],\n",
       "        [0.4771],\n",
       "        [0.4755],\n",
       "        [0.4755],\n",
       "        [0.4755],\n",
       "        [0.4745],\n",
       "        [0.4756],\n",
       "        [0.4756],\n",
       "        [0.4758],\n",
       "        [0.4744],\n",
       "        [0.4768],\n",
       "        [0.4753],\n",
       "        [0.4763],\n",
       "        [0.4769],\n",
       "        [0.4755],\n",
       "        [0.4767],\n",
       "        [0.4755],\n",
       "        [0.4747],\n",
       "        [0.4757],\n",
       "        [0.4759],\n",
       "        [0.4756],\n",
       "        [0.4757],\n",
       "        [0.4753],\n",
       "        [0.4749],\n",
       "        [0.4751],\n",
       "        [0.4763],\n",
       "        [0.4761],\n",
       "        [0.4767],\n",
       "        [0.4766],\n",
       "        [0.4755],\n",
       "        [0.4749],\n",
       "        [0.4743],\n",
       "        [0.4764],\n",
       "        [0.4764],\n",
       "        [0.4750],\n",
       "        [0.4756],\n",
       "        [0.4744],\n",
       "        [0.4743],\n",
       "        [0.4751],\n",
       "        [0.4753],\n",
       "        [0.4769],\n",
       "        [0.4751],\n",
       "        [0.4763],\n",
       "        [0.4760],\n",
       "        [0.4769],\n",
       "        [0.4757],\n",
       "        [0.4748],\n",
       "        [0.4764],\n",
       "        [0.4761],\n",
       "        [0.4751],\n",
       "        [0.4776],\n",
       "        [0.4757],\n",
       "        [0.4762],\n",
       "        [0.4762],\n",
       "        [0.4749],\n",
       "        [0.4755],\n",
       "        [0.4760],\n",
       "        [0.4745],\n",
       "        [0.4750],\n",
       "        [0.4752],\n",
       "        [0.4755],\n",
       "        [0.4761],\n",
       "        [0.4767],\n",
       "        [0.4760],\n",
       "        [0.4750],\n",
       "        [0.4761],\n",
       "        [0.4757],\n",
       "        [0.4751],\n",
       "        [0.4773],\n",
       "        [0.4757],\n",
       "        [0.4754],\n",
       "        [0.4751],\n",
       "        [0.4770],\n",
       "        [0.4749]], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator(TensorFakeTranslated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerGenerator = optim.Adam(generator.parameters(), lr=1e-3)\n",
    "optimizerClassifier = optim.Adam(discriminator.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 4001.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$' 'D' 's' '-' 'x' 'U' 'q' 'w' 's' '.' 'L' 'I' 'D' '.' 'P']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "C:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2016: UserWarning: Using a target size (torch.Size([20000])) that is different to the input size (torch.Size([20000, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "C:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2016: UserWarning: Using a target size (torch.Size([10000])) that is different to the input size (torch.Size([10000, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>) tensor(9.5639, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w' 'D' 'D' '=' 'a' '=' 'P' 'p' '8' 'l' 'W' 'O' 'P' 'w' 'P']\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>) tensor(9.5819, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c' 'V' '0' '=' 'Q' 'N' 'l' 'p' '=' '.' 'L' 'I' 'P' 'a' 'W']\n",
      "tensor(0.6708, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>) tensor(9.6079, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w' 'm' 'D' '-' 'w' '/' 'b' 'n' '5' '-' 'W' 'O' '.' '.' '=']\n",
      "tensor(0.6520, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>) tensor(9.6475, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-8771716f299e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mxx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTensorFakeIns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtranslated1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranslated2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatureloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtranslate_outputs_to_onehots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlongestword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monehotvectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mTensorFakeTranslated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslated2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-b8e29e08ff75>\u001b[0m in \u001b[0;36mtranslate_outputs_to_onehots\u001b[1;34m(npoutputs, dlugoscunikalne, embeddings, longestword, onehots)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmultiprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslate_outputs_to_onehots_parallel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpoutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdlugoscunikalne\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monehots\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpodzial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mresults2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    TensorFakeSeeds = torch.rand(iloscslow, 500).to(\"cuda:0\")\n",
    "    TensorFakeIns = generator(TensorFakeSeeds).to(\"cuda:0\")\n",
    "    \n",
    "    xx = TensorFakeIns.cpu().detach().numpy()\n",
    "    translated1, translated2, featureloss = translate_outputs_to_onehots(xx, 400, embeddings, longestword, onehotvectors)\n",
    "    TensorFakeTranslated = torch.Tensor(translated2).to(\"cuda:0\")\n",
    "    \n",
    "    print(translated1[0])\n",
    "    \n",
    "    TensorReal = torch.Tensor(dataset_real).to(\"cuda:0\")\n",
    "    \n",
    "    TensorIns = torch.cat((TensorFakeTranslated.detach(), TensorReal), 0).to(\"cuda:0\")\n",
    "    \n",
    "    ## DISCRIMINATOR\n",
    "    discriminator.train()\n",
    "    optimizerClassifier.zero_grad()\n",
    "    \n",
    "    y_ = discriminator(TensorIns)\n",
    "    lossDiscriminator = criterion(y_, TensorOuts)\n",
    "    \n",
    "    lossDiscriminator.backward()\n",
    "    optimizerClassifier.step()\n",
    "    \n",
    "    ## GENERATOR\n",
    "#     TensorFakeSeeds = torch.rand(iloscslow, 500).to(\"cuda:0\")\n",
    "#     TensorFakeIns = generator(TensorFakeSeeds).to(\"cuda:0\")\n",
    "    \n",
    "#     xx = TensorFakeIns.cpu().detach().numpy()\n",
    "#     translated1, translated2, featureloss = translate_outputs_to_onehots(xx, 400, embeddings, longestword, onehotvectors)\n",
    "#     TensorFakeTranslated = torch.Tensor(translated2).to(\"cuda:0\")\n",
    "    \n",
    "    \n",
    "    generator.train()\n",
    "    optimizerGenerator.zero_grad()\n",
    "    \n",
    "    y_ = discriminator(TensorFakeTranslated)\n",
    "    lossGenerator = criterion(y_, TensorRealOuts) + (1-featureloss)*10\n",
    "    \n",
    "    lossGenerator.backward()\n",
    "    optimizerGenerator.step()\n",
    "    \n",
    "    #print(xx)\n",
    "    print(lossDiscriminator, lossGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
