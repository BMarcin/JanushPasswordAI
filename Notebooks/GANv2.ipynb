{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100\n",
      "['502945220', 'mazur5', 'fno47wnf', 'plujek', 'wsmbydgoszcz', 'wanda12', '18051974', 'blazenek', 'folwark', 'wntkp49', 'h0bb1t', '280470', 'ika1229', 'lidia1970', 'sabra23', 'gadzina', 'ppspike', 'kolec4', 'pawel6', 'zuza22', 'twistor', 'gapa', 'st2309', 'anita2009', 'fender4', 'pikulgks', 'smeagol', 'halina61', 'piksel', 'fargo6', 'raba', 'kasiakasia', 'kacper21', 'becha1', 'asica1972', 'rybaryba', 'aga1981', 'kjuik', 'kierasek', 'poter', 'ddsa12', 'panjanpan', 'monika1', 'queen05', 'nosferatum', 'marlon', 'lukis1', 'lysy1975', 'wnuczek', '100gram', 'pawel1979', 'kurt1970', 'art1011', '2102jozef', 'cewak1111', 'fenix67', 'lama641', 'okmn1bbb', 'anser80', 'orbit1', 'sirius', 'fikimiki', 'almaberta', 'klipo1', '892589', 'lewmar', 'mike99', 'yachtdragon', 'player', 'badura', 'opkny6', '26krisek', 'honcia', 'hiper5', 'pankracy', 'jacky67', 'chujnaryj', 'kambr66', 'dupersznyt', 'lisek1959', 'polimer1', 'pablosan1', 'bacman', 'sandiego', '0101ola', 'pukpuk1', 'mentel', 'warny76', '4862tummy', '324561', '26101988', 'getefumy', '1igoronet', 'susiec', 'gabi123', '12081992', '30051982', 'ewanorba', 'mp1805', 'malfoy1']\n"
     ]
    }
   ],
   "source": [
    "plik = open(\"../100k.txt\")\n",
    "\n",
    "slowka = [slowo.lower().replace(\"\\n\", \"\") for index,slowo in enumerate(plik)]\n",
    "slowa = []\n",
    "\n",
    "print(len(slowka))\n",
    "\n",
    "while len(slowa) < 100:\n",
    "    los = random.randint(0, len(slowka) - 1)\n",
    "    if slowka[los] not in slowa:\n",
    "        slowa.append(slowka[los])\n",
    "\n",
    "print(len(slowa))\n",
    "print(slowa[0:200])\n",
    "\n",
    "slowa = slowa[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unique(wektor):\n",
    "    return np.array(sorted(list({letter for word in wektor for letter in word})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one_hot_vectors(wektor):\n",
    "    return {wektor[cnt]:[1 if ii == cnt else 0 for ii in range(len(wektor))] for cnt in range(len(wektor))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_word_vector(word, onehotvectors):\n",
    "    return np.array([onehotvectors[letter] for letter in word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_longest_word(words):\n",
    "    longest = 0\n",
    "    \n",
    "    for word in words:\n",
    "        if len(word) > longest:\n",
    "            longest = len(word)\n",
    "            \n",
    "    return longest\n",
    "\n",
    "find_longest_word(slowa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420\n"
     ]
    }
   ],
   "source": [
    "def get_inputs_length(words, onehotvectors):\n",
    "    return find_longest_word(words)*len(onehotvectors[list(onehotvectors.keys())[0]])\n",
    "\n",
    "insy = get_inputs_length(slowa, make_one_hot_vectors(find_unique(slowa)))\n",
    "print(insy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs_by_characters_count(ch_count, onehotvectors):\n",
    "    return ch_count*len(onehotvectors[list(onehotvectors.keys())[0]])\n",
    "\n",
    "#insy = get_inputs_by_characters_count(15, make_one_hot_vectors(find_unique(slowa)))\n",
    "#print(insy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_slowa(words, onehotvectors, wielkoscwejscia):\n",
    "    wielkosc_one_hota = len(onehotvectors[list(onehotvectors.keys())[0]])\n",
    "    \n",
    "    zwrot = []\n",
    "    \n",
    "    for slowo in words:\n",
    "        builded = np.array(make_word_vector(slowo, onehotvectors))\n",
    "        builded = builded.reshape(-1)\n",
    "        braki = wielkoscwejscia - len(builded)\n",
    "        \n",
    "        wektor = np.concatenate((builded,np.array([0 for __ in range(braki)])), axis=0)\n",
    "        zwrot.append(wektor)\n",
    "    return np.array(zwrot)\n",
    "    \n",
    "#build_slowa(words, make_one_hot_vectors(find_unique(words)), 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ins, outs):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.fc_in = nn.Linear(in_features=ins, out_features=2000)\n",
    "        self.fc_h1 = nn.Linear(in_features=2000, out_features=2000)\n",
    "        self.fc_h2 = nn.Linear(in_features=2000, out_features=3000)\n",
    "        self.fc_h3 = nn.Linear(in_features=3000, out_features=4000)\n",
    "        self.fc_h4 = nn.Linear(in_features=4000, out_features=2000)\n",
    "        self.fc_h5 = nn.Linear(in_features=2000, out_features=500)\n",
    "        self.fc_h6 = nn.Linear(in_features=500, out_features=300)\n",
    "        self.fc_h7 = nn.Linear(in_features=300, out_features=300)\n",
    "        self.fc_out = nn.Linear(in_features=300, out_features=outs)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        self.activation2 = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc_in(x)\n",
    "        # x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_h1(x)\n",
    "        # x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_h2(x)\n",
    "        # x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_h3(x)\n",
    "        # x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_h4(x)\n",
    "        # x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_h5(x)\n",
    "        # x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_h6(x)\n",
    "        # x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_h7(x)\n",
    "        x = self.activation2(x)\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        #x = self.activation2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, ins, outs):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.fc_in = nn.Linear(in_features=ins, out_features=1000)\n",
    "        self.fc_h1 = nn.Linear(in_features=1000, out_features=1000)\n",
    "        self.fc_h2 = nn.Linear(in_features=1000, out_features=1000)\n",
    "        self.fc_h3 = nn.Linear(in_features=1000, out_features=1000)\n",
    "        self.fc_out = nn.Linear(in_features=1000, out_features=outs)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        self.activation2 = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        inp = x\n",
    "        \n",
    "        x = self.fc_in(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_h1(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_h2(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_h3(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        x = self.activation2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.xavier_normal(m.weight.data, 1.0, 0.002)\n",
    "        #nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x219faeed0b0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manualSeed = 1001\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 420])\n",
      "torch.Size([100, 420])\n",
      "torch.Size([200, 420])\n"
     ]
    }
   ],
   "source": [
    "TensorRealOuts = torch.full((len(slowa), insy), 1, requires_grad=False).float().to(\"cuda:0\")\n",
    "TensorFakeOuts = torch.full((len(slowa), insy), 0, requires_grad=False).float().to(\"cuda:0\")\n",
    "\n",
    "TensorOuts = torch.cat((TensorRealOuts, TensorFakeOuts), 0)\n",
    "\n",
    "print(TensorRealOuts.shape)\n",
    "print(TensorFakeOuts.shape)\n",
    "\n",
    "print(TensorOuts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "randoms = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(randoms, insy).to(\"cuda:0\")\n",
    "classifier = Classifier(insy, insy).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (fc_in): Linear(in_features=420, out_features=1000, bias=True)\n",
       "  (fc_h1): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "  (fc_h2): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "  (fc_h3): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "  (fc_out): Linear(in_features=1000, out_features=420, bias=True)\n",
       "  (activation): ReLU()\n",
       "  (activation2): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.apply(weights_init)\n",
    "classifier.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "optimizerGenerator = optim.Adam(generator.parameters(), lr=1e-4)\n",
    "optimizerClassifier = optim.Adam(classifier.parameters(), lr=1e-4)\n",
    "\n",
    "print(optimizerGenerator)\n",
    "print(optimizerClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCELoss()\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "print(criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeneratorLosses = []\n",
    "ClassifierLosses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6932, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>) tensor(0.6944, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>) tensor(13.9950, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>) tensor(59.9472, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>) tensor(59.9472, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-3b4ec7261145>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mTensorRealIns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_slowa\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslowa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmake_one_hot_vectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslowa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minsy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mTensorSeeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslowa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandoms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mTensorFakeIns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorSeeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(30000):\n",
    "    TensorRealIns = torch.tensor(build_slowa(slowa, make_one_hot_vectors(find_unique(slowa)), insy)).float().to(\"cuda:0\")\n",
    "    TensorSeeds = torch.rand(len(slowa), randoms, requires_grad=False).float().to(\"cuda:0\")\n",
    "    TensorFakeIns = generator(TensorSeeds)\n",
    "\n",
    "    TensorIns = torch.cat((TensorRealIns, TensorFakeIns.detach()), 0)\n",
    "    \n",
    "    classifier.train()\n",
    "    optimizerClassifier.zero_grad()\n",
    "    \n",
    "    y_ = classifier(TensorIns)\n",
    "    lossClassifier = criterion(y_, TensorOuts)\n",
    "    \n",
    "    lossClassifier.backward()\n",
    "    optimizerClassifier.step()\n",
    "    \n",
    "    generator.train()\n",
    "    optimizerGenerator.zero_grad()\n",
    "\n",
    "    y_ = classifier(TensorFakeIns)\n",
    "    lossGenerator = criterion(y_, TensorRealOuts)\n",
    "\n",
    "    lossGenerator.backward()\n",
    "    optimizerGenerator.step()\n",
    "\n",
    "    GeneratorLosses.append(lossGenerator)\n",
    "    ClassifierLosses.append(lossClassifier)\n",
    "    \n",
    "#     if lossGenerator < 0.2:\n",
    "#         break\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        print(lossClassifier, lossGenerator)\n",
    "        #print(TensorSeeds)\n",
    "        #print(TensorFakeIns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots()\n",
    "ax.plot([x for x in range(len(GeneratorLosses))], GeneratorLosses, \".\", [x for x in range(len(GeneratorLosses))], ClassifierLosses, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
