{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plikembd = open(\"../embeddings_small.txt\")\n",
    "\n",
    "embeddingscuda_chars = {}\n",
    "embeddingscuda_chars['ðŸˆ³'] = 0\n",
    "\n",
    "#embeddingscuda = torch.tensor([]).to(\"cuda:0\")\n",
    "#embeddingscuda =  torch.cat((embeddingscuda, torch.zeros((400)).to(\"cuda:0\")), 0)\n",
    "\n",
    "#print(embeddingscuda.shape)\n",
    "\n",
    "for cnt, line in enumerate(plikembd.readlines()):\n",
    "    exp1 = line.replace(\"\\n\", \"\").split(\":\")\n",
    "    \n",
    "    znak = exp1[0]\n",
    "    #embedding = torch.tensor([float(liczba) for liczba in exp1[1].replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\",\\t\")[:-1]]).to(\"cuda:0\")\n",
    "    \n",
    "    embeddingscuda_chars[znak] = cnt+1\n",
    "   # embeddingscuda = torch.cat((embeddingscuda, embedding), 0)\n",
    "\n",
    "#embeddingscuda = embeddingscuda.reshape(82, -1)\n",
    "\n",
    "#print(embeddingscuda.shape)\n",
    "#print(embeddingscuda[embeddingscuda_chars['a']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abmicro', '527579', 'agro2011', 'nakamichi', 'dugant', '29082009', 'hannah1', 'ma12po', '580813', 'lukasz4', 'kriket', 'werohaze', 'dron14121987', 'pinot1', 'maria59', 'moltrex', 'kilim', 'Zabeczka', '7937', '7maluszek', 'gacek16', 'ruleta1', '17Cyprian', 'maj2006', 'o2skarek', 'anno01', 'gusciol', 'gumis1', 'malaz11', 'watomzon', 'rumianek', 'neoisp', 'zsofie', 'zipera', '141084', 'ultraboy', '110567', 'anbog', 'troyd34', 'roxboro', 'werunia', 'misiokrzysio', 'hydra6', 'grzes10', 'kakigewy', 'filip98', '20021970', 'natka777', 'patricia', 'polisnova', 'miko20', 'prj2501', 'grobian1', '1972ml', 'robo21101967', 'jw17061958', 'gregordj', 'insko2000', 'maclear', 'zl060374', 'asia7', 'misiu777', 'varius2', 'lgflatron', 'rele1', '130178', 'centrala', 'filoman', '41karat2', '84jaysinner', 'agatina', 'ambasada', 'maly17', 'goszkam', '1branka', 'dasti', 'petro111', '070165', '20111965', 'triforce', 'bogumil1', 'anna3005', 'dron10011001', 'santaclara', 'pas2526', '11011975', 'rest12', 'j87neo', 'limak44', 'dark72', '258447', 'sk8000', '110871', 'wolf1111', 'arek1967', '24011959', 'kataga1', 'arek456', 'tokaj', 'platanowa']\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "polskie = open(\"../100k.txt\", encoding='utf8')\n",
    "slowa = [slowo.replace(\"\\n\", \"\") for slowo in polskie.readlines()]\n",
    "polskie.close()\n",
    "print(slowa[:100])\n",
    "print(len(slowa))\n",
    "slowa = slowa[:13000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'm', 'i', 'c', 'r', 'o', '5', '2', '7', '9', 'g', '0', '1', 'n', 'k', 'h', 'd', 'u', 't', '8', 'p', '3', 'l', 's', 'z', '4', 'e', 'w', 'x', 'Z', '6', 'C', 'y', 'j', 'f', 'v', 'F', 'P', 'R', 'O', 'T', 'A', 'X', 'L', 'E', 'S', 'I', 'K', 'N', 'D', 'M', 'q', 'H', 'U', 'J', 'Q', 'G', 'W', 'B', 'V', 'Y', '@', '.', '#', '!', ';', '*', '`']\n",
      "15\n",
      "69\n"
     ]
    }
   ],
   "source": [
    "longestword = 0\n",
    "\n",
    "unikalneznaki = []\n",
    "for slowo in slowa:\n",
    "    for literka in slowo:\n",
    "        if literka not in unikalneznaki:\n",
    "            unikalneznaki.append(literka)\n",
    "    if len(slowo) > longestword:\n",
    "        longestword = len(slowo)\n",
    "            \n",
    "print(unikalneznaki)\n",
    "print(longestword)\n",
    "print(len(unikalneznaki))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ðŸˆ³', ' ', '!', '#', '$', '%', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ';', '=', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "print(list(embeddingscuda_chars.keys()))\n",
    "print(len(list(embeddingscuda_chars.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "82\n",
      "82\n",
      "{'ðŸˆ³': 0, ' ': 1, '!': 2, '#': 3, '$': 4, '%': 5, '*': 6, '+': 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ';': 22, '=': 23, '@': 24, 'A': 25, 'B': 26, 'C': 27, 'D': 28, 'E': 29, 'F': 30, 'G': 31, 'H': 32, 'I': 33, 'J': 34, 'K': 35, 'L': 36, 'M': 37, 'N': 38, 'O': 39, 'P': 40, 'Q': 41, 'R': 42, 'S': 43, 'T': 44, 'U': 45, 'V': 46, 'W': 47, 'X': 48, 'Y': 49, 'Z': 50, '[': 51, ']': 52, '^': 53, '_': 54, '`': 55, 'a': 56, 'b': 57, 'c': 58, 'd': 59, 'e': 60, 'f': 61, 'g': 62, 'h': 63, 'i': 64, 'j': 65, 'k': 66, 'l': 67, 'm': 68, 'n': 69, 'o': 70, 'p': 71, 'q': 72, 'r': 73, 's': 74, 't': 75, 'u': 76, 'v': 77, 'w': 78, 'x': 79, 'y': 80, 'z': 81}\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "onehotvectors = {}\n",
    "onehotvectorsindexed = torch.tensor([]).to(\"cuda:0\")\n",
    "klasyid = {}\n",
    "\n",
    "for cnt, litera in enumerate(list(embeddingscuda_chars.keys())):\n",
    "    vector = [0 for __ in range(len(embeddingscuda_chars.keys()))]\n",
    "    vector[cnt] = 1\n",
    "    onehotvectors[litera] = torch.Tensor(vector).to(\"cuda:0\")\n",
    "    # onehotvectorsindexed.append(onehotvectors[litera])\n",
    "    onehotvectorsindexed = torch.cat((onehotvectorsindexed, onehotvectors[litera]), 0)\n",
    "    \n",
    "    klasyid[litera] = cnt\n",
    "    \n",
    "onehotvectorsindexed = onehotvectorsindexed.reshape(len(onehotvectors), -1)\n",
    "    \n",
    "print(len(onehotvectors))\n",
    "print(len(onehotvectors['ðŸˆ³']))\n",
    "print(len(klasyid))\n",
    "print(klasyid)\n",
    "print(onehotvectorsindexed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "print(onehotvectors['ðŸˆ³'])\n",
    "print(len(onehotvectors['ðŸˆ³']))\n",
    "\n",
    "dlugoschotvectora = len(onehotvectors['ðŸˆ³'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilosc wejsc dyskryminatora: 1230\n"
     ]
    }
   ],
   "source": [
    "print(\"ilosc wejsc dyskryminatora: \" + str(dlugoschotvectora * longestword))\n",
    "#print(\"ilosc wyjsc generatora: \" + str(len(embeddingscuda[0]) * longestword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13000/13000 [04:13<00:00, 51.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13000, 1230])\n"
     ]
    }
   ],
   "source": [
    "dataset_real = torch.Tensor([]).to(\"cuda:0\")\n",
    "iloscslow = 0\n",
    "\n",
    "pusty = torch.zeros(len(embeddingscuda_chars.keys())).to(\"cuda:0\")\n",
    "\n",
    "for cnt in tqdm(range(len(slowa))):\n",
    "    slowo = slowa[cnt]\n",
    "    for index in range(longestword):\n",
    "        if index<len(slowo):\n",
    "            dataset_real = torch.cat((dataset_real, onehotvectors[slowo[index]]), 0)\n",
    "        else:\n",
    "            dataset_real = torch.cat((dataset_real, pusty), 0)\n",
    "    iloscslow = iloscslow + 1\n",
    "\n",
    "dataset_real = dataset_real.reshape(iloscslow, -1)\n",
    "\n",
    "print(dataset_real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()     \n",
    "        \n",
    "        self.fc_in = nn.Linear(1230, 1000)\n",
    "        self.fc_h1 = nn.Linear(1000, 600)\n",
    "        self.fc_h2 = nn.Linear(600, 100)\n",
    "        self.fc_h3 = nn.Linear(100, 20)\n",
    "#         self.fc_h4 = nn.Linear(100, 50)\n",
    "        #self.fc_h5 = nn.Linear(200, 20)\n",
    "        self.fc_out = nn.Linear(20, 1)\n",
    "        \n",
    "    def forward(self, x):      \n",
    "        x = self.fc_in(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        x = self.fc_h1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        x = self.fc_h2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        x = self.fc_h3(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "#         x = self.fc_h4(x)\n",
    "#         x = F.relu(x)\n",
    "        \n",
    "#         x = self.fc_h5(x)\n",
    "#         x = F.leaky_relu(x)\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.fc_in = nn.Linear(10, 1000)\n",
    "        self.bn1 = nn.BatchNorm1d(1000)\n",
    "        self.fc_h1 = nn.Linear(1000, 1000)\n",
    "        self.bn2 = nn.BatchNorm1d(1000)\n",
    "        self.fc_h2 = nn.Linear(1000, 1000)\n",
    "        self.bn3 = nn.BatchNorm1d(1000)\n",
    "        self.fc_h3 = nn.Linear(1000, 1000)\n",
    "        self.bn4 = nn.BatchNorm1d(1000)\n",
    "        self.fc_h4 = nn.Linear(1000, 1000)\n",
    "        self.bn5 = nn.BatchNorm1d(1000)\n",
    "        self.fc_out = nn.Linear(1000, 1230)\n",
    "        \n",
    "        self.activation1 = nn.PReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.drop = nn.Dropout(p=0.4)\n",
    "        \n",
    "        self.p1 = torch.tensor([x for x in range(82)]).to(\"cuda:0\")\n",
    "        self.p2 = torch.tensor([x for x in range(82, 164)]).to(\"cuda:0\")\n",
    "        self.p3 = torch.tensor([x for x in range(164, 246)]).to(\"cuda:0\")\n",
    "        self.p4 = torch.tensor([x for x in range(246, 328)]).to(\"cuda:0\")\n",
    "        self.p5 = torch.tensor([x for x in range(328, 410)]).to(\"cuda:0\")\n",
    "        self.p6 = torch.tensor([x for x in range(410, 492)]).to(\"cuda:0\")\n",
    "        self.p7 = torch.tensor([x for x in range(492, 574)]).to(\"cuda:0\")\n",
    "        self.p8 = torch.tensor([x for x in range(574, 656)]).to(\"cuda:0\")\n",
    "        self.p9 = torch.tensor([x for x in range(656, 738)]).to(\"cuda:0\")\n",
    "        self.p10 = torch.tensor([x for x in range(738, 820)]).to(\"cuda:0\")\n",
    "        self.p11 = torch.tensor([x for x in range(820, 902)]).to(\"cuda:0\")\n",
    "        self.p12 = torch.tensor([x for x in range(902, 984)]).to(\"cuda:0\")\n",
    "        self.p13 = torch.tensor([x for x in range(984, 1066)]).to(\"cuda:0\")\n",
    "        self.p14 = torch.tensor([x for x in range(1066, 1148)]).to(\"cuda:0\")\n",
    "        self.p15 = torch.tensor([x for x in range(1148, 1230)]).to(\"cuda:0\")\n",
    "        \n",
    "        #         x1 = torch.argmax(self.softmax(x[:,0:82]), dim=1)\n",
    "#         x2 = torch.argmax(self.softmax(x[:,82:164]), dim=1)\n",
    "#         x3 = torch.argmax(self.softmax(x[:,164:246]), dim=1)\n",
    "#         x4 = torch.argmax(self.softmax(x[:,246:328]), dim=1)\n",
    "#         x5 = torch.argmax(self.softmax(x[:,328:410]), dim=1)\n",
    "#         x6 = torch.argmax(self.softmax(x[:,410:492]), dim=1)\n",
    "#         x7 = torch.argmax(self.softmax(x[:,492:574]), dim=1)\n",
    "#         x8 = torch.argmax(self.softmax(x[:,574:656]), dim=1)\n",
    "#         x9 = torch.argmax(self.softmax(x[:,656:738]), dim=1)\n",
    "#         x10 = torch.argmax(self.softmax(x[:,738:820]), dim=1)\n",
    "#         x11 = torch.argmax(self.softmax(x[:,820:902]), dim=1)\n",
    "#         x12 = torch.argmax(self.softmax(x[:,902:984]), dim=1)\n",
    "#         x13 = torch.argmax(self.softmax(x[:,984:1066]), dim=1)\n",
    "#         x14 = torch.argmax(self.softmax(x[:,1066:1148]), dim=1)\n",
    "#         x15 = torch.argmax(self.softmax(x[:,1148:1230]), dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.fc_in (x)\n",
    "        x1 = F.relu(x)\n",
    "        \n",
    "        x1 = self.bn1(x1)\n",
    "        \n",
    "        x = self.fc_h1(x1)\n",
    "        x2 = F.relu(x)\n",
    "        \n",
    "        x2 = self.bn2(x2)\n",
    "        \n",
    "        x = x1 * x2\n",
    "        \n",
    "        #x = self.drop(x)\n",
    "          \n",
    "        x = self.fc_h2(x)\n",
    "        x3 = F.relu(x)\n",
    "        \n",
    "        x3 = self.bn1(x3)\n",
    "        \n",
    "        x = x1 * x2 * x3\n",
    "        \n",
    "        #x = self.drop(x)\n",
    "        \n",
    "        x = self.fc_h3(x)\n",
    "        x4 = F.relu(x)\n",
    "        \n",
    "        x4 = self.bn1(x4)\n",
    "        \n",
    "        x = x1 * x2 * x3 * x4\n",
    "        \n",
    "        #x = self.drop(x)\n",
    "        \n",
    "        x = self.fc_h4(x)\n",
    "        x5 = F.relu(x)\n",
    "        \n",
    "        x5 = self.bn1(x5)\n",
    "        \n",
    "        x = x1 * x2 + x3 * x4 * x5\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        \n",
    "        x1 = torch.argmax(self.softmax(torch.index_select(x, 1, self.p1)), dim=1)\n",
    "        x2 = torch.argmax(self.softmax(torch.index_select(x, 1, self.p2)), dim=1)\n",
    "        x3 = torch.argmax(self.softmax(torch.index_select(x, 1, self.p3)), dim=1)\n",
    "        x4 = torch.argmax(self.softmax(torch.index_select(x, 1, self.p4)), dim=1)\n",
    "        x5 = torch.argmax(self.softmax(torch.index_select(x, 1, self.p5)), dim=1)\n",
    "        x6 = torch.argmax(self.softmax(torch.index_select(x, 1, self.p6)), dim=1)\n",
    "        x7 = torch.argmax(self.softmax(torch.index_select(x, 1, self.p7)), dim=1)\n",
    "        x8 = torch.argmax(self.softmax(torch.index_select(x, 1, self.p8)), dim=1)\n",
    "        x9 = torch.argmax(self.softmax(torch.index_select(x, 1, self.p9)), dim=1)\n",
    "        x10 = torch.argmax(self.softmax(torch.index_select(x, 1, self.p10)), dim=1)\n",
    "        x11 = torch.argmax(self.softmax(torch.index_select(x, 1, self.p11)), dim=1)\n",
    "        x12 = torch.argmax(self.softmax(torch.index_select(x, 1, self.p12)), dim=1)\n",
    "        x13 = torch.argmax(self.softmax(torch.index_select(x, 1, self.p13)), dim=1)\n",
    "        x14 = torch.argmax(self.softmax(torch.index_select(x, 1, self.p14)), dim=1)\n",
    "        x15 = torch.argmax(self.softmax(torch.index_select(x, 1, self.p15)), dim=1)\n",
    "        \n",
    "        \n",
    "        ##todo przyspieszyÄ‡\n",
    "        \n",
    "        \n",
    "        #tt = torch.tensor([[-1], [0, 1,2,3,4,5,6]])\n",
    "        \n",
    "#         x1 = torch.argmax(self.softmax(x[:,0:82]), dim=1)\n",
    "#         x2 = torch.argmax(self.softmax(x[:,82:164]), dim=1)\n",
    "#         x3 = torch.argmax(self.softmax(x[:,164:246]), dim=1)\n",
    "#         x4 = torch.argmax(self.softmax(x[:,246:328]), dim=1)\n",
    "#         x5 = torch.argmax(self.softmax(x[:,328:410]), dim=1)\n",
    "#         x6 = torch.argmax(self.softmax(x[:,410:492]), dim=1)\n",
    "#         x7 = torch.argmax(self.softmax(x[:,492:574]), dim=1)\n",
    "#         x8 = torch.argmax(self.softmax(x[:,574:656]), dim=1)\n",
    "#         x9 = torch.argmax(self.softmax(x[:,656:738]), dim=1)\n",
    "#         x10 = torch.argmax(self.softmax(x[:,738:820]), dim=1)\n",
    "#         x11 = torch.argmax(self.softmax(x[:,820:902]), dim=1)\n",
    "#         x12 = torch.argmax(self.softmax(x[:,902:984]), dim=1)\n",
    "#         x13 = torch.argmax(self.softmax(x[:,984:1066]), dim=1)\n",
    "#         x14 = torch.argmax(self.softmax(x[:,1066:1148]), dim=1)\n",
    "#         x15 = torch.argmax(self.softmax(x[:,1148:1230]), dim=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         x3 = torch.argmax(self.softmax(x[:][164:246]))\n",
    "#         x4 = torch.argmax(self.softmax(x[:][246:328]))\n",
    "#         x5 = torch.argmax(self.softmax(x[:][328:410]))\n",
    "#         x6 = torch.argmax(self.softmax(x[:][410:492]))\n",
    "#         x7 = torch.argmax(self.softmax(x[:][492:574]))\n",
    "#         x8 = torch.argmax(self.softmax(x[:][574:656]))\n",
    "#         x9 = torch.argmax(self.softmax(x[:][656:738]))\n",
    "#         x10 = torch.argmax(self.softmax(x[:][738:820]))\n",
    "#         x11 = torch.argmax(self.softmax(x[:][820:902]))\n",
    "#         x12 = torch.argmax(self.softmax(x[:][902:984]))\n",
    "#         x13 = torch.argmax(self.softmax(x[:][984:1066]))\n",
    "#         x14 = torch.argmax(self.softmax(x[:][1066:1148]))\n",
    "#         x15 = torch.argmax(self.softmax(x[:][1148:1230]))\n",
    "        \n",
    "        \n",
    "        return torch.cat((x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13, x14, x15), dim=0).reshape(len(x), -1)\n",
    "        #return torch.tensor([x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13, x14, x15])\n",
    "        #return torch.argmax(self.softmax(x[:,0:82]), dim=1)\n",
    "        \n",
    "        #return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator().to(\"cuda:0\")\n",
    "generator = Generator().to(\"cuda:0\")\n",
    "\n",
    "TensorReal = dataset_real\n",
    "\n",
    "TensorFakeOuts = torch.zeros(len(dataset_real)).to(\"cuda:0\")\n",
    "TensorRealOuts = torch.ones(len(dataset_real)).to(\"cuda:0\")\n",
    "\n",
    "TensorOuts = torch.cat((TensorFakeOuts, TensorRealOuts), 0).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "criterion_segment = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorFakeSeeds = torch.rand(iloscslow, 10).to(\"cuda:0\")\n",
    "TensorFakeIns = generator(TensorFakeSeeds[0:2]).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 15])\n",
      "tensor([[49, 49, 59, 59, 57, 57, 11, 11,  8,  8,  6,  6, 57, 57, 61],\n",
      "        [61,  5,  5, 13, 13, 55, 55, 47, 47, 33, 33, 43, 43, 56, 56]],\n",
      "       device='cuda:0')\n",
      "tensor([49, 49, 59, 59, 57, 57, 11, 11,  8,  8,  6,  6, 57, 57, 61],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(TensorFakeIns.shape)\n",
    "print(TensorFakeIns)\n",
    "print(TensorFakeIns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(onehotvectorsindexed[TensorFakeIns[0][0].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 82])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.tensor([x for x in range(82)]).to(\"cuda:0\")\n",
    "torch.index_select(TensorFakeIns, 1, indices).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputtoonehots(TensorFakes, printletters=False):\n",
    "#     zwrot = torch.tensor([]).to(\"cuda:0\")\n",
    "#     for cnt in range(len(TensorFakes)):\n",
    "#         zwrot = torch.cat(\n",
    "#             (\n",
    "#                 zwrot,\n",
    "#                 onehotvectorsindexed[fake[0].item()],\n",
    "#                 onehotvectorsindexed[fake[1].item()],\n",
    "#                 onehotvectorsindexed[fake[2].item()],\n",
    "#                 onehotvectorsindexed[fake[3].item()],\n",
    "#                 onehotvectorsindexed[fake[4].item()],\n",
    "#                 onehotvectorsindexed[fake[5].item()],\n",
    "#                 onehotvectorsindexed[fake[6].item()],\n",
    "#                 onehotvectorsindexed[fake[7].item()],\n",
    "#                 onehotvectorsindexed[fake[8].item()],\n",
    "#                 onehotvectorsindexed[fake[9].item()],\n",
    "#                 onehotvectorsindexed[fake[10].item()],\n",
    "#                 onehotvectorsindexed[fake[11].item()],\n",
    "#                 onehotvectorsindexed[fake[12].item()],\n",
    "#                 onehotvectorsindexed[fake[13].item()],\n",
    "#                 onehotvectorsindexed[fake[14].item()],\n",
    "#             )\n",
    "#         , dim=0)\n",
    "#         zwrot = torch.cat(\n",
    "#             (\n",
    "#                 zwrot,\n",
    "#                 torch.index_select(onehotvectorsindexed, 0, TensorFakes[cnt])\n",
    "#             ), dim=0)\n",
    "\n",
    "    if printletters:\n",
    "        fake = TensorFakes[0]\n",
    "        print(list(embeddingscuda_chars.keys())[fake[0].item()],\n",
    "             list(embeddingscuda_chars.keys())[fake[1].item()],\n",
    "             list(embeddingscuda_chars.keys())[fake[2].item()],\n",
    "             list(embeddingscuda_chars.keys())[fake[3].item()],\n",
    "             list(embeddingscuda_chars.keys())[fake[4].item()],\n",
    "             list(embeddingscuda_chars.keys())[fake[5].item()],\n",
    "             list(embeddingscuda_chars.keys())[fake[6].item()],\n",
    "             list(embeddingscuda_chars.keys())[fake[7].item()],\n",
    "             list(embeddingscuda_chars.keys())[fake[8].item()],\n",
    "             list(embeddingscuda_chars.keys())[fake[9].item()],\n",
    "             list(embeddingscuda_chars.keys())[fake[10].item()],\n",
    "             list(embeddingscuda_chars.keys())[fake[11].item()],\n",
    "             list(embeddingscuda_chars.keys())[fake[12].item()],\n",
    "             list(embeddingscuda_chars.keys())[fake[13].item()],\n",
    "             list(embeddingscuda_chars.keys())[fake[14].item()])\n",
    "\n",
    "    zwrot = torch.index_select(onehotvectorsindexed, 0, TensorFakes.reshape(-1))\n",
    "    \n",
    "    return zwrot.reshape(len(TensorFakes), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1230])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = outputtoonehots(TensorFakeIns[:2]); xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10., device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(TensorFakeIns[:50].gt(1).float().reshape(-1), 0)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myloss(Fakes):\n",
    "    return torch.mean(Fakes.gt(1).float().reshape(-1), 0)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerGenerator = optim.Adam(generator.parameters(), lr=3e-3)\n",
    "optimizerClassifier = optim.Adam(discriminator.parameters(), lr=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 49.63 MiB (GPU 0; 3.00 GiB total capacity; 1.64 GiB already allocated; 14.10 MiB free; 113.39 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-d2000f329482>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mTensorFakeSeeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miloscslow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mTensorFakeIns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorFakeSeeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprinted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-cb7b14e5a416>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mx5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx3\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 49.63 MiB (GPU 0; 3.00 GiB total capacity; 1.64 GiB already allocated; 14.10 MiB free; 113.39 MiB cached)"
     ]
    }
   ],
   "source": [
    "for epoch in range(20000):\n",
    "    TensorFakeSeeds = torch.rand(iloscslow, 10).to(\"cuda:0\")\n",
    "    TensorFakeIns = generator(TensorFakeSeeds).to(\"cuda:0\")\n",
    "    \n",
    "    printed = False\n",
    "    if epoch%2==0:\n",
    "        printed = True\n",
    "    \n",
    "    Fakes = outputtoonehots(TensorFakeIns, printletters=printed)\n",
    "    \n",
    "    TensorIns = torch.cat((Fakes, TensorReal), 0).to(\"cuda:0\")\n",
    "    \n",
    "    ## DISCRIMINATOR\n",
    "    discriminator.train()\n",
    "    optimizerClassifier.zero_grad()\n",
    "    \n",
    "    y1_ = discriminator(TensorIns)\n",
    "    lossDiscriminator = criterion(y1_, TensorOuts)\n",
    "    \n",
    "    lossDiscriminator.backward()\n",
    "    optimizerClassifier.step()\n",
    "    \n",
    "    \n",
    "    ## GENERATOR\n",
    "    generator.train()\n",
    "    optimizerGenerator.zero_grad()\n",
    "    \n",
    "    y2_ = discriminator(Fakes)\n",
    "    lossGenerator = (criterion(y2_, TensorRealOuts) + myloss(TensorFakeIns))\n",
    "    \n",
    "    lossGenerator.backward()\n",
    "    optimizerGenerator.step()\n",
    "    \n",
    "    if epoch%2==0:\n",
    "        print(\"Loss discriminator:\" + str(lossDiscriminator.item()), \"Loss generator:\" + str(lossGenerator.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
