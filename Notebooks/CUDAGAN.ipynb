{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400])\n",
      "torch.Size([82, 400])\n",
      "tensor([-0.1842972338,  0.1992288828, -0.1093217134,  0.0635560006,\n",
      "        -0.0170881711, -0.0069951965,  0.1790032834, -0.1581476331,\n",
      "         0.0322009474, -0.1496459693, -0.1595581025, -0.2537648678,\n",
      "         0.2232226729, -0.1215698719,  0.0059251408, -0.1644940972,\n",
      "         0.0264174044,  0.0696226805, -0.0749481246,  0.2048900872,\n",
      "        -0.0481871516, -0.1348041445,  0.1884992272, -0.0314494744,\n",
      "         0.1081886366,  0.0045932876, -0.1269595921,  0.1936095357,\n",
      "        -0.0679676980,  0.1462467760, -0.2293221653, -0.2348391116,\n",
      "        -0.1658135504, -0.0536651835,  0.0345649682, -0.0555758253,\n",
      "         0.1800168753, -0.1355556846,  0.0986127034, -0.0864410177,\n",
      "        -0.1333196312, -0.0306926053,  0.2023293376,  0.1658294201,\n",
      "         0.1575038880,  0.1013869643, -0.0837135166, -0.0609861165,\n",
      "        -0.1243505403, -0.0618062057, -0.0087015610, -0.1109482422,\n",
      "        -0.1424127370,  0.1705076247, -0.0412648059, -0.1866530329,\n",
      "         0.1705746651, -0.0454960205,  0.0511074215, -0.1814958006,\n",
      "         0.0312571451,  0.0023679240,  0.1567359865,  0.1214345321,\n",
      "         0.1875774860, -0.1155519187, -0.1487986147,  0.0846847817,\n",
      "        -0.1553875506,  0.1239548177,  0.1238240525,  0.1030294448,\n",
      "        -0.1249729469,  0.0957288370,  0.1068888679,  0.1004554108,\n",
      "         0.1896177530,  0.0751672834, -0.0123409629, -0.0072713750,\n",
      "        -0.1125810742,  0.1464326680, -0.0432669930,  0.1002970040,\n",
      "         0.1720880121, -0.1439751685,  0.1484931260, -0.0750802234,\n",
      "         0.1245075390,  0.1575208008,  0.0472818762,  0.1708101332,\n",
      "         0.1424195766, -0.2113518566,  0.1518024951,  0.1012588069,\n",
      "        -0.0948293880,  0.0880734175,  0.0028987343,  0.2490037680,\n",
      "        -0.1517948061,  0.2179073542,  0.1115292311, -0.0907436609,\n",
      "         0.0373055227,  0.1338036805,  0.0446807742,  0.0494914353,\n",
      "        -0.2003040314, -0.0165758971,  0.1906725913, -0.1125686616,\n",
      "         0.0837075040,  0.0787189752,  0.1161330193, -0.0904760137,\n",
      "        -0.2200971097,  0.1388819069,  0.2000113577,  0.0662657768,\n",
      "        -0.0767664090, -0.0759414434, -0.1551424116,  0.0764692724,\n",
      "         0.1699705720, -0.1184115931, -0.1102459058, -0.1875358224,\n",
      "        -0.0696347654,  0.0091158981, -0.0635609850, -0.1298705339,\n",
      "        -0.1130863652,  0.1928980798,  0.0196687635, -0.1482946724,\n",
      "         0.1796324104, -0.0572765842, -0.0930459797,  0.1370632946,\n",
      "        -0.0885020420, -0.0541497134, -0.0244223736,  0.1394562423,\n",
      "        -0.1150914058,  0.1048353016, -0.2776700556, -0.0062887603,\n",
      "         0.0435514413, -0.1757234782,  0.1874617785,  0.0973147750,\n",
      "         0.0489514396, -0.0719382167, -0.1697351038,  0.1430554092,\n",
      "         0.0192177109,  0.1406140029,  0.1027340665, -0.0372597240,\n",
      "         0.1868329346,  0.0916185975,  0.1726666093,  0.0728651732,\n",
      "         0.1129153222, -0.1677419543,  0.1660490781,  0.1553547531,\n",
      "        -0.1485620588, -0.0291875415,  0.0967422724, -0.1426796019,\n",
      "        -0.1801590472,  0.1073170677, -0.0307026878, -0.0640823022,\n",
      "        -0.0255387817,  0.1424802244,  0.0004050134,  0.0920248032,\n",
      "         0.0143009005,  0.1399734169,  0.1375159621,  0.0583447553,\n",
      "        -0.1298392266,  0.1625779867,  0.2700724602, -0.0049731066,\n",
      "         0.0533687323,  0.1339427382, -0.1611949503,  0.1461808085,\n",
      "         0.0875659809,  0.1031135619,  0.1906691343,  0.1570144594,\n",
      "         0.1205297783,  0.1688521951, -0.1290624142,  0.1077630520,\n",
      "         0.0646254569, -0.0102814827,  0.1897805631,  0.0730651394,\n",
      "        -0.0361849256, -0.2131652385, -0.1004962847, -0.0281383228,\n",
      "         0.1142958701,  0.3582850695, -0.0521302670,  0.0565140471,\n",
      "         0.1427058876,  0.0326559618, -0.1475312263,  0.2360350192,\n",
      "         0.0762174577,  0.1049004719, -0.0177720413,  0.0165965576,\n",
      "        -0.1699303985, -0.1306957453,  0.0217954274, -0.1758347750,\n",
      "        -0.0145670343, -0.0427457616, -0.1830043495, -0.1423098147,\n",
      "        -0.0442552604, -0.1996498257, -0.1549610943, -0.1192394048,\n",
      "        -0.0189614743,  0.1687261015, -0.1377387643,  0.1158430278,\n",
      "        -0.1168809235, -0.0595252439,  0.1422863752, -0.0726736933,\n",
      "        -0.0970197693, -0.1513723582, -0.0153689021,  0.1075288206,\n",
      "         0.0062753111, -0.0657496303,  0.1142629385, -0.1874541789,\n",
      "         0.1355450153, -0.1197057068,  0.0969110653,  0.1124221683,\n",
      "        -0.1598580629, -0.1999936551,  0.1559768468, -0.0135932276,\n",
      "         0.0698354617, -0.0378662422, -0.0273320470,  0.1686098427,\n",
      "         0.0638542548,  0.0868597031, -0.2574052811, -0.1108667031,\n",
      "         0.1787936836, -0.0970125794,  0.1467291713, -0.1019845307,\n",
      "        -0.1779254824,  0.1495919228,  0.2319046408, -0.0068741417,\n",
      "         0.1250005960,  0.1217587665,  0.0579981767, -0.1207496375,\n",
      "         0.1159732714,  0.1765701473,  0.0880894139,  0.0891111791,\n",
      "        -0.0511370264, -0.1724291742, -0.0651685894, -0.1133691743,\n",
      "         0.0261005946,  0.1822266430, -0.1386639923,  0.1091069654,\n",
      "         0.0469622687,  0.0981997624,  0.1842999160,  0.0152545795,\n",
      "         0.2312818617, -0.2560451925,  0.2024395615, -0.1238090470,\n",
      "         0.0606538616,  0.1952640712,  0.1311136633,  0.0081821000,\n",
      "        -0.1812462211, -0.1416241527,  0.1679642946,  0.1101941615,\n",
      "         0.1321880817, -0.1651239395,  0.1416729391, -0.0768660903,\n",
      "        -0.0916962326, -0.0775291026, -0.2172259390, -0.1380983442,\n",
      "         0.0925596729, -0.0876334459, -0.2041635662, -0.0396521129,\n",
      "        -0.0101271058,  0.0576047227,  0.1529120356,  0.0813933760,\n",
      "        -0.1099956483,  0.0344682857, -0.0813828111, -0.0637205914,\n",
      "        -0.1817055047, -0.0274054278,  0.2254342586,  0.2037117928,\n",
      "        -0.0709478110,  0.0082736313, -0.0607478879,  0.1292374283,\n",
      "        -0.0619269907, -0.1211330220, -0.0717913657, -0.1346032619,\n",
      "         0.0283130053,  0.0519250222,  0.1985547543, -0.1104769856,\n",
      "         0.0229423828,  0.0502811708, -0.1786527038, -0.1101744026,\n",
      "        -0.1502699554,  0.0042145052,  0.1003464609, -0.1421854645,\n",
      "         0.2305352092, -0.1077509522, -0.0847016275, -0.0700057745,\n",
      "         0.0919583738,  0.0947080180, -0.0742726102,  0.0602409802,\n",
      "         0.0123806819, -0.0902131498, -0.1669095159, -0.0799129456,\n",
      "         0.0454242714, -0.0129831648,  0.0325469524, -0.1643709987,\n",
      "        -0.0702609643,  0.0084340880,  0.1076420695,  0.2151346654,\n",
      "         0.2070665509, -0.1017798707,  0.0752904639, -0.1276532561,\n",
      "         0.2041089237, -0.1919434816,  0.0478103012, -0.0078700772,\n",
      "        -0.0243321322, -0.1665397882, -0.0519231334,  0.0806803480,\n",
      "         0.1152695641, -0.1654838473, -0.1136450171, -0.0383588187,\n",
      "        -0.1330948323, -0.1974440515, -0.1925254464,  0.0895201564,\n",
      "        -0.1270922720,  0.0431650355,  0.1176075265, -0.1642593443,\n",
      "        -0.1327029169,  0.0386101417,  0.0340109691,  0.1809563041,\n",
      "         0.0674237758,  0.0658109337,  0.2508264184,  0.1139955670],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "plikembd = open(\"../embeddings_small.txt\")\n",
    "\n",
    "embeddingscuda_chars = {}\n",
    "embeddingscuda_chars['ðŸˆ³'] = 0\n",
    "\n",
    "embeddingscuda = torch.tensor([]).to(\"cuda:0\")\n",
    "embeddingscuda =  torch.cat((embeddingscuda, torch.zeros((400)).to(\"cuda:0\")), 0)\n",
    "\n",
    "print(embeddingscuda.shape)\n",
    "\n",
    "for cnt, line in enumerate(plikembd.readlines()):\n",
    "    exp1 = line.replace(\"\\n\", \"\").split(\":\")\n",
    "    \n",
    "    znak = exp1[0]\n",
    "    embedding = torch.tensor([float(liczba) for liczba in exp1[1].replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\",\\t\")[:-1]]).to(\"cuda:0\")\n",
    "    \n",
    "    embeddingscuda_chars[znak] = cnt+1\n",
    "    embeddingscuda = torch.cat((embeddingscuda, embedding), 0)\n",
    "\n",
    "embeddingscuda = embeddingscuda.reshape(82, -1)\n",
    "\n",
    "print(embeddingscuda.shape)\n",
    "print(embeddingscuda[embeddingscuda_chars['a']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abmicro', '527579', 'agro2011', 'nakamichi', 'dugant', '29082009', 'hannah1', 'ma12po', '580813', 'lukasz4', 'kriket', 'werohaze', 'dron14121987', 'pinot1', 'maria59', 'moltrex', 'kilim', 'Zabeczka', '7937', '7maluszek', 'gacek16', 'ruleta1', '17Cyprian', 'maj2006', 'o2skarek', 'anno01', 'gusciol', 'gumis1', 'malaz11', 'watomzon', 'rumianek', 'neoisp', 'zsofie', 'zipera', '141084', 'ultraboy', '110567', 'anbog', 'troyd34', 'roxboro', 'werunia', 'misiokrzysio', 'hydra6', 'grzes10', 'kakigewy', 'filip98', '20021970', 'natka777', 'patricia', 'polisnova', 'miko20', 'prj2501', 'grobian1', '1972ml', 'robo21101967', 'jw17061958', 'gregordj', 'insko2000', 'maclear', 'zl060374', 'asia7', 'misiu777', 'varius2', 'lgflatron', 'rele1', '130178', 'centrala', 'filoman', '41karat2', '84jaysinner', 'agatina', 'ambasada', 'maly17', 'goszkam', '1branka', 'dasti', 'petro111', '070165', '20111965', 'triforce', 'bogumil1', 'anna3005', 'dron10011001', 'santaclara', 'pas2526', '11011975', 'rest12', 'j87neo', 'limak44', 'dark72', '258447', 'sk8000', '110871', 'wolf1111', 'arek1967', '24011959', 'kataga1', 'arek456', 'tokaj', 'platanowa']\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "polskie = open(\"../100k.txt\", encoding='utf8')\n",
    "slowa = [slowo.replace(\"\\n\", \"\") for slowo in polskie.readlines()]\n",
    "polskie.close()\n",
    "print(slowa[:100])\n",
    "print(len(slowa))\n",
    "slowa = slowa[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'm', 'i', 'c', 'r', 'o', '5', '2', '7', '9', 'g', '0', '1', 'n', 'k', 'h', 'd', 'u', 't', '8', 'p', '3', 'l', 's', 'z', '4', 'e', 'w', 'x', 'Z', '6', 'C', 'y', 'j', 'f', 'v', 'F', 'P', 'R', 'O', 'T', 'A', 'X', 'L', 'E', 'S', 'I', 'K', 'N', 'D', 'M', 'q', 'H', 'U', 'J', 'Q', 'G', 'W', 'B', 'V', 'Y', '@', '.', '#']\n",
      "15\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "longestword = 0\n",
    "\n",
    "unikalneznaki = []\n",
    "for slowo in slowa:\n",
    "    for literka in slowo:\n",
    "        if literka not in unikalneznaki:\n",
    "            unikalneznaki.append(literka)\n",
    "    if len(slowo) > longestword:\n",
    "        longestword = len(slowo)\n",
    "            \n",
    "print(unikalneznaki)\n",
    "print(longestword)\n",
    "print(len(unikalneznaki))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ðŸˆ³', ' ', '!', '#', '$', '%', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ';', '=', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "print(list(embeddingscuda_chars.keys()))\n",
    "print(len(list(embeddingscuda_chars.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "82\n",
      "82\n",
      "{'ðŸˆ³': 0, ' ': 1, '!': 2, '#': 3, '$': 4, '%': 5, '*': 6, '+': 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ';': 22, '=': 23, '@': 24, 'A': 25, 'B': 26, 'C': 27, 'D': 28, 'E': 29, 'F': 30, 'G': 31, 'H': 32, 'I': 33, 'J': 34, 'K': 35, 'L': 36, 'M': 37, 'N': 38, 'O': 39, 'P': 40, 'Q': 41, 'R': 42, 'S': 43, 'T': 44, 'U': 45, 'V': 46, 'W': 47, 'X': 48, 'Y': 49, 'Z': 50, '[': 51, ']': 52, '^': 53, '_': 54, '`': 55, 'a': 56, 'b': 57, 'c': 58, 'd': 59, 'e': 60, 'f': 61, 'g': 62, 'h': 63, 'i': 64, 'j': 65, 'k': 66, 'l': 67, 'm': 68, 'n': 69, 'o': 70, 'p': 71, 'q': 72, 'r': 73, 's': 74, 't': 75, 'u': 76, 'v': 77, 'w': 78, 'x': 79, 'y': 80, 'z': 81}\n"
     ]
    }
   ],
   "source": [
    "onehotvectors = {}\n",
    "klasyid = {}\n",
    "\n",
    "for cnt, litera in enumerate(list(embeddingscuda_chars.keys())):\n",
    "    vector = [0 for __ in range(len(embeddingscuda_chars.keys()))]\n",
    "    vector[cnt] = 1\n",
    "    onehotvectors[litera] = torch.Tensor(vector).to(\"cuda:0\")\n",
    "    \n",
    "    klasyid[litera] = cnt\n",
    "    \n",
    "print(len(onehotvectors))\n",
    "print(len(onehotvectors['ðŸˆ³']))\n",
    "print(len(klasyid))\n",
    "print(klasyid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "print(onehotvectors['ðŸˆ³'])\n",
    "print(len(onehotvectors['ðŸˆ³']))\n",
    "\n",
    "dlugoschotvectora = len(onehotvectors['ðŸˆ³'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilosc wejsc dyskryminatora: 1230\n",
      "ilosc wyjsc generatora: 6000\n"
     ]
    }
   ],
   "source": [
    "print(\"ilosc wejsc dyskryminatora: \" + str(dlugoschotvectora * longestword))\n",
    "print(\"ilosc wyjsc generatora: \" + str(len(embeddingscuda[0]) * longestword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:16<00:00, 294.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 1230])\n"
     ]
    }
   ],
   "source": [
    "dataset_real = torch.Tensor([]).to(\"cuda:0\")\n",
    "iloscslow = 0\n",
    "\n",
    "pusty = torch.zeros(len(embeddingscuda_chars.keys())).to(\"cuda:0\")\n",
    "\n",
    "for cnt in tqdm(range(len(slowa))):\n",
    "    slowo = slowa[cnt]\n",
    "    for index in range(longestword):\n",
    "        if index<len(slowo):\n",
    "            dataset_real = torch.cat((dataset_real, onehotvectors[slowo[index]]), 0)\n",
    "        else:\n",
    "            dataset_real = torch.cat((dataset_real, pusty), 0)\n",
    "    iloscslow = iloscslow + 1\n",
    "\n",
    "dataset_real = dataset_real.reshape(iloscslow, -1)\n",
    "\n",
    "print(dataset_real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors = torch.Tensor([\n",
    "#            [embeddingscuda[embeddingscuda_chars['a']], \n",
    "#            embeddingscuda[embeddingscuda_chars['b']], \n",
    "#            embeddingscuda[embeddingscuda_chars['c']], \n",
    "#            embeddingscuda[embeddingscuda_chars['d']], \n",
    "#            embeddingscuda[embeddingscuda_chars['e']],\n",
    "#            embeddingscuda[embeddingscuda_chars['f']],\n",
    "#            embeddingscuda[embeddingscuda_chars['g']],\n",
    "#            embeddingscuda[embeddingscuda_chars['h']]],\n",
    "#            [embeddingscuda[embeddingscuda_chars['a']], \n",
    "#            embeddingscuda[embeddingscuda_chars['b']], \n",
    "#            embeddingscuda[embeddingscuda_chars['c']], \n",
    "#            embeddingscuda[embeddingscuda_chars['d']], \n",
    "#            embeddingscuda[embeddingscuda_chars['e']],\n",
    "#            embeddingscuda[embeddingscuda_chars['f']],\n",
    "#            embeddingscuda[embeddingscuda_chars['g']],\n",
    "#            embeddingscuda[embeddingscuda_chars['h']]],\n",
    "#            [embeddingscuda[embeddingscuda_chars['a']], \n",
    "#            embeddingscuda[embeddingscuda_chars['b']], \n",
    "#            embeddingscuda[embeddingscuda_chars['c']], \n",
    "#            embeddingscuda[embeddingscuda_chars['d']], \n",
    "#            embeddingscuda[embeddingscuda_chars['e']],\n",
    "#            embeddingscuda[embeddingscuda_chars['f']],\n",
    "#            embeddingscuda[embeddingscuda_chars['g']],\n",
    "#            embeddingscuda[embeddingscuda_chars['h']]],\n",
    "#            [embeddingscuda[embeddingscuda_chars['a']], \n",
    "#            embeddingscuda[embeddingscuda_chars['b']], \n",
    "#            embeddingscuda[embeddingscuda_chars['c']], \n",
    "#            embeddingscuda[embeddingscuda_chars['d']], \n",
    "#            embeddingscuda[embeddingscuda_chars['e']],\n",
    "#            embeddingscuda[embeddingscuda_chars['f']],\n",
    "#            embeddingscuda[embeddingscuda_chars['g']],\n",
    "#            embeddingscuda[embeddingscuda_chars['h']]],\n",
    "#            [embeddingscuda[embeddingscuda_chars['a']], \n",
    "#            embeddingscuda[embeddingscuda_chars['b']], \n",
    "#            embeddingscuda[embeddingscuda_chars['c']], \n",
    "#            embeddingscuda[embeddingscuda_chars['d']], \n",
    "#            embeddingscuda[embeddingscuda_chars['e']],\n",
    "#            embeddingscuda[embeddingscuda_chars['f']],\n",
    "#            embeddingscuda[embeddingscuda_chars['g']],\n",
    "#            embeddingscuda[embeddingscuda_chars['h']]],\n",
    "#            [embeddingscuda[embeddingscuda_chars['a']], \n",
    "#            embeddingscuda[embeddingscuda_chars['b']], \n",
    "#            embeddingscuda[embeddingscuda_chars['c']], \n",
    "#            embeddingscuda[embeddingscuda_chars['d']], \n",
    "#            embeddingscuda[embeddingscuda_chars['e']],\n",
    "#            embeddingscuda[embeddingscuda_chars['f']],\n",
    "#            embeddingscuda[embeddingscuda_chars['g']],\n",
    "#            embeddingscuda[embeddingscuda_chars['h']]]\n",
    "# ]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()     \n",
    "        \n",
    "        self.fc_in = nn.Linear(6000, 4000)\n",
    "        self.fc_h1 = nn.Linear(4000, 2000)\n",
    "        self.fc_h2 = nn.Linear(2000, 1000)\n",
    "        self.fc_h3 = nn.Linear(1000, 200)\n",
    "#         self.fc_h4 = nn.Linear(100, 50)\n",
    "        self.fc_h5 = nn.Linear(200, 20)\n",
    "        self.fc_out = nn.Linear(20, 1)\n",
    "        \n",
    "    def forward(self, x):      \n",
    "        x = self.fc_in(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        x = self.fc_h1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        x = self.fc_h2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        x = self.fc_h3(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "#         x = self.fc_h4(x)\n",
    "#         x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_h5(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.fc_in = nn.Linear(500, 800)\n",
    "        self.fc_h1 = nn.Linear(800, 3500)\n",
    "#         self.fc_h2 = nn.Linear(1200, 2000)\n",
    "#         self.fc_h3 = nn.Linear(2000, 2800)\n",
    "#         self.fc_h4 = nn.Linear(2800, 3500)\n",
    "        self.fc_out = nn.Linear(3500, 6000)\n",
    "        \n",
    "        self.activation1 = nn.PReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc_in (x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        x = self.fc_h1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "#         x = self.fc_h2(x)\n",
    "#         x = F.relu(x)\n",
    "        \n",
    "#         x = self.fc_h3(x)\n",
    "#         x = F.relu(x)\n",
    "        \n",
    "#         x = self.fc_h4(x)\n",
    "#         x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator().to(\"cuda:0\")\n",
    "generator = Generator().to(\"cuda:0\")\n",
    "\n",
    "TensorReal = dataset_real\n",
    "\n",
    "TensorFakeOuts = torch.zeros(len(dataset_real)).to(\"cuda:0\")\n",
    "TensorRealOuts = torch.ones(len(dataset_real)).to(\"cuda:0\")\n",
    "\n",
    "TensorOuts = torch.cat((TensorFakeOuts, TensorRealOuts), 0).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 1230])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorReal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "criterion_segment = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorFakeSeeds = torch.rand(iloscslow, 500).to(\"cuda:0\")\n",
    "TensorFakeIns = generator(TensorFakeSeeds).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 750, 400])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorFakeIns.reshape(100, -1, 400).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cuda(vectors):    \n",
    "#     strings = []\n",
    "#     wyniki_loss = []\n",
    "#     onehots = torch.tensor([]).to(\"cuda:0\")\n",
    "    \n",
    "#     print(vectors.shape, embeddingscuda.shape)\n",
    "    \n",
    "#     s1 = torch.sum(vectors**2, dim=1, dtype=torch.float64).to(\"cuda:0\")\n",
    "#     s2 = torch.sum(embeddingscuda**2, dim=1, dtype=torch.float64).to(\"cuda:0\")\n",
    "    \n",
    "#     print(s1.shape, s2.shape)\n",
    "    \n",
    "#     sqrted_s1 = torch.sqrt(vectors)\n",
    "#     sqrted_s2 = torch.sqrt(s2)\n",
    "    \n",
    "#     print(sqrted_s1.shape, sqrted_s2.shape)\n",
    "\n",
    "#     dzielenie = sqrted_s1*sqrted_s2\n",
    "    \n",
    "#     for cnt in tqdm(range(len(vectors))):\n",
    "\n",
    "#         string = \"\"\n",
    "\n",
    "#         for cnt2, single in enumerate(vectors[cnt]):\n",
    "            \n",
    "#             sumaup = torch.sum(vectors[cnt][cnt2] * embeddingscuda, dim=1, dtype=torch.float64).to(\"cuda:0\")\n",
    "\n",
    "#             wynik = sumaup/(sqrted[cnt][cnt2].reshape(400, -1)*torch.sqrt(s2))\n",
    "#             wynik[0] = 0\n",
    "#             string=string+list(embeddingscuda_chars.keys())[torch.argmax(wynik).item()]\n",
    "#             wyniki_loss.append(torch.max(wynik).item())\n",
    "#             onehots = torch.cat((onehots, onehotvectors[list(embeddingscuda_chars.keys())[torch.argmax(wynik).item()]]), 0)\n",
    "            \n",
    "#         strings.append(string)\n",
    "        \n",
    "#     return strings, onehots.reshape(len(vectors), -1), np.mean(np.array(wyniki_loss))\n",
    "# # %time cuda(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cuda2(vectors):\n",
    "#     print(vectors.shape, embeddingscuda.shape)\n",
    "\n",
    "#     sqrted_sum_s1 = torch.sqrt(torch.sum(vectors**2, dim=2))\n",
    "#     sqrted_sum_s2 = torch.sqrt(torch.sum(embeddingscuda**2, dim=1))\n",
    "    \n",
    "#     print(sqrted_sum_s1.shape, sqrted_sum_s2.shape)\n",
    "    \n",
    "#     for vector in embeddingscuda:\n",
    "    \n",
    "    \n",
    "#     return \"\", \"\", \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translated1, translated2, translated_loss = cuda2(TensorFakeIns.reshape(100, -1, 400))\n",
    "# print(translated_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(translated1[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5044869184],\n",
       "        [0.5044723153],\n",
       "        [0.5044777989],\n",
       "        ...,\n",
       "        [0.5044805408],\n",
       "        [0.5044566989],\n",
       "        [0.5044723153]], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator(TensorFakeIns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerGenerator = optim.Adam(generator.parameters(), lr=1e-3)\n",
    "optimizerClassifier = optim.Adam(discriminator.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 0. Got 1230 and 6000 in dimension 1 at c:\\a\\w\\1\\s\\tmp_conda_3.7_104535\\conda\\conda-bld\\pytorch_1550400486030\\work\\aten\\src\\thc\\generic/THCTensorMath.cu:83",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-9f50ea7c4241>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mTensorFakeIns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorFakeSeeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mTensorIns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorFakeIns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensorReal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m      \u001b[1;31m## DISCRIMINATOR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 1230 and 6000 in dimension 1 at c:\\a\\w\\1\\s\\tmp_conda_3.7_104535\\conda\\conda-bld\\pytorch_1550400486030\\work\\aten\\src\\thc\\generic/THCTensorMath.cu:83"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    TensorFakeSeeds = torch.rand(iloscslow, 500).to(\"cuda:0\")\n",
    "    TensorFakeIns = generator(TensorFakeSeeds).to(\"cuda:0\")\n",
    "    \n",
    "    TensorIns = torch.cat((TensorFakeIns.detach(), TensorReal), 0).to(\"cuda:0\")\n",
    "    \n",
    "     ## DISCRIMINATOR\n",
    "    discriminator.train()\n",
    "    optimizerClassifier.zero_grad()\n",
    "    \n",
    "    y_ = discriminator(TensorIns)\n",
    "    lossDiscriminator = criterion(y_, TensorOuts)\n",
    "    \n",
    "    lossDiscriminator.backward()\n",
    "    optimizerClassifier.step()\n",
    "    \n",
    "    \n",
    "    ## GENERATOR\n",
    "    generator.train()\n",
    "    optimizerGenerator.zero_grad()\n",
    "    \n",
    "    y_ = discriminator(TensorFakeIns)\n",
    "    lossGenerator = criterion(y_, TensorRealOuts)\n",
    "    \n",
    "    lossGenerator.backward()\n",
    "    optimizerGenerator.step()\n",
    "    \n",
    "    #print(xx)\n",
    "    print(lossDiscriminator, lossGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
