{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['harcowaaby', 'groblowych', 'lon偶owaliby', 'zasmagaaby', 'zdradza', 'niezamianowanej', 'transowych', 'nagonkowy', 'niezagubionych', 'karykaturk', 'wyhandlowaoby', 'tessarotypie', 'niehermowi', 'dobiobym', 'kantaty', 'siorpnijcie', 'rozlewanej', 'wciosaabym', 'r贸wnoczonowego', 'jawi', 'stygmatoidalnej', 'niekaliskiej', 'wysiewach', 'niegodkowsk', 'dystansowaobym', 'pokratkowane', 'nieetylujcych', 'niedowchaniem', 'siorbnlicie', 'maj贸wk', 'kontrujcy', 'cal贸wk', 'niezbudowani', 'nieszk贸karsk', 'falbaniaste', 'ogipsowaem', 'wykraczalibymy', 'niemikrosomaln', 'nie偶贸tkowego', 'zrywaj', 'szatniark', 'meteopaty', 'dosu偶yybymy', 'ampelografio', 'zlepianymi', 'okrtuj', 'niekonwentualn', 'baklavach', 'kreatywny', 'niebladncego', 'przedkocielne', 'wiktymologami', 'adypinowe', 'odnawiabym', 'siar', 'nieusiada', 'usaniom', 'doniczka', 'oblepiaem', 'szczypka', 'rzymiank', 'pomieszkujce', 'tapicerowa', 'metalurg贸w', 'plotowana', 'makaronizacyj', 'wzornikujcemu', 'dedukowana', 'nadzwyczaj', 'wystrzelenia', 'nietr贸jsylabowe', 'widrowatych', 'cmoktaby', 'wymigaycie', 'trwogom', 'karakolowaam', 'tryskawcach', 'zalterowana', 'mechaciaby', 'korduple', 'achotliwymi', 'doby', 'niemamuninych', 'odratowujcymi', 'dyktatorsk', 'lodowanym', 'oskar偶eniach', 'podrasowanym', 'zbawaniejcie', 'niepoddbicka', 'niezastopowan', 'zamulmy', 'warkn', 'poobjadao', 'przesyp', 'reformist贸w', 'przysiga', 'neologizmie', 'nieprogresywna', 'obrzdowego']\n",
      "13000\n"
     ]
    }
   ],
   "source": [
    "polskie = open(\"../polskie-slowa.txt\", encoding='utf8')\n",
    "slowa = [slowo.replace(\"\\n\", \"\") for slowo in polskie.readlines()]\n",
    "polskie.close()\n",
    "print(slowa[:100])\n",
    "print(len(slowa))\n",
    "slowa = slowa[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h', 'a', 'r', 'c', 'o', 'w', '', 'b', 'y', '', 'g', 'l', 'n', '偶', 'i', 'z', 's', 'm', 'd', '', 'e', 'j', 't', 'k', 'u', '', 'p', '贸', '', 'f', 'v', '', '藕']\n",
      "15\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "longestword = 0\n",
    "\n",
    "unikalneznaki = []\n",
    "for slowo in slowa:\n",
    "    for literka in slowo:\n",
    "        if literka not in unikalneznaki:\n",
    "            unikalneznaki.append(literka)\n",
    "    if len(slowo) > longestword:\n",
    "        longestword = len(slowo)\n",
    "            \n",
    "print(unikalneznaki)\n",
    "print(longestword)\n",
    "print(len(unikalneznaki))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "klasy = {}\n",
    "klasy[0] = \"\"\n",
    "for cnt, znak in enumerate(unikalneznaki):\n",
    "    klasy[cnt+1] = znak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'h': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'a': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'r': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'c': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'o': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'w': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'b': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'y': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'g': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'l': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'n': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '偶': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'i': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'z': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 's': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'm': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'd': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'e': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'j': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 't': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'k': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'u': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], '': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 'p': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], '贸': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], '': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 'f': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 'v': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], '': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], '藕': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}\n"
     ]
    }
   ],
   "source": [
    "onehotvectory = {}\n",
    "for cnt, litera in enumerate(unikalneznaki):\n",
    "    vec = [0 for __ in range(len(unikalneznaki))]\n",
    "    vec[cnt] = 1\n",
    "    onehotvectory[litera] = vec\n",
    "\n",
    "print(onehotvectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilosc wejsc: 495\n"
     ]
    }
   ],
   "source": [
    "print(\"ilosc wejsc: \" + str(len(unikalneznaki) * longestword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_real = []\n",
    "# dataset_real = [onehotvectory[slowo[index]] if index<len(slowo) else [0 for __ in range(len(unikalneznaki))] for slowo in slowa for index in range(longestword)]\n",
    "\n",
    "#longestword = 5\n",
    "#slowa = [\"siema\", \"abcd\", \"abc\"]\n",
    "iloscslow = 0\n",
    "\n",
    "for cnt, slowo in enumerate(slowa):\n",
    "    slowoencoded = []\n",
    "    for index in range(longestword):\n",
    "        if index<len(slowo):\n",
    "            slowoencoded.append(onehotvectory[slowo[index]])\n",
    "            # slowoencoded.append(slowo[index])\n",
    "        else:\n",
    "            slowoencoded.append([0 for __ in range(len(unikalneznaki))])\n",
    "    dataset_real = dataset_real + slowoencoded\n",
    "    iloscslow = iloscslow + 1\n",
    "    if len(slowo) < longestword:\n",
    "        for __ in range(longestword - len(slowo)):\n",
    "            #dataset_real.append(\"XD\")\n",
    "            slowoencoded = [slowoencoded[-1]] + slowoencoded[:-1]\n",
    "            dataset_real = dataset_real + slowoencoded\n",
    "            iloscslow = iloscslow + 1\n",
    "            #print(dataset_real[-1] + dataset_real[:-1])\n",
    "    # dataset_real.append(\"  \")\n",
    "\n",
    "# for xx in dataset_real:\n",
    "#     print(xx)\n",
    "\n",
    "\n",
    "# dataset_fake = []\n",
    "\n",
    "\n",
    "# for __ in range(len(slowa)):\n",
    "#     slowo = []\n",
    "#     wielkosc = random.randint(3, longestword)\n",
    "#     for xx in range(longestword):\n",
    "#         if xx < wielkosc:\n",
    "#             slowo.append(onehotvectory[list(onehotvectory.keys())[random.randint(0, len(onehotvectory)-1)]])\n",
    "#         else:\n",
    "#             slowo.append([0 for __ in range(len(unikalneznaki))])\n",
    "#     dataset_fake.append(slowo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()     \n",
    "        \n",
    "        self.fc_in = nn.Linear(495, 400)\n",
    "        self.fc_h1 = nn.Linear(400, 300)\n",
    "        self.fc_h2 = nn.Linear(300, 200)\n",
    "        self.fc_h3 = nn.Linear(200, 100)\n",
    "        self.fc_h4 = nn.Linear(100, 50)\n",
    "        self.fc_h5 = nn.Linear(50, 20)\n",
    "        self.fc_out = nn.Linear(20, 1)\n",
    "        \n",
    "    def forward(self, x):      \n",
    "        x = self.fc_in(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_h1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_h2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_h3(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_h4(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_h5(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.fc_in = nn.Linear(500, 500)\n",
    "        self.fc_h1 = nn.Linear(500, 500)\n",
    "        self.fc_h2 = nn.Linear(500, 500)\n",
    "        self.fc_h3 = nn.Linear(500, 500)\n",
    "        self.fc_h4 = nn.Linear(500, 500)\n",
    "        self.fc_out = nn.Linear(500, 33)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc_in (x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_h1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_h2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_h3(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_h4(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_real = np.array(dataset_real).reshape(iloscslow, -1)\n",
    "#dataset_fake = np.array(dataset_fake).reshape(len(slowa), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23632, 495)\n"
     ]
    }
   ],
   "source": [
    "print(dataset_real.shape)\n",
    "#print(dataset_fake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator().to(\"cuda:0\")\n",
    "generator = Generator().to(\"cuda:0\")\n",
    "#TensorFake = torch.Tensor(dataset_fake).to(\"cuda:0\")\n",
    "TensorReal = torch.Tensor(dataset_real).to(\"cuda:0\")\n",
    "\n",
    "#TensorIns = torch.cat((TensorReal, TensorFake), 0).to(\"cuda:0\")\n",
    "\n",
    "#print(TensorIns.shape)\n",
    "\n",
    "TensorFakeOuts = torch.zeros(len(dataset_real)).to(\"cuda:0\")\n",
    "TensorRealOuts = torch.ones(len(dataset_real)).to(\"cuda:0\")\n",
    "\n",
    "#TensorOuts = torch.cat((TensorRealOuts, TensorFakeOuts), 0).to(\"cuda:0\")\n",
    "\n",
    "#TensorRealOuts = TensorRealOuts.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "criterion_segment = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Onecycle():\n",
    "    def __init__(self, optimizer, lrmin, lrmax, epochs, model):\n",
    "        self.b1 = lrmin\n",
    "        self.a1 = (lrmax - self.b1) / (epochs/2)\n",
    "    \n",
    "        self.b2 = lrmax - ((-self.a1)*epochs/2)\n",
    "        self.epochs = epochs\n",
    "        self.model = model\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def build(self, epoch):\n",
    "        lr = 0\n",
    "        if epoch<=self.epochs/2:\n",
    "            lr = self.a1*epoch+self.b1\n",
    "        else:\n",
    "            lr = (-self.a1)*epoch+self.b2\n",
    "        \n",
    "        return self.optimizer(self.model.parameters(), lr=lr)\n",
    "    \n",
    "    def get_lr_arr(self):\n",
    "        lrs = []\n",
    "        for epoch in range(self.epochs):\n",
    "            if epoch<=self.epochs/2:\n",
    "                lr = self.a1*epoch+self.b1\n",
    "                lrs.append(lr)\n",
    "            else:\n",
    "                lr = (-self.a1)*epoch+self.b2\n",
    "                lrs.append(lr)\n",
    "        return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_discriminator = optim.Adam\n",
    "optim_generator = optim.Adam\n",
    "\n",
    "onecycle_discriminator = Onecycle(optim_discriminator, 1e-6, 1e-4, 5000, discriminator)\n",
    "onecycle_generator = Onecycle(optim_generator, 1e-6, 1e-4, 5000, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "C:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2016: UserWarning: Using a target size (torch.Size([23632])) that is different to the input size (torch.Size([23632, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7101739048957825 0.676959753036499 0.709609866142273\n",
      "tensor([[0.4952, 0.4951, 0.5089,  ..., 0.4908, 0.5033, 0.5102],\n",
      "        [0.4947, 0.4949, 0.5099,  ..., 0.4910, 0.5024, 0.5098],\n",
      "        [0.4949, 0.4950, 0.5090,  ..., 0.4917, 0.5027, 0.5089],\n",
      "        ...,\n",
      "        [0.4947, 0.4957, 0.5089,  ..., 0.4917, 0.5031, 0.5102],\n",
      "        [0.4950, 0.4947, 0.5095,  ..., 0.4912, 0.5025, 0.5098],\n",
      "        [0.4945, 0.4956, 0.5088,  ..., 0.4908, 0.5034, 0.5104]],\n",
      "       device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "0.7098696827888489 0.6760892868041992 0.7105105519294739\n",
      "0.7093702554702759 0.6739636063575745 0.7127302885055542\n",
      "0.7086514830589294 0.6706767678260803 0.7161726951599121\n",
      "0.7076119184494019 0.6656920313835144 0.7214536666870117\n",
      "0.706194281578064 0.6563113927841187 0.731536328792572\n",
      "0.7042956352233887 0.6359648704528809 0.75412517786026\n",
      "0.7018410563468933 0.6052531003952026 0.7901769280433655\n",
      "0.6994562745094299 0.6079193949699402 0.7870849370956421\n",
      "0.6978535652160645 0.6657482385635376 0.7216824889183044\n",
      "0.6906781792640686 0.6662821173667908 0.7211087346076965\n",
      "tensor([[2.1088e-07, 1.5962e-05, 5.8647e-05,  ..., 3.0641e-05, 3.4500e-06,\n",
      "         2.0992e-08],\n",
      "        [1.6500e-07, 1.3383e-05, 5.0375e-05,  ..., 2.6098e-05, 2.8384e-06,\n",
      "         1.5786e-08],\n",
      "        [3.8196e-07, 2.4522e-05, 8.5611e-05,  ..., 4.5704e-05, 5.6423e-06,\n",
      "         4.1446e-08],\n",
      "        ...,\n",
      "        [2.4737e-07, 1.7927e-05, 6.5076e-05,  ..., 3.4288e-05, 3.9410e-06,\n",
      "         2.5090e-08],\n",
      "        [6.5391e-07, 3.5603e-05, 1.2015e-04,  ..., 6.5482e-05, 8.7182e-06,\n",
      "         7.6646e-08],\n",
      "        [2.7651e-07, 1.9525e-05, 6.9565e-05,  ..., 3.7034e-05, 4.3245e-06,\n",
      "         2.8689e-08]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "0.6870604753494263 0.6606977581977844 0.7277618050575256\n",
      "0.6956011056900024 0.6269808411598206 0.7665793299674988\n",
      "0.7600862383842468 0.5651660561561584 0.8424403667449951\n",
      "0.7101694345474243 0.718289315700531 0.6711201667785645\n",
      "0.7007062435150146 0.6975518465042114 0.6891565322875977\n",
      "0.6880648732185364 0.6971796751022339 0.6888890266418457\n",
      "0.6972492337226868 0.6894875764846802 0.6964253187179565\n",
      "0.687070369720459 0.699893057346344 0.6881536841392517\n",
      "0.7090783715248108 0.6718544960021973 0.7155454158782959\n",
      "0.7037287950515747 0.681704044342041 0.7045043110847473\n",
      "tensor([[3.9410e-05, 3.3125e-03, 3.9153e-01,  ..., 2.7888e-08, 1.1103e-04,\n",
      "         5.3630e-07],\n",
      "        [3.9064e-05, 3.2767e-03, 3.9164e-01,  ..., 2.7573e-08, 1.0931e-04,\n",
      "         5.2729e-07],\n",
      "        [6.2617e-05, 4.2869e-03, 3.9484e-01,  ..., 6.2459e-08, 1.6845e-04,\n",
      "         1.0529e-06],\n",
      "        ...,\n",
      "        [5.8022e-05, 4.1023e-03, 3.9410e-01,  ..., 5.4687e-08, 1.5679e-04,\n",
      "         9.3752e-07],\n",
      "        [4.8543e-05, 3.7146e-03, 3.9239e-01,  ..., 4.0081e-08, 1.3369e-04,\n",
      "         7.2692e-07],\n",
      "        [5.4594e-05, 3.9422e-03, 3.9488e-01,  ..., 4.9019e-08, 1.4837e-04,\n",
      "         8.5973e-07]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "0.6899534463882446 0.6906231641769409 0.6956415772438049\n",
      "0.6900405287742615 0.7059272527694702 0.6832115650177002\n",
      "0.709039568901062 0.6689189672470093 0.7201160192489624\n",
      "0.6949658989906311 0.6908619999885559 0.6954599618911743\n",
      "0.6963127255439758 0.6808321475982666 0.7089476585388184\n",
      "0.6938015222549438 0.6912875771522522 0.6964246034622192\n",
      "0.6943479180335999 0.6915027499198914 0.6954435706138611\n",
      "0.6932790279388428 0.6923326849937439 0.6964613795280457\n",
      "0.6962435841560364 0.6899052858352661 0.699582040309906\n",
      "0.7059820294380188 0.6763058304786682 0.7116357088088989\n",
      "tensor([[8.1837e-06, 3.1449e-07, 8.8345e-09,  ..., 2.1485e-07, 1.4085e-02,\n",
      "         7.3518e-09],\n",
      "        [1.0686e-05, 4.3968e-07, 1.3399e-08,  ..., 3.0065e-07, 1.5482e-02,\n",
      "         1.1180e-08],\n",
      "        [9.6700e-06, 3.8536e-07, 1.1422e-08,  ..., 2.6373e-07, 1.5004e-02,\n",
      "         9.4815e-09],\n",
      "        ...,\n",
      "        [9.4544e-06, 3.7420e-07, 1.0976e-08,  ..., 2.5487e-07, 1.4754e-02,\n",
      "         9.1134e-09],\n",
      "        [1.0299e-05, 4.2024e-07, 1.2672e-08,  ..., 2.8945e-07, 1.5221e-02,\n",
      "         1.0569e-08],\n",
      "        [8.5097e-06, 3.2607e-07, 9.3278e-09,  ..., 2.2326e-07, 1.4290e-02,\n",
      "         7.7292e-09]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "0.7073699235916138 0.6671278476715088 0.7233960032463074\n",
      "0.684973955154419 0.701642632484436 0.6872736215591431\n",
      "0.692499041557312 0.6969159245491028 0.6936944127082825\n",
      "0.7043672204017639 0.6821478605270386 0.7042364478111267\n",
      "0.6953016519546509 0.6898438930511475 0.6996655464172363\n",
      "0.6968063712120056 0.6880149245262146 0.7022753953933716\n",
      "0.7152901887893677 0.6493828892707825 0.7425772547721863\n",
      "0.695232093334198 0.6961239576339722 0.6975787878036499\n",
      "0.7106102108955383 0.6660841107368469 0.726386308670044\n",
      "0.6980513334274292 0.6822748780250549 0.7092000842094421\n",
      "tensor([[2.1190e-01, 2.2815e-01, 1.5813e-07,  ..., 5.8190e-06, 9.9776e-03,\n",
      "         5.5342e-07],\n",
      "        [2.1410e-01, 2.2879e-01, 1.7240e-07,  ..., 6.1959e-06, 1.0226e-02,\n",
      "         5.9943e-07],\n",
      "        [2.0508e-01, 2.1976e-01, 9.1831e-08,  ..., 3.8339e-06, 8.5628e-03,\n",
      "         3.3515e-07],\n",
      "        ...,\n",
      "        [2.1157e-01, 2.2648e-01, 1.5336e-07,  ..., 5.6380e-06, 9.9545e-03,\n",
      "         5.4017e-07],\n",
      "        [2.1186e-01, 2.2664e-01, 1.4980e-07,  ..., 5.5921e-06, 9.8266e-03,\n",
      "         5.2561e-07],\n",
      "        [2.1849e-01, 2.3298e-01, 2.4314e-07,  ..., 8.0796e-06, 1.1331e-02,\n",
      "         8.2008e-07]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "0.7115302681922913 0.6591365337371826 0.7326951026916504\n",
      "0.6906207203865051 0.6898133754730225 0.6959680318832397\n",
      "0.6914568543434143 0.6924691200256348 0.6931054592132568\n",
      "0.713875949382782 0.6508726477622986 0.7450977563858032\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-56ba219f569d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0my_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorFakeIns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mlossDfake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensorFakeOuts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mlossDfake\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2026\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[1;32m-> 2027\u001b[1;33m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[0;32m   2028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2029\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(5000):\n",
    "    optimizer_discriminator = onecycle_discriminator.build(epoch)\n",
    "    optimizer_generator = onecycle_generator.build(epoch)\n",
    "    \n",
    "    \n",
    "    optimizer_discriminator.zero_grad()\n",
    "    \n",
    "    y_ = discriminator(TensorReal)\n",
    "    lossDreal = criterion(y_, TensorRealOuts)\n",
    "    \n",
    "    lossDreal.backward()\n",
    "    \n",
    "    \n",
    "    TensorFakeSeeds = torch.rand(iloscslow, 500).to(\"cuda:0\")\n",
    "    TensorFakeIns = generator(TensorFakeSeeds).to(\"cuda:0\")\n",
    "    \n",
    "    for i in range(15):\n",
    "        w = TensorFakeIns[]\n",
    "    \n",
    "    y_ = discriminator(TensorFakeIns)\n",
    "    lossDfake = criterion(y_, TensorFakeOuts)\n",
    "    \n",
    "    lossDfake.backward()\n",
    "    optimizer_discriminator.step()\n",
    "    \n",
    "    \n",
    "    optimizer_generator.zero_grad()\n",
    "    \n",
    "    TensorFakeSeeds = torch.rand(iloscslow, 500).to(\"cuda:0\")\n",
    "    TensorFakeIns = generator(TensorFakeSeeds).to(\"cuda:0\")\n",
    "\n",
    "    y_ = discriminator(TensorFakeIns)\n",
    "    lossG = criterion(y_, TensorRealOuts)\n",
    "\n",
    "    lossG.backward()\n",
    "    optimizer_generator.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(lossDreal.item(), lossDfake.item(), lossG.item())\n",
    "        \n",
    "    if epoch % 1000 == 0:\n",
    "        print(TensorFakeIns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real: konstelacje 1.0\n",
      "Real: maraszynko 1.0\n",
      "Real: asdasd 1.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    slowka = [\"konstelacje\", \"maraszynko\", \"asdasd\"]\n",
    "    \n",
    "    test_data = np.array([onehotvectory[slowo[index]] if index<len(slowo) else [0 for __ in range(len(unikalneznaki))] for slowo in slowka for index in range(longestword)]).reshape(len(slowka), -1)\n",
    "    TensorTest = torch.Tensor(test_data).to(\"cuda:0\")\n",
    "\n",
    "    y_ = discriminator(TensorTest)\n",
    "    \n",
    "    y = y_.cpu().detach().numpy()\n",
    "    \n",
    "    for cnt, item in enumerate(y):\n",
    "        if item < 0.5:\n",
    "            print(\"Fake: \" + slowka[cnt] + \" \" + str(item[0]))\n",
    "        else:\n",
    "            print(\"Real: \" + slowka[cnt] + \" \" + str(item[0]))\n",
    "\n",
    "    #print(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
