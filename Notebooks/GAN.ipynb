{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W-Y3LtVW6BQ5",
    "outputId": "05bfa9fe-4b55-463c-9d70-72044fac9fed"
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c4MybKoz6BRB"
   },
   "outputs": [],
   "source": [
    "plikembd = open(\"../character_embeddings.txt\")\n",
    "\n",
    "embeddings = {}\n",
    "\n",
    "for line in plikembd.readlines():\n",
    "    exp1 = line.replace(\"\\n\", \"\").split(\":\")\n",
    "    \n",
    "    znak = exp1[0]\n",
    "    embedding = [float(liczba) for liczba in exp1[1].replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\",\\t\")[:-1]]\n",
    "\n",
    "    \n",
    "    embeddings[znak] = embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "apE9EEd26BRG"
   },
   "source": [
    "## Znajdowanie znaku na podstawie wybranego punktu w przestrzeni\n",
    "Sieć Generatora będzie na outpucie dawać nam współrzędne punktów, które tworzą hasła. Punkty te będą niedokładne, dlatego musimy mieć funkcję, która będzie w stanie przetworzyć je na znak. Będzie się to odbywać na zasadzie znajdywania najbliżej położonego punktu.\n",
    "\n",
    "W tym celu wykorzystujemy wzór do obliczenia odległości:\n",
    "\\begin{equation}\n",
    "\\textit{odległość = }\n",
    "\\sqrt{\\sum_{i=0}^{m} (x_{1i}+x_{2i})^{2}}\n",
    "\\textit{, gdzie m to wielkość wektora znaku, a x oraz y to wektory punktów}\n",
    "\\end{equation}\n",
    "\n",
    "### Dorzucamy trochę dodatków\n",
    "Wiemy, że na wyjściu Generatora będziemy mieć stałą liczbę wyjść zależną jedynie od wielkości wektorów dla znaków. Chcemy jednak móc generować ciągi znaków o różnej długości. By tak zrobić należy wprowadzić do naszej przestrzeni znaków dodatkowy(pusty) znak. Wprowadzenie jego musi jednak pomijać całkowicie zależności jakie zostały już wyznaczone między znakami. Zdecydowałem się na stworzenie ogarniczenia, że jeżeli odległość od najbliższego punktu będzie większa niż jakaś ustalona, to zwracamy wtedy znak pusty. Całość przedstawia poniższa grafika. Pomarańczowe/żółte elementy pokazują wyznaczone znaki, a zielone to punkty trafione przez Generator. Dookoła zielonych punktów jest okrąg pokazujący zakres wyłapywania znaków, jeżeli najbliższy wyznaczony znak znajduje się poza przestrzenią wtedy zwracany jest znak pusty (🈳).\n",
    "\n",
    "![https://i.imgur.com/7nDZ2aZ.png](https://i.imgur.com/7nDZ2aZ.png) \n",
    "\n",
    "#### Wnioski\n",
    "+ Czy odległość dla zwróconego znaku powinna być uwzględniania w funkcji loss? Nie koniecznie się to nadaje, bo ta wartość zawsze jest dodania i nie wskaże nam wektora przesunięcia stepu w poszukiwaniu minimum\n",
    "+ Dane wejściowe dla klasyfikatora można wzbogacić. Chodzi o dodanie pustego znaku(🈳) do hasła, tak by wypełnić jego okno, jakie jest ustalone na wyjściu Generatora i wejściu Dyskryminatora. Dodatkowo można poprzesuwać w różne strony takie hasło."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "q726W7dZ6BRH",
    "outputId": "9d33ea85-8051-462d-ba32-f0e6561adfbd"
   },
   "outputs": [],
   "source": [
    "def get_closest_char_from_space(vectors, embeddings, odleglosc_do_pustego=5, pusty='🈳'):\n",
    "    minimalna = math.inf\n",
    "    znak = pusty\n",
    "    \n",
    "    for key in embeddings:\n",
    "        suma = 0\n",
    "        \n",
    "        for vecid in range(len(vectors)):\n",
    "            suma = suma + (embeddings[key][vecid] - vectors[vecid])**2\n",
    "            \n",
    "        odleglosc = math.sqrt(suma)\n",
    "        \n",
    "        if odleglosc < minimalna:\n",
    "            minimalna = odleglosc\n",
    "            znak = key\n",
    "        \n",
    "    if minimalna > odleglosc_do_pustego:\n",
    "        znak = pusty\n",
    "    else:\n",
    "        minimalna = 0\n",
    "        \n",
    "    return znak, minimalna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "VJxD1-7Q6BRW",
    "outputId": "ab941416-e0cc-4f28-e1fe-024a7231bb0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.90062712, 8.0872146 , 1.17390081, ..., 1.87586838, 5.36048875,\n",
       "       1.3166711 ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate_char_to_embedding(char, embeddings, odleglosc_do_pustego=5, pusty='🈳'):\n",
    "    if char in list(embeddings.keys()):\n",
    "        return embeddings[char]\n",
    "    else:\n",
    "        if char == pusty:\n",
    "            wymiarowosc = len(embeddings[list(embeddings.keys())[0]])\n",
    "            \n",
    "            #np.random.seed(random.randint(0, 100000))\n",
    "            wartosci = np.random.rand(wymiarowosc)\n",
    "\n",
    "            for index, element in enumerate(wartosci):\n",
    "                wartosci[index] = wartosci[index] * random.randint(0,10)\n",
    "\n",
    "            while get_closest_char_from_space(wartosci, embeddings)[1] <= odleglosc_do_pustego:\n",
    "                #np.random.seed(random.randint(0, 100000))\n",
    "                wartosci = np.random.rand(wymiarowosc)\n",
    "\n",
    "                for index, element in enumerate(wartosci):\n",
    "                    wartosci[index] = wartosci[index] * random.randint(0,10)\n",
    "                    \n",
    "            return wartosci\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "translate_char_to_embedding('🈳', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qvh1C9_V6BRd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def outputsieci_na_znaki(embeddings, outputsieci, odleglosc_do_pustego=5):\n",
    "    ile_skladowych = len(embeddings[list(embeddings.keys())[0]])\n",
    "    \n",
    "    zwrot = \"\"\n",
    "    \n",
    "    for x in range(int(len(outputsieci)/ile_skladowych)):\n",
    "        zwrot = zwrot + get_closest_char_from_space(outputsieci[ile_skladowych*x:x*ile_skladowych+ile_skladowych], embeddings, odleglosc_do_pustego=odleglosc_do_pustego)[0]\n",
    "    \n",
    "    return zwrot\n",
    "\n",
    "outputsieci_na_znaki(embeddings, [-0.0151,  0.0794,  0.1788,  0.1366, -0.0584,  0.0482,  0.1471,  0.0611,\n",
    "        -0.0016, -0.0677,  0.0954,  0.0197, -0.1034,  0.0747,  0.1616, -0.0592,\n",
    "        -0.0510,  0.0859, -0.0009,  0.0471,  0.0045, -0.1478,  0.1598, -0.0229,\n",
    "         0.0614, -0.1198, -0.1260,  0.0950,  0.1093,  0.0679])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputsieci_na_znaki_batch(embeddings, batch, odleglosc_do_pustego=5):\n",
    "    ile_skladowych = len(embeddings[list(embeddings.keys())[0]])\n",
    "    \n",
    "    zwr = []\n",
    "    \n",
    "    for outputsieci in batch:\n",
    "        zwrot = \"\"\n",
    "        for x in range(int(len(outputsieci)/ile_skladowych)):\n",
    "            zwrot = zwrot + get_closest_char_from_space(outputsieci[ile_skladowych*x:x*ile_skladowych+ile_skladowych], embeddings, odleglosc_do_pustego=odleglosc_do_pustego)[0]\n",
    "    \n",
    "        zwr.append(zwrot)\n",
    "    return zwr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myloss(embeddings, batchoutput, odleglosc_do_pustego=1, aggfunc=np.max, aggbatch=np.mean):\n",
    "    ile_skladowych = len(embeddings[list(embeddings.keys())[0]])\n",
    "    \n",
    "    ret = []\n",
    "    \n",
    "    for outputsieci in batchoutput:\n",
    "        zwrot = []\n",
    "        for x in range(int(len(outputsieci)/ile_skladowych)):\n",
    "            zwrot.append(get_closest_char_from_space(outputsieci[ile_skladowych*x:x*ile_skladowych+ile_skladowych], embeddings, odleglosc_do_pustego=odleglosc_do_pustego)[1])\n",
    "        \n",
    "        zwrot = np.array(zwrot)\n",
    "        ret.append(aggfunc(zwrot))\n",
    "    return aggbatch(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2V8JaoX6BRm"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.fc_in = nn.Linear(in_features=300, out_features=300)\n",
    "        self.fc_h1 = nn.Linear(in_features=300, out_features=300)\n",
    "        self.fc_h2 = nn.Linear(in_features=300, out_features=300)\n",
    "        self.fc_h3 = nn.Linear(in_features=300, out_features=300)\n",
    "        self.fc_h4 = nn.Linear(in_features=300, out_features=300)\n",
    "        self.fc_h5 = nn.Linear(in_features=300, out_features=300)\n",
    "        self.fc_h6 = nn.Linear(in_features=300, out_features=300)\n",
    "        self.fc_h7 = nn.Linear(in_features=300, out_features=300)\n",
    "        self.fc_out = nn.Linear(in_features=300, out_features=30)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        self.activation2 = nn.PReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc_in(x)\n",
    "        # x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_h1(x)\n",
    "        # x = self.activation2(x)\n",
    "        \n",
    "        x = self.fc_h2(x)\n",
    "        # x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_h3(x)\n",
    "        # x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_h4(x)\n",
    "        # x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_h5(x)\n",
    "        # x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_h6(x)\n",
    "        # x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_h7(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        # x = self.activation2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VoMG5EjN6BRt"
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.fc_in = nn.Linear(in_features=30, out_features=600)\n",
    "        self.fc_h1 = nn.Linear(in_features=600, out_features=400)\n",
    "        self.fc_h2 = nn.Linear(in_features=400, out_features=200)\n",
    "        self.fc_h3 = nn.Linear(in_features=200, out_features=70)\n",
    "        self.fc_out = nn.Linear(in_features=70, out_features=30)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        self.activation2 = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        inp = x\n",
    "        \n",
    "        x = self.fc_in(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_h1(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_h2(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_h3(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        x = self.activation2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.xavier_normal(m.weight.data, 1.0, 0.002)\n",
    "        #nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "uRRzitHGTSoj",
    "outputId": "ac6f9f26-a714-4d0f-ace8-7443e470afed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "20\n",
      "['fialek', 'baktrian', 'ostry6', 'loffee', 'orginal', 'liwka11', 'miska2003', 'pitka', '1asdfghjkl', 'julusia', 'marika5', 'katon99', 'thc', 'arkadyy', 'bogna1', 'pimpong', 'oliwek', 'danzka', 'sk07007', 'dance']\n"
     ]
    }
   ],
   "source": [
    "plik = open(\"../100k.txt\")\n",
    "\n",
    "slowka = [slowo.lower().replace(\"\\n\", \"\") for index,slowo in enumerate(plik)]\n",
    "slowa = []\n",
    "\n",
    "print(len(slowka))\n",
    "\n",
    "while len(slowa) < 20:\n",
    "    los = random.randint(0, len(slowka) - 1)\n",
    "    if slowka[los] not in slowa:\n",
    "        slowa.append(slowka[los])\n",
    "\n",
    "print(len(slowa))\n",
    "print(slowa[0:2000])\n",
    "\n",
    "slowa = slowka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_longest_word(words):\n",
    "    longest = 0\n",
    "    for word in words:\n",
    "        if len(word) > longest:\n",
    "            longest = len(word)\n",
    "    return longest\n",
    "\n",
    "longestwrd = get_longest_word(slowa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9600,)\n"
     ]
    }
   ],
   "source": [
    "def zbuduj_slowo(word, embeddings, longestword, odleglosc_do_pustego=5):\n",
    "    slowo = []\n",
    "    \n",
    "    for litera in word:\n",
    "        slowo.append(translate_char_to_embedding(litera, embeddings, odleglosc_do_pustego=odleglosc_do_pustego, pusty='🈳'))\n",
    "    \n",
    "    reszta = longestword - len(word)\n",
    "    \n",
    "    for __ in range(reszta):\n",
    "        slowo.append(translate_char_to_embedding(\"🈳\", embeddings, odleglosc_do_pustego=odleglosc_do_pustego, pusty='🈳'))\n",
    "        \n",
    "    return np.array(slowo).reshape(-1)\n",
    "print(zbuduj_slowo(\"halko\", embeddings, 6).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2a6d7cffc70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manualSeed = 1001\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(\"cuda:0\")\n",
    "classifier = Classifier().to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (fc_in): Linear(in_features=30, out_features=600, bias=True)\n",
       "  (fc_h1): Linear(in_features=600, out_features=400, bias=True)\n",
       "  (fc_h2): Linear(in_features=400, out_features=200, bias=True)\n",
       "  (fc_h3): Linear(in_features=200, out_features=70, bias=True)\n",
       "  (fc_out): Linear(in_features=70, out_features=30, bias=True)\n",
       "  (activation): ReLU()\n",
       "  (activation2): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.apply(weights_init)\n",
    "classifier.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "TensorRealOuts = torch.full((len(slowa), 30), 1, requires_grad=False).float().to(\"cuda:0\")\n",
    "TensorFakeOuts = torch.full((len(slowa), 30), 0, requires_grad=False).float().to(\"cuda:0\")\n",
    "\n",
    "TensorOuts = torch.cat((TensorRealOuts, TensorFakeOuts), 0)\n",
    "\n",
    "print(TensorRealOuts)\n",
    "print(TensorFakeOuts)\n",
    "\n",
    "print(TensorOuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "optimizerGenerator = optim.Adam(generator.parameters(), lr=1e-3)\n",
    "optimizerClassifier = optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "\n",
    "print(optimizerGenerator)\n",
    "print(optimizerClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCELoss()\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "print(criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeneratorLosses = []\n",
    "ClassifierLosses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-872dcf5afee8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mzbuduj_slowo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslowo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlongestwrd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mslowo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mslowa\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-872dcf5afee8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mzbuduj_slowo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslowo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlongestwrd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mslowo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mslowa\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-111c2fa514da>\u001b[0m in \u001b[0;36mzbuduj_slowo\u001b[1;34m(word, embeddings, longestword, odleglosc_do_pustego)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m__\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreszta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mslowo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslate_char_to_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"🈳\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0modleglosc_do_pustego\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0modleglosc_do_pustego\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpusty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'🈳'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslowo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-e26439f20aa6>\u001b[0m in \u001b[0;36mtranslate_char_to_embedding\u001b[1;34m(char, embeddings, odleglosc_do_pustego, pusty)\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mwartosci\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwartosci\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mget_closest_char_from_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwartosci\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0modleglosc_do_pustego\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m                 \u001b[1;31m#np.random.seed(random.randint(0, 100000))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mwartosci\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwymiarowosc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-c6b802f2dff4>\u001b[0m in \u001b[0;36mget_closest_char_from_space\u001b[1;34m(vectors, embeddings, odleglosc_do_pustego, pusty)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mvecid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0msuma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuma\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvecid\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mvectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvecid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0modleglosc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(np.array([zbuduj_slowo(slowo, embeddings, longestwrd) for slowo in slowa])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-0ebbd610a880>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mTensorRealIns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mzbuduj_slowo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslowo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlongestwrd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mslowo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mslowa\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslowa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mTensorSeeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslowa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mTensorFakeIns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorSeeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mTensorIns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorRealIns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensorFakeIns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-0ebbd610a880>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mTensorRealIns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mzbuduj_slowo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslowo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlongestwrd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mslowo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mslowa\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslowa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mTensorSeeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslowa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mTensorFakeIns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorSeeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mTensorIns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorRealIns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensorFakeIns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-111c2fa514da>\u001b[0m in \u001b[0;36mzbuduj_slowo\u001b[1;34m(word, embeddings, longestword, odleglosc_do_pustego)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m__\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreszta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mslowo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslate_char_to_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"🈳\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0modleglosc_do_pustego\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0modleglosc_do_pustego\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpusty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'🈳'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslowo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-e26439f20aa6>\u001b[0m in \u001b[0;36mtranslate_char_to_embedding\u001b[1;34m(char, embeddings, odleglosc_do_pustego, pusty)\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mwartosci\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwartosci\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mget_closest_char_from_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwartosci\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0modleglosc_do_pustego\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m                 \u001b[1;31m#np.random.seed(random.randint(0, 100000))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mwartosci\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwymiarowosc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-c6b802f2dff4>\u001b[0m in \u001b[0;36mget_closest_char_from_space\u001b[1;34m(vectors, embeddings, odleglosc_do_pustego, pusty)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mvecid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0msuma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuma\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvecid\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mvectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvecid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0modleglosc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    TensorRealIns = torch.tensor(np.array([zbuduj_slowo(slowo, embeddings, longestwrd) for slowo in slowa]), requires_grad=False).reshape(len(slowa), -1).float().to(\"cuda:0\")\n",
    "    TensorSeeds = torch.rand(len(slowa), 300, requires_grad=False).float().to(\"cuda:0\")\n",
    "    TensorFakeIns = generator(TensorSeeds)\n",
    "    TensorIns = torch.cat((TensorRealIns, TensorFakeIns.detach()), 0)\n",
    "    \n",
    "    classifier.train()\n",
    "    optimizerClassifier.zero_grad()\n",
    "    \n",
    "    y_ = classifier(TensorIns)\n",
    "    lossClassifier = criterion(y_, TensorOuts)\n",
    "    \n",
    "    lossClassifier.backward()\n",
    "    optimizerClassifier.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    generator.train()\n",
    "    optimizerGenerator.zero_grad()\n",
    "    \n",
    "    y_ = classifier(TensorFakeIns)\n",
    "    lossGenerator = criterion(y_, TensorRealOuts)# + myloss(embeddings, TensorFakeIns.cpu().detach().numpy(), odleglosc_do_pustego=4)\n",
    "    \n",
    "    lossGenerator.backward()\n",
    "    optimizerGenerator.step()\n",
    "    \n",
    "    GeneratorLosses.append(lossGenerator)\n",
    "    ClassifierLosses.append(lossClassifier)\n",
    "    \n",
    "#     if lossGenerator < 0.2:\n",
    "#         break\n",
    "\n",
    "#     faked = TensorFakeIns[0].cpu().detach().numpy()\n",
    "#     xx = outputsieci_na_znaki(embeddings, faked, odleglosc_do_pustego=4)\n",
    "    \n",
    "#     wszystkieznakowe = 0\n",
    "    \n",
    "#     for znak in xx:\n",
    "#         if znak in list(embeddings.keys()):\n",
    "#             wszystkieznakowe = wszystkieznakowe + 1\n",
    "    \n",
    "#     if wszystkieznakowe == len(xx):\n",
    "#         break\n",
    "            \n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        print(lossClassifier, lossGenerator)\n",
    "        #print(TensorSeeds)\n",
    "        #print(TensorFakeIns[0])\n",
    "        faked = TensorFakeIns[0].cpu().detach().numpy()\n",
    "        print(outputsieci_na_znaki(embeddings, faked, odleglosc_do_pustego=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots()\n",
    "ax.plot([x for x in range(len(GeneratorLosses))], GeneratorLosses, \".\", [x for x in range(len(GeneratorLosses))], ClassifierLosses, \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testowanie generatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for __ in range(20):\n",
    "        noise = torch.randn(300).to(\"cuda:0\")\n",
    "        fake = generator(noise)\n",
    "        faked = fake.cpu().detach().numpy()\n",
    "        print(outputsieci_na_znaki(embeddings, faked, odleglosc_do_pustego=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.tensor([0,0.99,0.1554,0.73766,0.1554,0,0.1515,0.1515,0.1515,0.1515,0.1515,0.1515,0.1515,0.1515,0.1515,0.1515,0.1515,0.1515,0.1515,0.1515]).float().to(\"cuda:0\")\n",
    "fake = generator(noise)\n",
    "faked = fake.cpu().detach().numpy()\n",
    "print(outputsieci_na_znaki(embeddings, faked, odleglosc_do_pustego=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GAN.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
