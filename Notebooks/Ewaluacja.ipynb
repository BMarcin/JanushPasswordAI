{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook służący do ewaluacji\n",
    "W nim chodzi o wygenerowanie X haseł na podstawie nauczonego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import multiprocessing\n",
    "from datetime import datetime\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1010101011)\n",
    "random.seed(1010101011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterLSTM(nn.Module):\n",
    "    def __init__(self, vocabsize, lstmlayers, hiddensize):\n",
    "        super(CharacterLSTM, self).__init__()\n",
    "        \n",
    "        ## WARSTWY\n",
    "        self.embd = nn.Embedding(vocabsize, vocabsize)\n",
    "        self.LSTM1 = nn.GRU(vocabsize, hiddensize, lstmlayers, batch_first=True, bidirectional=True)\n",
    "        self.linear_ins = nn.Linear(2*hiddensize, vocabsize)\n",
    "\n",
    "        self.drop = nn.Dropout(p=0.1)\n",
    "        \n",
    "        ## OUTS\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x, hidden, NLL=True): \n",
    "        # WEJSCIE\n",
    "        y0 = self.embd(x)\n",
    "        \n",
    "        # LSTM\n",
    "        y, h1_ = self.LSTM1(y0, hidden)\n",
    "        \n",
    "        y = self.drop(y)\n",
    "        \n",
    "        # LINEAR OUT 1\n",
    "        y = self.linear_ins(y)\n",
    "        \n",
    "        if NLL:\n",
    "            y = self.softmax(y[:,-1])\n",
    "        \n",
    "        # zwrot\n",
    "        return y, h1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Odtworzenie zmiennych uczenia \"\"\"\n",
    "zmienne = torch.load(\"../models/zmienne_modelu.pth\")\n",
    "\n",
    "chartoidx = zmienne[0]\n",
    "\n",
    "longestword = zmienne[1]\n",
    "lstms = zmienne[2]\n",
    "hiddensize = zmienne[3]\n",
    "\n",
    "chlstm = torch.load(\"../models/NEWDS_START_bezrelu_lstm_15_hidden_40_cosine1e-8_rmsprop1e-7_50epoch_loss_2.423110246658325.pt\", map_location=device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Działa dość wolno, słabo zoptymalizowane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6778ea0050a64f9c9b5c9e28985f016f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=140000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "chardict = list(chartoidx.keys())\n",
    "\n",
    "\"\"\" parametr randomizacji \"\"\"\n",
    "\"\"\" im wyższa wartość tym bardziej randomowe i mniejsze odwzorowanie  \"\"\"\n",
    "temperature = 0.8\n",
    "\n",
    "\n",
    "plikhasel = open(\"../haslaAI.txt\", \"a\", encoding=\"utf8\")\n",
    "\n",
    "hiddens = torch.zeros(2*lstms, 1, hiddensize).to(device)\n",
    "\n",
    "for _ in tqdm_notebook(range(140000)):\n",
    "    with torch.no_grad():\n",
    "        lastchar = 0\n",
    "        cnt = 0\n",
    "\n",
    "        chlstm.eval()\n",
    "        znaki = [chartoidx[\"<START>\"]]\n",
    "        bazastart = len(znaki)\n",
    "\n",
    "        for __ in range(longestword - bazastart+1):\n",
    "            znaki.append(chartoidx[\"<EMPTY>\"])\n",
    "\n",
    "        for item in range(longestword - bazastart+1):\n",
    "            x = torch.Tensor(znaki).long().to(device).view(1, -1)\n",
    "\n",
    "            out, _ = chlstm(x, hiddens, NLL=False)\n",
    "            \n",
    "            zwrot = out[:,-1].view(-1)\n",
    "            \n",
    "            \"\"\" Rozkład wielomianowy \"\"\"\n",
    "            exped = zwrot.data.div(temperature).exp()\n",
    "            top_i = torch.multinomial(exped, 1)\n",
    "            charid = top_i[0]\n",
    "\n",
    "            znaki[item+bazastart] = charid\n",
    "\n",
    "\n",
    "        slowo = \"\"\n",
    "        for item in znaki:\n",
    "            if item != 0 and item != 1:\n",
    "                slowo+=chardict[item]\n",
    "\n",
    "#         print(slowo)\n",
    "        plikhasel.write(slowo+\"\\n\")\n",
    "plikhasel.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
