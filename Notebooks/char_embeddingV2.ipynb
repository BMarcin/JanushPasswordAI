{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "--np-oHc2RVM"
   },
   "source": [
    "# Char Embedding dla JanushPasswordGAN\n",
    "*Notebook mia by kr贸tszy *\n",
    "\n",
    "## Zadanie\n",
    "Na podstawie wszystkich hase wyznaczy wartoci do nauki sieci neuronowej. Po nauczeniu sieci otrzymamy wektory zale偶noci dla poszczeg贸lnych znak贸w.\n",
    "\n",
    "## Podzadania\n",
    "### Znalezienie unikalnych znak贸w w zbiorze alfabetu hase\n",
    "Bierzemy wszystkie hasa i tworzymy zbi贸r unikalnych znak贸w, jakie byy tam u偶yte.\n",
    "##### Info\n",
    "Funkcja dodatkowo musi porzdkowa znaki wedug kolejnoci alfabetycznej (liczby bd na pocztku).\n",
    "##### Przykad\n",
    "Nasz alfabet skada si ze s贸w: \"abc\" oraz \"abbd\". Na wyjciu otrzymamy wektor: \n",
    "```\n",
    "['a', 'b', 'c', 'd']\n",
    "```\n",
    "\n",
    "### Dla ka偶dego znaku wyznaczy One Hot Vector\n",
    "Dla ka偶dego unikalnego znaku (dlatego wymagana jest funkcja powy偶ej) wyznaczamy one hot vector.\n",
    "#### Co to jest one hot vector?\n",
    "One hot vector jest to wektor 0 i 1 (zer i jedynek), kt贸ry bdzie jednoznacznie identyfikowa ka偶dy znak z podanego alfabetu. W ka偶dym takim wektorze znajduje si jedna 1 (jedynka) i ka偶dy jest dugoci wektora unikalnych znak贸w alfabetu. Jedynka wystpuje w tym miejscu, pod kt贸rym znajduje si dany znak w wektorze unikalnych znak贸w.\n",
    "##### Info\n",
    "W tak utworzonej przestrzenii mo偶na bdzie wyr贸偶ni wektor pusty - nie oznaczajcy 偶adnego ze znak贸w. Wektor taki bdzie skada si z samych 0 (zer).\n",
    "##### Przykad\n",
    "Nasz alfabet skada si ze s贸w: \"abc\" oraz \"abbd\". Dla takiego alfabetu wyznaczamy unikalne znaki (funkcja powy偶ej) i otrzymujemy wektor ['a', 'b', 'c', 'd']. Zgodnie z definicj one hot vector'a wektor ka偶dego znaku bdzie dugoci wektora unikalnych znak贸w, czyli w tym przypadku 4. Wyznaczone one-hot-vectory dla tego przykadu powinny wyglda nastpujco:\n",
    "```\n",
    "{\n",
    "    'a': [1, 0, 0, 0],\n",
    "    'b': [0, 1, 0, 0],\n",
    "    'c': [0, 0, 1, 0],\n",
    "    'd': [0, 0, 0, 1]\n",
    "}\n",
    "```\n",
    "\n",
    "### Dla ka偶dego znaku wyznaczy unikalne ID klasy - numeracja\n",
    "To zadanie jest dosy proste. Sie wyznaczajca Character Embedding bdzie wykorzystywa funkje SoftMax oraz CrossEntropy (wicej info poni偶ej ). Funkcja CrossEntropy jako jeden z argument贸w przyjmuje \"klasy\" do kt贸rych ma dopasowa wyniki. W naszym przypadku jedna klasa to bdzie jeden znak. Cae zadanie sprowadza si jedynie do utworzenia sownika, w kt贸rym pod indeksami znajdziemy znaki, a jako ich wartoci kolejne cyfry.\n",
    "###### Przykad\n",
    "```\n",
    "{\n",
    "    'a': 0,\n",
    "    'b': 1,\n",
    "    'c': 2\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "### Dla ka偶dego hasa wyznaczy wektor one hot wektor贸w\n",
    "W tym zadaniu dosownie musimy przepisa haso skadajce si ze znak贸w na wektor one hot vector'贸w. Chodzi o to, by stworzy reprezentacj ka偶dego hasa w formie bardziej siecio neuronowej .\n",
    "##### Przykad\n",
    "Nasz alfabet skada si ze s贸w: \"abc\" oraz \"abbd\". Wyznaczamy dla niego unikalne znaki wg. pierwszej funkcji z tego notebook'a i nastpnie one hot vectory dla ka偶dego znaku (one hot vector'y bdzie trzeba poda jako argument wejciowy dla tej funkcji). Na wyjciu powinnimy otrzyma dwie macierze: jedn dla slowa \"abc\" i drug dla \"abbd\".\n",
    "```\n",
    "[\n",
    "    [\n",
    "        [1, 0, 0, 0], #znak \"a\"\n",
    "        [0, 1, 0, 0], #znak \"b\"\n",
    "        [0, 0, 1, 0]  #znak \"c\"\n",
    "    ],\n",
    "    [\n",
    "        [1, 0, 0, 0], #znak \"a\"\n",
    "        [0, 1, 0, 0], #znak \"b\"\n",
    "        [0, 1, 0, 0], #znak \"b\"\n",
    "        [0, 0, 0, 1]  #znak \"d\"\n",
    "    ]\n",
    "]\n",
    "    \n",
    "```\n",
    "\n",
    "###  Wyznaczenie wielkoci okna dla sieci CE (Character Embedding)\n",
    "Chodzi o znalezienie minimalnej wielkoci okna, kt贸ra pozwoli na prawidowe wykonanie CE.\n",
    "\n",
    "#### Jak to ma dziaa?\n",
    "CE ma za zadanie wyznaczy zale偶noci midzy literami. Z tego te偶 powodu nale偶y ka偶de sowo przepuci przez SSN (Sztuczn Sie Neuronow) na kilka przypadk贸w (bdzie ich tyle ile jest znak贸w w danym sowie). W sieci musi si pojawi co na wejciu i co na wyjciu. Jako, 偶e SSN ma si nauczy zale偶noci midzy znakami, to bdziemy operowa na znakach. Dla pierwszego przypadku zabieramy ze sowa ostatni znak i umieszczamy jego one hot vector na wyjciu. Nastpnie wyznaczamy liczb wej do sieci, a bdzie ich dwukrotna liczba znak贸w, kt贸re zostay po zabraniu tego ostatniego. Cae wejcie dzielimy na dwie czci - g贸rne i dolne. Do g贸rnego trafi one hot vector'y znak贸w poprzedzajcych, ten kt贸ry jest na wyjciu, a reszt (cz doln) uzupeniamy wartociami pustymi (one hot vector z samymi 0 (zerami)). Dla kolejnego przypadku przesuwamy ka偶dy znak \"w d贸\". To oznacza, 偶e na pierwszym neuronie wejciowym bdzie teraz one hot vector zerowy, kt贸ry by w poprzednim przypadku w dolnej czci, a na drugim wejciu znak, kt贸ry by wczeniej na pierwszym wejciu. Na wyjcie sieci przeskakuje znak poprzedzajcy ten, kt贸ry si znajdowa wczeniej na wyjciu. Znak, kt贸ry znajdowa si na wyjciu przeskakuje do dolnej czci na pierwsze wejcie tej czci.\n",
    "\n",
    "#### Wic gdzie w tym wszystkim wielko okna?\n",
    "Wielko okna musi pozwala na swobodne wyznaczenie wszystkich przypadk贸w, tak by znaki z kt贸rych skada si dane sowo mogby by poprzerzucane.\n",
    "\n",
    "##### Przykad\n",
    "Poni偶szy rysunek obrazuje wyznaczenie wielkoci okna i rozpisanie przypadk贸w dla sowa \"abc\". Jak widzimy dla sowa skadajcego si z 3 znak贸w wielko okna musi wynosi 4.\n",
    "![Opis trzech przypadk贸w](https://i.imgur.com/TQOwdIX.png)\n",
    "\n",
    "### CBOW\n",
    "Stworzenie sieci w stylu CBOW, by wyznaczy zale偶noci midzy znakami i stworzy wektory dla ka偶dego znaku.\n",
    "\n",
    "Schemat sieci\n",
    "![Schemat CBOW](https://i.imgur.com/jdTjKTS.png)\n",
    "\n",
    "#### Oznaczenia\n",
    "tx - tensor wejciowy zawierajcy one hot vector (array).\n",
    "\n",
    "h1 - neuron warstwy ukrytej.\n",
    "\n",
    "y1 - tensor wyjciowy zawierajcy one hot vector (array).\n",
    "\n",
    "\n",
    "#### Waciwie po co to cae cibo?\n",
    "CBOW ma za zadanie wyznaczy wektory dla znak贸w.\n",
    "\n",
    "#### Dobra, to gdzie w tej sieci te wektory?\n",
    "Wektory dla znak贸w wejciowych opisuj wagi znajdujce si pomidzy warstw ukryt, a wyjciem.\n",
    "##### Przykad\n",
    "Dla przykadu sowa \"abc\" bdzie nastpujcy opis wektor贸w dla znak贸w\n",
    "```\n",
    "[wh1y1, wh2y1, wh3y1], #znak \"a\"\n",
    "[wh1y2, wh2y2, wh3y2], #znak \"b\"\n",
    "[wh1y2, wh2y3, wh3y3]  #znak \"c\"\n",
    "```\n",
    "\n",
    "#### \"Mechanika\" CBOW\n",
    "W sieci mo偶emy zaobserwowa swego rodzaju kompresj danych i ich dekompresj (dla przykadu \"abc\" nie zaobserwujemy tego efektu). Kompresja nastpuje pomidzy warstw wejciow, a warstw ukryt (z wielu danych robimy mniejsz ich ilo). Dekompresja nastpuje midzy warstw ukryt, a warstw wyjciow (z maej iloci danych robimy ich wiksz porcj). Daje nam to mo偶liwo odtwarzania(rownoznaczne z dekompresj) sowa na podstawie wektor贸w. Liczba wektor贸w bdzie wynosi tyle ile jest neuron贸w w warstwie ukrytej.\n",
    "\n",
    "#### Ale jak to wektory maj opisywa wagi, skoro wagi si ustal na samym kocu uczenia i dla wszystkich znak贸w bd te same? aka. yyyy jakie to ma zale偶noci?\n",
    "\n",
    "Sam miaem troch problem贸w w zrozumieniu na jakiej podstawie mo偶na stwierdzi kt贸ry wektor wag znajdujcych si midzy warstw ukryt, a warstw wyjciow odpowiada kt贸remu znakowi. Odpowied藕 jest banalnie prosta. Nie patrzmy na metod CBOW, jako dziaajc od lewej do prawej tylko na odwr贸t. Dla danego znaku, kt贸ry jest na wyjciu znaczenie w obliczeniach ma tylko jeden wektor, ze wzgldu na kodowanie znaku jako one hot vector - ten, dla kt贸rego jako wynik przelicze (warstwy ukrytej i wag) wynosi 1. Dla reszty wyniki maj wynosi 0. Oto caa magia .\n",
    "\n",
    "##### Przykad \n",
    "![Przykad1](https://i.imgur.com/pnwQpDV.png)\n",
    "\n",
    "### Kompletny schemat sieci do wyznaczenia wektor贸w \n",
    "![Schemat sieci do wyznaczenia wektor贸w](https://i.imgur.com/r2sg5ZP.png)\n",
    "\n",
    "[Dokumentacja funkcji CrossEntropyLoss()](https://pytorch.org/docs/stable/nn.html#crossentropyloss)\n",
    "\n",
    "#### Opis wg. mnie\n",
    "Kombinacja funkcji Softmax i CrossEntropy ma za zadanie wartociom uzyskanych z sieci (y1,y2,y3,y4) przypisa warto przynale偶noci do danej klasy (podzadanie wyznaczenia klas). Im ni偶sza warto tym warto bardziej przynale偶y do danej klasy.\n",
    "\n",
    "##### Przykad\n",
    "Jak wida wy偶ej w schemacie dla klasy 'a' (klasa znaku 'a') najni偶sz warto, co stanowi o przynale偶noci testowanej klasy. Testowanie klasy polega na obliczeniu wartoci 'loss' za pomoc CrossEntropyLoss().\n",
    "\n",
    "#### Do czego waciwie w CE potrzebujemy Softmax'u i CrossEntropy?\n",
    "W sumie to jedynie do lepszego procesu uczenia i jak bymy sie uparli to mo偶emy sobie posprawdza jakie jest prawdopodobiestwo wystpienia jakiego znaku po danej sekwencji znak贸w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4c3bfXZQy8jB"
   },
   "source": [
    "# Kod robicy magi part1 - przygotowanie wartoci do sieci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PzJ8syRPzBb2"
   },
   "source": [
    "## Importy\n",
    "Importujemy bibliotek Numpy, kt贸ra jest potrzebna dla czci pierwszej naszego CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PchVJKMi2NwW"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ilVJUQaEzGCz"
   },
   "source": [
    "## Funkcje\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nEQYf-gzzJjZ"
   },
   "source": [
    "### Znalezienie unikalnych znak贸w\n",
    "Wejciem bdzie wektor wyraz贸w\n",
    "Wyjciem jest wektor unikalnych znak贸w\n",
    "\n",
    "Lepiej rozpisany kod, co by atwiej go zrozumie:\n",
    "```\n",
    "def find_unique(wektor):\n",
    "  zwrot = []\n",
    "  for word in wektor:\n",
    "    for letter in word:\n",
    "      if letter not in zwrot:\n",
    "        zwrot.append(letter)\n",
    "  return zwrot\n",
    "  #PS. gdzie tu jeszcze sorted() by musiao by, ale jako 偶e edytuje to miesic p贸藕niej to nwm \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1946,
     "status": "ok",
     "timestamp": 1554534013817,
     "user": {
      "displayName": "Marcin Borzymowski",
      "photoUrl": "https://lh3.googleusercontent.com/-cn5cz3qzzCE/AAAAAAAAAAI/AAAAAAAAeY4/AlgtNekgbTE/s64/photo.jpg",
      "userId": "08472151881814245002"
     },
     "user_tz": -120
    },
    "id": "I6FONpF9zSzX",
    "outputId": "9eed8dbe-da98-46a0-d8f6-215e447aa526"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'b', 'c', 'd', 'e', 'f'], dtype='<U1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_unique(wektor):\n",
    "    return np.array(sorted(list({letter for word in wektor for letter in word})))\n",
    "  \n",
    "find_unique(['abcf', 'abcd', 'abcde'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mSIiGizV1BDI"
   },
   "source": [
    "### Wyznaczenie One Hot Vectors\n",
    "Wejciem jest wektor unikalnych znak贸w\n",
    "\n",
    "Wyjciem jest sownik z one hot vector'贸w podpisanych pod znak, kt贸ry reprezentuj\n",
    "\n",
    "Lepiej rozpisany kod, co by atwiej go zrozumie\n",
    "```\n",
    "def make_one_hot_vectors(wektor):\n",
    "  zwrot = {}\n",
    "  for cnt in range(len(wektor)):\n",
    "    vec = []\n",
    "    for ii in range(len(wektor)):\n",
    "      if ii == cnt:\n",
    "        vec.append(1)\n",
    "      else:\n",
    "        vec.append(0)\n",
    "    zwrot[wektor[cnt]] = vec\n",
    "  return zwrot\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1939,
     "status": "ok",
     "timestamp": 1554534013818,
     "user": {
      "displayName": "Marcin Borzymowski",
      "photoUrl": "https://lh3.googleusercontent.com/-cn5cz3qzzCE/AAAAAAAAAAI/AAAAAAAAeY4/AlgtNekgbTE/s64/photo.jpg",
      "userId": "08472151881814245002"
     },
     "user_tz": -120
    },
    "id": "0bTer6YC1FT8",
    "outputId": "94d7f803-2f19-41cf-e275-564c21f76565"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [1, 0, 0, 0, 0],\n",
       " 'b': [0, 1, 0, 0, 0],\n",
       " 'c': [0, 0, 1, 0, 0],\n",
       " 'd': [0, 0, 0, 1, 0],\n",
       " 'e': [0, 0, 0, 0, 1]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_one_hot_vectors(wektor):\n",
    "    return {wektor[cnt]:[1 if ii == cnt else 0 for ii in range(len(wektor))] for cnt in range(len(wektor))}\n",
    "  \n",
    "make_one_hot_vectors(['a', 'b', 'c', 'd', 'e'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wyznaczenie ID klasy\n",
    "Wejciem s wyznaczone wczeniej one hot vectory dla unikalnych znak贸w\n",
    "Wyjciem jest sownik, kt贸rego kluczami s znaki dla kt贸rych wyznaczono one hot vectory, a kluczami ID klas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_class_id(one_hot_vectors):\n",
    "    zwrot = {}\n",
    "    \n",
    "    for cnt, one_hot_vector in enumerate(one_hot_vectors):\n",
    "        zwrot[one_hot_vector] = cnt\n",
    "        \n",
    "    return zwrot\n",
    "\n",
    "make_class_id(make_one_hot_vectors(['a', 'b', 'c', 'd', 'e']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4gd4VzKq_pvc"
   },
   "source": [
    "### Wyznaczenie wektora one hot wektor贸w\n",
    "Wejcie to sowo oraz sownik wczeniej wyznaczonych one hot wektor贸w dla znak贸w\n",
    "\n",
    "Wyjcie to tablica one hot vector贸w dla sowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1932,
     "status": "ok",
     "timestamp": 1554534013819,
     "user": {
      "displayName": "Marcin Borzymowski",
      "photoUrl": "https://lh3.googleusercontent.com/-cn5cz3qzzCE/AAAAAAAAAAI/AAAAAAAAeY4/AlgtNekgbTE/s64/photo.jpg",
      "userId": "08472151881814245002"
     },
     "user_tz": -120
    },
    "id": "k9ZnB1OP_uti",
    "outputId": "4bc14e25-a7cf-40c5-d970-e58691428880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]]\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]]\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "def make_word_vector(word, onehotvectors):\n",
    "    return np.array([onehotvectors[letter] for letter in word])\n",
    "\n",
    "for slowo in ['abc', 'abcd', 'abcde']:\n",
    "    print(make_word_vector(slowo, make_one_hot_vectors(['a', 'b', 'c', 'd', 'e'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AaokxM4dA_MB"
   },
   "source": [
    "### Wyznaczenie wielkoci okna oraz wszelkich kombinacji dla sowa w CE aka. wyznaczenie wartoci do nauki sieci\n",
    "Generalnie byo du偶o rozkmin jak to zrobi, bo du偶o si dzieje w tym. \n",
    "\n",
    "Musimy przepisa nasze wektory one hot wektor贸w na bezporednie wartoci, kt贸re bd podane do sieci zachowujac wszelkie kombinacje znak贸w. \n",
    "\n",
    "Zobrazowaem dziaanie funkcji na pierwszym obrazie w tym notebook'u - tworzy ona kombinacje wartoci.\n",
    "\n",
    "Wejciem jest one hot wektor sowa\n",
    "Wyjciem jest:\n",
    "+ inputs dla sieci neuronowej\n",
    "+ outputs dla sieci neuronowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1245,
     "status": "ok",
     "timestamp": 1554536630896,
     "user": {
      "displayName": "Marcin Borzymowski",
      "photoUrl": "https://lh3.googleusercontent.com/-cn5cz3qzzCE/AAAAAAAAAAI/AAAAAAAAeY4/AlgtNekgbTE/s64/photo.jpg",
      "userId": "08472151881814245002"
     },
     "user_tz": -120
    },
    "id": "r79u8xpVBHH3",
    "outputId": "667e2d57-d3eb-487e-cf76-c6dfc74c259c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEJSCIA\n",
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 0 0]\n",
      "  [0 1 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 0 0]\n",
      "  [0 0 1]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 1 0]\n",
      "  [0 0 1]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n",
      "\n",
      "WYJSCIA\n",
      "[[0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def get_min_window_size(wordlen):\n",
    "    return 2*(wordlen-1)\n",
    "\n",
    "\n",
    "def make_pre_char_embedding(wektoryslow, windowsize, fill = 0):\n",
    "    \n",
    "    ''' definicje wejsc i wyjsc '''\n",
    "    inns = []\n",
    "    outs = []\n",
    "    \n",
    "    ''' lecimy po kazdym wektorze one hot vectorow '''\n",
    "    for wektor in wektoryslow:\n",
    "        ''' dla kazdego wektora sprawdzamy minimalna dlugosc okna, by sprawdzic czy jest zgodnosc z argumentem \"windowsize\" '''\n",
    "        min_window_size = get_min_window_size(len(wektor))\n",
    "\n",
    "        ''' sprawdzenie poprawnoci podanych danych '''\n",
    "        if min_window_size > windowsize:\n",
    "            raise Exception(\"Bledna wielkosc okna, powinna wynosic minimum: \" + str(min_window_size) + \", a mam: \" + str(windowsize))\n",
    "        \n",
    "        ''' nie obsugujemy s贸w kr贸tszych od 3 '''\n",
    "        if len(wektor) < 3:\n",
    "            raise Exception(\"Wektor zbyt krotki. Dlugosc powinna wynosic minimum 3\")\n",
    "        \n",
    "        ''' lokalne wartoci inputs i outputs '''\n",
    "        ''' w nich  przechowujemy \"kombinacje\" dla wszystkich znak贸w jednego sowa'''\n",
    "        inputs = []\n",
    "        outputs = []\n",
    "\n",
    "        ''' tutaj jest bardzo wa偶na warto wyliczana '''\n",
    "        ''' majc wielko okna = 8, a sowo wielkoci 3 musimy tak uo偶y znaki tego sowa, '''\n",
    "        ''' by znajdoway si one na rodkowych pozycjach '''\n",
    "        ''' ta warto jest indeksem, o kt贸ry nale偶y przesun znaki sowa '''\n",
    "        beginfill = int((windowsize-min_window_size)/2)\n",
    "\n",
    "        ''' outed zawiera index one hot vectora sowa, kt贸re znajduje si na wyjciu sieci '''\n",
    "        outed = len(wektor)- 1\n",
    "        \n",
    "        ''' zbudowanie pierwotnego okna '''\n",
    "        ''' pocztek okna wypeniamy one hot vectorami znak贸w,'''\n",
    "        ''' a reszt zerami '''\n",
    "        window = [wektor[x-beginfill] if (x < len(wektor)+beginfill-1) and (x > beginfill - 1) else [fill for xx in range(len(wektor[0]))] for x in range(windowsize)]\n",
    "\n",
    "        ''' dodajemy do tablic '''\n",
    "        inputs.append(window)\n",
    "        outputs.append(wektor[outed])\n",
    "\n",
    "        ''' i tutaj g贸wna ptla przeksztace '''\n",
    "        ''' du偶o rozkmin byo jak zrobi wszystkie kombinacje dla danego sowa, '''\n",
    "        ''' ale python jest wspaniay je偶eli chodzi o operacje na tablicach, '''\n",
    "        ''' wic przesunicie wszystkich znak贸w o jeden do przodu to po prostu pierwsza instrukcja ptli  '''\n",
    "        ''' nastpnie robimy podmiank wartoci wyjciowej '''\n",
    "        ''' i zamieniamy indeks wyjcia '''\n",
    "        for x in range(len(wektor) - 1):\n",
    "            window = [window[-1]] + window[:-1]\n",
    "            window[outed+beginfill+x] = wektor[outed]\n",
    "            outed = outed - 1\n",
    "            #print(window)\n",
    "\n",
    "            inputs.append(window)\n",
    "            outputs.append(wektor[outed])\n",
    "        \n",
    "        \n",
    "        ''' inputy i outputy dla konkretnego sowa dodajemy do input贸w i output贸w caociowych '''\n",
    "        inns = inns + inputs\n",
    "        outs = outs + outputs\n",
    "    \n",
    "    return np.array(inns, dtype=int), np.array(outs, dtype=int)\n",
    "    #return inputs, outputs\n",
    "\n",
    "inputs, outputs = make_pre_char_embedding([make_word_vector(\"abc\", make_one_hot_vectors(find_unique(['abc'])))], 8)\n",
    "#inputs, outputs = make_pre_char_embedding([make_word_vector(\"abc\", make_one_hot_vectors(find_unique(['abc']))), make_word_vector(\"abcde\", make_one_hot_vectors(find_unique(['abcde'])))], 8)\n",
    "print(\"WEJSCIA\")\n",
    "print(inputs)\n",
    "print(\"\\nWYJSCIA\")\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bIBUU7GSjixY"
   },
   "source": [
    "### Funkcje pomocnicze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jMtV7x_Cjkc7"
   },
   "outputs": [],
   "source": [
    "def find_longest_word(wektor):\n",
    "    longest = 0\n",
    "    for slowo in wektor:\n",
    "        if len(slowo) > longest:\n",
    "            longest = len(slowo)\n",
    "    return longest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcje tumaczce r贸偶ne postacie znak贸w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate_class_to_sign(classid, classdict):\n",
    "    for item in classdict:\n",
    "        if classdict[item] == classid:\n",
    "            return item\n",
    "        \n",
    "translate_class_to_sign(1, make_class_id(make_one_hot_vectors(['a', 'b', 'c', 'd', 'e'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate_sign_to_class(sign, classdict):\n",
    "    return classdict[sign]\n",
    "\n",
    "translate_sign_to_class('b', make_class_id(make_one_hot_vectors(['a', 'b', 'c', 'd', 'e'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate_one_hot_vector_to_sign(one_hot_vector, one_hot_vectors):\n",
    "    for item in one_hot_vectors:\n",
    "        if np.array_equal(np.array(one_hot_vectors[item]), one_hot_vector):\n",
    "            return item\n",
    "        \n",
    "translate_one_hot_vector_to_sign(np.array([0,1,0,0,0]), make_one_hot_vectors(['a', 'b', 'c', 'd', 'e']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "19rc9MjJcreR"
   },
   "source": [
    "# Job/Magic\n",
    "## Info\n",
    "\n",
    "Jest tutaj mae demo prezentujce dziaanie funkcji, kt贸re zostay utworzone wy偶ej "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7058
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1050,
     "status": "ok",
     "timestamp": 1554537279606,
     "user": {
      "displayName": "Marcin Borzymowski",
      "photoUrl": "https://lh3.googleusercontent.com/-cn5cz3qzzCE/AAAAAAAAAAI/AAAAAAAAeY4/AlgtNekgbTE/s64/photo.jpg",
      "userId": "08472151881814245002"
     },
     "user_tz": -120
    },
    "id": "AdMImBQvcte5",
    "outputId": "d49e9004-a235-4edb-d929-21129d2c7e7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIKALNE ZNAKI\n",
      "['a' 'b' 'c' 'd' 'e']\n",
      "\n",
      "\n",
      "ONE-HOT-VECTORS\n",
      "a [1, 0, 0, 0, 0]\n",
      "b [0, 1, 0, 0, 0]\n",
      "c [0, 0, 1, 0, 0]\n",
      "d [0, 0, 0, 1, 0]\n",
      "e [0, 0, 0, 0, 1]\n",
      "\n",
      "\n",
      "HASLA ZAPISANE ONE-HOT-WEKTORAMI\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]]\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]]\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]]\n",
      "\n",
      "\n",
      "NAJDLUZSZY WYRAZ:  5\n",
      "\n",
      "\n",
      "MIN WINDOW SIZE:  8\n",
      "\n",
      "\n",
      "INPUTY DLA SIECI\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 0]]\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 0]]\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]]\n",
      "\n",
      "\n",
      "OUTPUTY DLA SIECI\n",
      "[0 0 1 0 0]\n",
      "[0 1 0 0 0]\n",
      "[1 0 0 0 0]\n",
      "[0 0 0 1 0]\n",
      "[0 0 1 0 0]\n",
      "[0 1 0 0 0]\n",
      "[1 0 0 0 0]\n",
      "[0 0 0 0 1]\n",
      "[0 0 0 1 0]\n",
      "[0 0 1 0 0]\n",
      "[0 1 0 0 0]\n",
      "[1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "''' lista naszych slow '''\n",
    "#hasla = [\"123456\", \n",
    "#         \"neo24\", \n",
    "#         \"qwerty\", \n",
    "#         \"monika\", \n",
    "#         \"1235\", \n",
    "#         \"misiek\"]\n",
    "\n",
    "hasla = [\"abc\", \"abcd\", \"abcde\"]\n",
    "\n",
    "\n",
    "\n",
    "''' wyszukujemy unikalne znaki i tworzymy one hot wektory '''\n",
    "unique = find_unique(hasla)\n",
    "onehots = make_one_hot_vectors(unique)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "''' przepisujemy slowa na one hot vectory ''' \n",
    "word_vectors = []\n",
    "\n",
    "for haslo in hasla:\n",
    "    word_vectors.append(make_word_vector(haslo, onehots))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "''' znajdujemy najdluzsze slowo i minimalna wielkosc okna ''' \n",
    "longestword = find_longest_word(hasla)\n",
    "min_window = get_min_window_size(longestword)\n",
    "\n",
    "''' tworzymy wartosci do uczenia dla sieci '''\n",
    "inputs, outputs = make_pre_char_embedding(word_vectors ,min_window)\n",
    "  \n",
    "    \n",
    "    \n",
    "''' printy na wszystko, co tu sie dzialo '''    \n",
    "print(\"UNIKALNE ZNAKI\")  \n",
    "print(unique)\n",
    "\n",
    "print(\"\\n\\nONE-HOT-VECTORS\")\n",
    "for onehot in onehots:\n",
    "    print(onehot, onehots[onehot])\n",
    "    \n",
    "print(\"\\n\\nHASLA ZAPISANE ONE-HOT-WEKTORAMI\")\n",
    "for word_vector in word_vectors:\n",
    "    print(word_vector)\n",
    "    \n",
    "print(\"\\n\\nNAJDLUZSZY WYRAZ: \", longestword) \n",
    "\n",
    "print(\"\\n\\nMIN WINDOW SIZE: \", min_window)\n",
    "\n",
    "print(\"\\n\\nINPUTY DLA SIECI\")\n",
    "for inn in inputs:\n",
    "    print(inn)\n",
    "\n",
    "print(\"\\n\\nOUTPUTY DLA SIECI\")\n",
    "for out in outputs:\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GdpMEobAUq9I"
   },
   "source": [
    "# Kot  robicy magi part2 - SSN \n",
    "W tej czci najfajniejsza zabawa. Zaczniemy od wprowadzenia caego modelu sieci i om贸wienia go na prostym przykadzie, czyli hasa \"abc\". \n",
    "\n",
    "Cao oparta na frameworku PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ufu2gNYSUq9m"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zbudowanie modelu\n",
    "\n",
    "Klasa w konstruktorze przyjmuje dwa parametry. Pierwszym jest ilo wej do sieci, kt贸ra musi odpowiada minimalnenej wielkoci okna. Drugim argumentem jest ilo wyj, kt贸ra musi by r贸wna najdu偶szemu wyrazowi, co jest r贸wne wielkoci jednego one hot vector'a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, inputs, outputs):\n",
    "        super(CBOW, self).__init__()\n",
    "        \n",
    "        self.fc_in = nn.Linear(in_features=inputs, out_features=4)\n",
    "        self.fc_out = nn.Linear(in_features=4, out_features=outputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc_in(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przygotowanie danych trenujcych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja pomocnicza do tumaczenia one hot wektora na klas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_labels_to_classes(labels, classdict, one_hot_vectors):\n",
    "    return np.array([translate_sign_to_class(translate_one_hot_vector_to_sign(item, one_hot_vectors), classdict) for item in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mamy tutaj swego rodzaju zdublowanie podsumowania czci pierwszej dotyczcej character embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, 'a': 6, 'b': 7, 'c': 8, 'd': 9, 'e': 10, 'g': 11, 'h': 12, 'i': 13, 'j': 14, 'k': 15, 'l': 16, 'm': 17, 'n': 18, 'o': 19, 'p': 20, 'q': 21, 'r': 22, 's': 23, 't': 24, 'u': 25, 'w': 26, 'y': 27, 'z': 28} \n",
      "\n",
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [1 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]] \n",
      "\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] \n",
      "\n",
      "[ 5  4  3  2  1  0  3  1 19 10 18 27 24 22 10 26 21  6 15 13 18 19 17  4\n",
      "  2  1  0 15 10 13 23 13 17 27 20 25 15  6 28  6 18 13 16 19 22  6 15  6\n",
      " 13 23  6 15  3  2  1  0 18 13  8 22  6 17 22 19 13 23  6 24 15 10 24 22\n",
      "  6  7 11 18 25 23 17  6 23 15 10 17 19 24  6 24  6 10  7 22 10 20  8  6\n",
      " 15  0  6 13 23  6 15  0  0  0  0  0  0 28 22 19 11 10 28 22 11  6 15 28\n",
      " 23 27 17 28 23 25 10 24  6 17  6 15 16  6 22 20 16  6 12  8 13 17  6 15\n",
      " 13 18 19 22 10 26 10 26 21  2  1  0 15 10 24 14 19 26 23 10  9 10  8 22\n",
      " 10 17]\n"
     ]
    }
   ],
   "source": [
    "''' zebranie slow '''\n",
    "slowa = [\"123456\", \n",
    "         \"neo24\", \n",
    "         \"qwerty\", \n",
    "         \"monika\", \n",
    "         \"1235\", \n",
    "         \"misiek\", \n",
    "         \"zakupy\", \n",
    "         \"karolina\", \n",
    "         \"kasia\", \n",
    "         \"1234\", \n",
    "         \"marcin\", \n",
    "         \"tasior\", \n",
    "         \"bartek\", \n",
    "         \"samsung\", \n",
    "         \"tomek\", \n",
    "         \"beata\", \n",
    "         \"kacper\", \n",
    "         \"kasia1\", \n",
    "         \"111111\", \n",
    "         \"grzegorz\", \n",
    "         \"myszka\", \n",
    "         \"mateusz\", \n",
    "         \"pralka\", \n",
    "         \"michal\", \n",
    "         \"weronika\", \n",
    "         \"123qwe\", \n",
    "         \"wojtek\", \n",
    "         \"mercedes\"]\n",
    "\n",
    "\n",
    "\n",
    "''' znalezienie unikalnych znakow i utworzenie one hot vectorow dla znakow '''\n",
    "unikalne = find_unique(slowa)\n",
    "onehotvectory = make_one_hot_vectors(unikalne)\n",
    "\n",
    "\n",
    "''' przepisanie slow na one hot vectory '''\n",
    "wyrazy = [make_word_vector(slowo, onehotvectory) for slowo in slowa]\n",
    "\n",
    "\n",
    "\n",
    "''' zbudowanie klas dla poszczegolnych znakow'''\n",
    "classdict = make_class_id(onehotvectory)\n",
    "print(classdict, '\\n')\n",
    "\n",
    "\n",
    "''' znalezienie najdluzszego slowa i minimalnej wielkosci okna '''\n",
    "najdluzszeslowo = find_longest_word(slowa)\n",
    "minimalnawielkoscokna = get_min_window_size(najdluzszeslowo)\n",
    "\n",
    "''' przygotowanie danych do uczenia '''\n",
    "training_data, training_data_labels = make_pre_char_embedding(wyrazy, minimalnawielkoscokna)\n",
    "    \n",
    "print(training_data, '\\n')\n",
    "print(training_data_labels, '\\n')\n",
    "\n",
    "training_data_classes = translate_labels_to_classes(training_data_labels, classdict, onehotvectory)\n",
    "print(training_data_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prezentacja postaci danych\n",
    "Czyli pokazanie wielkoci macierzy, jakie trafiaj do sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ksztalt macierzy przed przeksztalceniem (170, 14, 29) \n",
      "\n",
      "macierz przed przeksztalceniem [[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [1 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]] \n",
      "\n",
      "ksztalt macierzy po przeksztalceniu (170, 406) \n",
      "\n",
      "macierz do podania do sieci [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print('ksztalt macierzy przed przeksztalceniem', training_data.shape, '\\n')\n",
    "print('macierz przed przeksztalceniem', training_data, '\\n')\n",
    "training_data = training_data.reshape(training_data.shape[0], -1)\n",
    "print('ksztalt macierzy po przeksztalceniu', training_data.shape, '\\n')\n",
    "print('macierz do podania do sieci', training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilosc probek do uczenia sieci 406\n",
      "ilosc probek na wyjsciu sieci 170\n"
     ]
    }
   ],
   "source": [
    "print('ilosc probek do uczenia sieci', training_data.shape[1])\n",
    "print('ilosc probek na wyjsciu sieci', training_data_classes.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Je偶eli dostpne jest GPU to przenosimy dane na GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utworzenie modelu sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CBOW = nn.DataParallel(CBOW(training_data.shape[1], len(unikalne)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tworzenie tensor贸w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Tensor z wartociami wejciowymi '''\n",
    "TensorX = torch.Tensor(training_data).to(device)\n",
    "\n",
    "''' Tensor z klasami, kt贸re maj si pokazywa na wyjciu '''\n",
    "TensorClass = torch.tensor(training_data_classes).long().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posta tensor贸w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([ 5,  4,  3,  2,  1,  0,  3,  1, 19, 10, 18, 27, 24, 22, 10, 26, 21,  6,\n",
      "        15, 13, 18, 19, 17,  4,  2,  1,  0, 15, 10, 13, 23, 13, 17, 27, 20, 25,\n",
      "        15,  6, 28,  6, 18, 13, 16, 19, 22,  6, 15,  6, 13, 23,  6, 15,  3,  2,\n",
      "         1,  0, 18, 13,  8, 22,  6, 17, 22, 19, 13, 23,  6, 24, 15, 10, 24, 22,\n",
      "         6,  7, 11, 18, 25, 23, 17,  6, 23, 15, 10, 17, 19, 24,  6, 24,  6, 10,\n",
      "         7, 22, 10, 20,  8,  6, 15,  0,  6, 13, 23,  6, 15,  0,  0,  0,  0,  0,\n",
      "         0, 28, 22, 19, 11, 10, 28, 22, 11,  6, 15, 28, 23, 27, 17, 28, 23, 25,\n",
      "        10, 24,  6, 17,  6, 15, 16,  6, 22, 20, 16,  6, 12,  8, 13, 17,  6, 15,\n",
      "        13, 18, 19, 22, 10, 26, 10, 26, 21,  2,  1,  0, 15, 10, 24, 14, 19, 26,\n",
      "        23, 10,  9, 10,  8, 22, 10, 17], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(TensorX)\n",
    "print(TensorClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wybranie optymizera oraz funkcji LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Adam optimizer '''\n",
    "optimizer = optim.Adam(CBOW.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "\n",
    "''' CrossEntropy jako loss '''\n",
    "criterion = nn.CrossEntropyLoss() #z softmaxem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opisanie obiektu sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): CBOW(\n",
       "    (fc_in): Linear(in_features=406, out_features=4, bias=True)\n",
       "    (fc_out): Linear(in_features=4, out_features=29, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CBOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sprawdzenie tensora wejciowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sprawdzenie tensora wyjciowego (tensora klas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5,  4,  3,  2,  1,  0,  3,  1, 19, 10, 18, 27, 24, 22, 10, 26, 21,  6,\n",
       "        15, 13, 18, 19, 17,  4,  2,  1,  0, 15, 10, 13, 23, 13, 17, 27, 20, 25,\n",
       "        15,  6, 28,  6, 18, 13, 16, 19, 22,  6, 15,  6, 13, 23,  6, 15,  3,  2,\n",
       "         1,  0, 18, 13,  8, 22,  6, 17, 22, 19, 13, 23,  6, 24, 15, 10, 24, 22,\n",
       "         6,  7, 11, 18, 25, 23, 17,  6, 23, 15, 10, 17, 19, 24,  6, 24,  6, 10,\n",
       "         7, 22, 10, 20,  8,  6, 15,  0,  6, 13, 23,  6, 15,  0,  0,  0,  0,  0,\n",
       "         0, 28, 22, 19, 11, 10, 28, 22, 11,  6, 15, 28, 23, 27, 17, 28, 23, 25,\n",
       "        10, 24,  6, 17,  6, 15, 16,  6, 22, 20, 16,  6, 12,  8, 13, 17,  6, 15,\n",
       "        13, 18, 19, 22, 10, 26, 10, 26, 21,  2,  1,  0, 15, 10, 24, 14, 19, 26,\n",
       "        23, 10,  9, 10,  8, 22, 10, 17], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wypisanie wielkoci macierzy tensor贸w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([170, 406])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([170])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorClass.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wypisanie wielkoci wag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 406])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CBOW.module.fc_in.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CBOW.module.fc_out.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test pierwszego przeliczenia sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = CBOW(TensorX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uczenie sieci \n",
    "### Wyjanienie poszczeg贸lnych zale偶noci\n",
    "```loss.backward(), optimizer.step(), optimizer.zero_grad(), CBOW.train()```\n",
    "\n",
    "pytorch umo偶liwia ustawienie sieci w tryb uczenia (bardziej zo偶ony obliczeniowo) dlatego stosuje si na pocztku polecenie ```CBOW.train()```\n",
    "\n",
    "```optimizer.step()``` aktualizuje parametry bazujc na obecnej wartoci gradientu. Wywoujc ```loss.backward()``` sumuje wartoci gradientu dla ka偶dego parametru, dlatego po ka偶dym ```optimizer.step()``` powinnimy go wyzerowa wykorzystujc ```optimizer.zero_grad()```.\n",
    "\n",
    "W niekt贸rych typach sieci np. rekurencyjnych korzysta si z sumowania wartoci gradientu i nie zeruje si jej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n"
     ]
    }
   ],
   "source": [
    "''' ustawiamy tablice do stworzenia wykresiku '''\n",
    "lossx = []\n",
    "lossy = []\n",
    "\n",
    "''' Waciwa nauka sieci '''\n",
    "for epoch in range(22000):\n",
    "    ''' Przestawienie obiektu sieci w tryb uczenia '''\n",
    "    CBOW.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    ''' Przeliczenie wartoci '''\n",
    "    y_ = CBOW(TensorX)\n",
    "    \n",
    "    ''' Obliczenie funkcji loss '''\n",
    "    loss = criterion(y_, TensorClass)\n",
    "    \n",
    "    ''' Dodanie loss do wykresiku '''\n",
    "    lossx.append(epoch)\n",
    "    lossy.append(loss)\n",
    "\n",
    "    ''' Wsteczna propagacja i aktualizacja parametr贸w przez optimizer'''\n",
    "    loss.backward(loss)\n",
    "    optimizer.step()\n",
    "    \n",
    "    ''' print '''\n",
    "    if epoch % 1000 == 0:\n",
    "        print(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wywietlenie wykresu funkcji LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29d07797400>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fix, ax = plt.subplots()\n",
    "ax.plot(lossx, lossy, \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kocowa warto LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.0135, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print('loss', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wypisanie wag - wektor贸w dla poszczeg贸lnych znak贸w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 2.1931,  0.8272, -2.0412, -0.6663],\n",
       "        [ 1.5130,  1.1437, -1.8022,  2.1213],\n",
       "        [ 1.9682, -1.6273, -1.8342, -1.4252],\n",
       "        [ 0.9122, -1.7326, -2.3486,  1.0160],\n",
       "        [ 0.7862, -1.4051, -0.8626,  2.5286],\n",
       "        [ 1.9869,  0.1184, -0.6159, -2.3581],\n",
       "        [-2.0315, -0.8995, -2.0305,  1.8326],\n",
       "        [ 1.5581, -2.1662,  2.4547, -0.7539],\n",
       "        [ 0.7055,  1.8532,  2.1081,  1.1137],\n",
       "        [-0.0718,  0.5995, -1.0464, -2.6285],\n",
       "        [-0.2473,  2.0792, -2.1034, -0.5287],\n",
       "        [-1.2192, -2.4789, -1.9915, -0.0878],\n",
       "        [ 1.9364,  0.8407,  2.1112, -0.3539],\n",
       "        [ 2.3690,  2.3451,  0.0171,  0.6382],\n",
       "        [ 1.3847, -2.0265,  1.7633,  1.4512],\n",
       "        [-2.1155, -1.5337, -0.6503, -2.2414],\n",
       "        [-0.8052,  2.2430,  0.6030,  0.3018],\n",
       "        [-0.9617, -2.1021,  2.0134, -1.5975],\n",
       "        [-1.9627,  1.5479, -0.3133, -1.7771],\n",
       "        [-1.5930,  1.2491,  2.6188, -1.7039],\n",
       "        [ 2.0714, -0.3166,  2.0823,  2.1153],\n",
       "        [ 2.5524, -1.9315,  0.1335,  1.5111],\n",
       "        [-1.3924, -2.3555,  2.1061,  2.2927],\n",
       "        [-1.8144,  1.0933,  1.1134,  2.3971],\n",
       "        [-2.4894, -1.0007,  0.9834,  0.5235],\n",
       "        [ 2.3345, -2.3615,  0.1773, -1.0012],\n",
       "        [ 1.1545, -0.2916,  1.8084, -2.4950],\n",
       "        [-0.0853, -1.2262, -2.1678, -1.9453],\n",
       "        [ 0.6804,  2.2914,  1.3325, -2.3767]], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CBOW.module.fc_out.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testowanie sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor(40.2838, device='cuda:0')\n",
      "2 tensor(22.5190, device='cuda:0')\n",
      "3 tensor(52.6319, device='cuda:0')\n",
      "4 tensor(34.3751, device='cuda:0')\n",
      "5 tensor(19.5292, device='cuda:0')\n",
      "6 tensor(51.5873, device='cuda:0')\n",
      "a tensor(10.0097, device='cuda:0')\n",
      "b tensor(42.5548, device='cuda:0')\n",
      "c tensor(15.9288, device='cuda:0')\n",
      "d tensor(42.1251, device='cuda:0')\n",
      "e tensor(26.0722, device='cuda:0')\n",
      "g tensor(32.0403, device='cuda:0')\n",
      "h tensor(32.2573, device='cuda:0')\n",
      "i tensor(26.1492, device='cuda:0')\n",
      "j tensor(26.4934, device='cuda:0')\n",
      "k tensor(34.4740, device='cuda:0')\n",
      "l tensor(12.7101, device='cuda:0')\n",
      "m tensor(33.1420, device='cuda:0')\n",
      "n tensor(25.1086, device='cuda:0')\n",
      "o tensor(21.8157, device='cuda:0')\n",
      "p tensor(22.7463, device='cuda:0')\n",
      "q tensor(36.9912, device='cuda:0')\n",
      "r tensor(9.9928, device='cuda:0')\n",
      "s tensor(0.0001, device='cuda:0')\n",
      "t tensor(10.3798, device='cuda:0')\n",
      "u tensor(48.5107, device='cuda:0')\n",
      "w tensor(43.5843, device='cuda:0')\n",
      "y tensor(42.6082, device='cuda:0')\n",
      "z tensor(36.2496, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "''' przepisanie slowa na one hot vector '''\n",
    "wyrazy_testowe = [make_word_vector('mercedes', onehotvectory)]\n",
    "\n",
    "''' przepisanie slowa na wartosci przy zachowaniu wielkosci okna z procesu uczenia '''\n",
    "''' UWAGA - w tym procesie ze slowa podanego wyzej zabierana jest ostatnia litera '''\n",
    "''' zgodnie z definicja funkcji  \"make_pre_char_embedding\" ostatnia litera trafia na wyjscie sieci'''\n",
    "''' zatem wpisujac w zbiorze testowym slowo ze zbioru uczacego, na wyjsciu powinnismy otrzymac ostatni znak '''\n",
    "''' z podanego wyzej slowa  '''\n",
    "testing_data, testing_data_labels = make_pre_char_embedding(wyrazy_testowe, minimalnawielkoscokna)\n",
    "\n",
    "''' reshape wartosci '''\n",
    "''' wybieramy indeks slowa \"0\", bo chcemy miec pierwszy przypadek ulozenia wartosci wejsciowych dla sieci '''\n",
    "''' tzn. wszystkie litery na wejscie, oprocz ostatniej, ktora trafia na wyjscie '''\n",
    "testing_data = testing_data[0].reshape(1, -1)\n",
    "\n",
    "''' utworzenie tensora i wyslanie go do wlasciwego urzadzenia (CPU/GPU) '''\n",
    "TestingTensor = torch.Tensor(testing_data)\n",
    "TestingTensor = TestingTensor.to(device)\n",
    "\n",
    "''' dla CrossEntropy wyznaczana jest wartosc przynaleznosci do danej klasy '''\n",
    "''' im nizsza wartosc, tym lepsze dopasowanie '''\n",
    "''' do CrossEntropy mozemy podac tylko jedna wartosc do przeliczenia '''\n",
    "''' dlatego nalezy zrobic tablice tensorow wartosci wszystkich klas '''\n",
    "''' dla ktorych pozniej przeliczymy LOSS CrossEntropy '''\n",
    "TestingTensorsClass = [torch.tensor([x]).long().to(device) for x in range(len(unikalne))]\n",
    "\n",
    "''' bardzo wazne - w sieci nalezy wylaczyc tryb uczenia '''\n",
    "''' z tego co czytalem, wylacza on m.in. korzystanie z wartosci gradientow, co przyspiesza obliczenia '''\n",
    "''' wykorzystywac wartosc tylko wtedy, gdy nie planujemy uczyc sieci '''\n",
    "CBOW.eval()\n",
    "\n",
    "\n",
    "''' tryb wylaczonych gradientow '''\n",
    "with torch.no_grad():\n",
    "    ''' iterujemy przez wszystkie wartosci klas '''\n",
    "    for x in range(len(unikalne)):\n",
    "        ''' przeliczamy wartosc '''\n",
    "        y_ = CBOW(TestingTensor)\n",
    "        \n",
    "        ''' chcemy zrobic fajnego print'a, wiec tlumaczymy podawana klase na znak '''\n",
    "        ''' w drugim argumencie printa otrzymujemy nasz LOSS, '''\n",
    "        ''' ktory mowi jaki najprawdopodobniej jest ostatni znak podanego slowa '''\n",
    "        ''' (dla slowa ze zbioru uczacego powinien to byc ostatni znak podanego slowa) '''\n",
    "        print(translate_class_to_sign(x, classdict), criterion(y_, TestingTensorsClass[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z kodu wy偶ej zrobienie funkcji \n",
    "Tutaj generalnie jest taki myk, 偶e sowo kt贸re chcemy przetestowa jest bezporednio konwertowane na wektor one hot wektor贸w. Nie wystpuje tutaj dopasowywanie sowa do wielkoci okna.\n",
    "\n",
    "#### Ale dlaczego?\n",
    "Rzecz w tym, 偶e biorc pod uwag sowo \"abc\" przy wielkoci okna = 8 nie bylibymy w stanie uo偶y wektor贸w tak, by pokazao przewidywany znak dla znaku pomidzy znakami sowa.\n",
    "\n",
    "##### Przykad\n",
    "Chcemy wyznaczy prawdopodobiestwo wystpienia jakiego znaku pomidzy znakami \"abb\" oraz \"cc\". Stosujc dopasowywanie do wielkoci okna moglibymy dopasowywa jedynie prawdopodobiestwo ostatniego znaku, albo innego typu uo偶enia, ale na to trza pisa osobne funkcje \n",
    "\n",
    "#### Jak to wicj dziaa\n",
    "Metoda ta wykorzystuje opisywany wy偶ej myk. Nie jest on do koca poprawny, ale dziaa, a jak dziaa i jest gupie, to nie jest a偶 takie gupie. Znaki naszego sowa s bezporednio konwertowane na one hot vectory. Oznacza to, 偶e musimy wybra jaki znak, kt贸ry nie wystpi w zbiorze znak贸w. Odwoujc si do zbioru naszych hase jestem przekonany, 偶e na pewno nie wystpi w nim... emotka  \"japoski przycisk 'wolne miejsce'\".\n",
    "\n",
    "##### Przykad\n",
    "Mamy wielko okna = 8, chcemy sprawdzi predykcj dla znaku pomidzy \"abb\" oraz \"cc\". Nasze sowo musimy zatem zapisa jako:\n",
    "abbcc仇.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(minimalnawielkoscokna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n 0.5373992919921875\n",
      "e 1.1352081298828125\n",
      "d 2.796807289123535\n",
      "z 3.4891624450683594\n",
      "l 6.445146560668945\n",
      "o 7.607002258300781\n",
      "y 7.849733352661133\n",
      "k 8.552597999572754\n",
      "1 8.79341983795166\n",
      "6 10.951892852783203\n",
      "i 11.683647155761719\n",
      "w 13.154324531555176\n",
      "a 15.852775573730469\n",
      "t 16.237091064453125\n",
      "3 18.450305938720703\n",
      "c 18.631845474243164\n",
      "h 19.0881404876709\n",
      "s 19.186553955078125\n",
      "2 19.213600158691406\n",
      "g 19.8337345123291\n",
      "m 19.9807071685791\n",
      "4 24.092668533325195\n",
      "u 25.20496368408203\n",
      "5 28.46202850341797\n",
      "b 31.598663330078125\n",
      "p 33.29864501953125\n",
      "j 33.79948425292969\n",
      "r 34.65837478637695\n",
      "q 35.61117172241211\n"
     ]
    }
   ],
   "source": [
    "''' FUNKCJA WYKORZYSTUJACA EMOTKI  '''\n",
    "''' WYKORZYSTYWANA EMOTKA: , WE SE SKOPIUJ  '''\n",
    "def test_word(word, fill = 0):\n",
    "    word_one_hot = np.array([onehotvectory[letter] if letter != '' else [fill for x in range(len(unikalne))] for letter in word])\n",
    "\n",
    "    if len(word_one_hot) != minimalnawielkoscokna:\n",
    "        raise Exception(\"Slowo o blednej dluosci wejsciowej\")\n",
    "\n",
    "    TestTensor = torch.Tensor(word_one_hot.reshape(1, -1)).to(device)\n",
    "\n",
    "    TestingTensorsClass = [torch.tensor([x]).long().to(device) for x in range(len(unikalne))]\n",
    "\n",
    "    prawdopodobienstwa = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x in range(len(unikalne)):\n",
    "            y_ = CBOW(TestTensor)\n",
    "            \n",
    "            ''' obliczenie CrossEntropyLoss i zapisanie do sownika '''\n",
    "            prawdopodobienstwa[translate_class_to_sign(x, classdict)] = criterion(y_, TestingTensorsClass[x]).item()\n",
    "            \n",
    "        ''' posortowanie i wypisanie predykcji '''\n",
    "        for item in sorted(prawdopodobienstwa, key=prawdopodobienstwa.get):\n",
    "            print(item, prawdopodobienstwa[item])\n",
    "            \n",
    "test_word(\"mercedes仇仇仇仇\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, 'a': 6, 'b': 7, 'c': 8, 'd': 9, 'e': 10, 'g': 11, 'h': 12, 'i': 13, 'j': 14, 'k': 15, 'l': 16, 'm': 17, 'n': 18, 'o': 19, 'p': 20, 'q': 21, 'r': 22, 's': 23, 't': 24, 'u': 25, 'w': 26, 'y': 27, 'z': 28}\n",
      "a oraz 1:  -0.20318055\n",
      "a oraz 2:  0.29019618\n",
      "a oraz 3:  -0.11692118\n",
      "a oraz 4:  0.55803335\n",
      "a oraz 5:  0.5505853\n",
      "a oraz 6:  -0.6505636\n",
      "a oraz a:  1.0000001\n",
      "a oraz b:  -0.58106524\n",
      "a oraz c:  -0.48864615\n",
      "a oraz d:  -0.3027108\n",
      "a oraz e:  0.18205574\n",
      "a oraz g:  0.71550846\n",
      "a oraz h:  -0.90853775\n",
      "a oraz i:  -0.48387635\n",
      "a oraz j:  -0.1617659\n",
      "a oraz k:  0.23408662\n",
      "a oraz l:  -0.12063607\n",
      "a oraz m:  -0.26033157\n",
      "a oraz n:  -0.00235564\n",
      "a oraz o:  -0.48232433\n",
      "a oraz p:  -0.3338954\n",
      "a oraz q:  -0.076077506\n",
      "a oraz r:  0.3336214\n",
      "a oraz s:  0.40507293\n",
      "a oraz t:  0.4806048\n",
      "a oraz u:  -0.39331108\n",
      "a oraz w:  -0.8871496\n",
      "a oraz y:  0.189663\n",
      "a oraz z:  -0.8224315\n"
     ]
    }
   ],
   "source": [
    "def similarity(letter1, letter2):\n",
    "    id1=0\n",
    "    id2=0\n",
    "    \n",
    "    for classid in classdict:\n",
    "        if classid == letter1:\n",
    "            id1 = classdict[classid]\n",
    "        \n",
    "        if classid == letter2:\n",
    "            id2 = classdict[classid]\n",
    "    \n",
    "    v1 = CBOW.cpu().module.fc_out.weight[id1].detach().numpy()\n",
    "    v2 = CBOW.cpu().module.fc_out.weight[id2].detach().numpy()\n",
    "    \n",
    "    d = np.dot(v1, v2)\n",
    "    \n",
    "    l1 = np.sqrt(np.sum(v1**2))\n",
    "    l2 = np.sqrt(np.sum(v2**2))\n",
    "    \n",
    "    return d/(l1*l2)\n",
    "\n",
    "\n",
    "literka = \"a\"\n",
    "\n",
    "print(classdict)\n",
    "\n",
    "for classid in classdict:\n",
    "    print(literka+\" oraz \"+classid+\": \", similarity(literka, classid))\n",
    "\n",
    "#print(similarity(\"z\", \"a\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ciekawostka 1\n",
    "Mo偶e emotki, to spos贸b na nowe i o wiele bezpieczniejsze hasa?\n",
    "\n",
    "![WP haso emotkami](https://i.imgur.com/1pQVulX.png)\n",
    "\n",
    "W WP mamy filtry na pole z hasem.\n",
    "\n",
    "A w .net nie \n",
    "\n",
    "![Morele.net](https://i.imgur.com/Nj5Sujm.png)\n",
    "\n",
    "Na konto da si normalnie zalogowa i korzysta \n",
    "\n",
    "#### Ciekawostka 2\n",
    "+  skada si z 4 znak贸w\n",
    "+  skada si z 2 znak贸w\n",
    "+ ㄢㄢр skada si z 11 znak贸w \n",
    "\n",
    "#### Ciekawostka 3\n",
    "[Generator hasa emoji](https://passmoji.com/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "char_embeddingV2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
